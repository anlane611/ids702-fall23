[
  {
    "objectID": "unit0b.html",
    "href": "unit0b.html",
    "title": "Cleaning and exploring data in R",
    "section": "",
    "text": "A crucial first step of data analysis is exploring the dataset (and then cleaning, as needed). Today, we will practice exploring and cleaning data in R."
  },
  {
    "objectID": "unit0b.html#types-of-variables",
    "href": "unit0b.html#types-of-variables",
    "title": "Cleaning and exploring data in R",
    "section": "Types of variables",
    "text": "Types of variables\nNumeric variables take numerical values and it makes sense to perform calculations on the values (e.g., addition, mean)\n\nDiscrete variables can not take decimal values (e.g., Number of required statistics courses in a major)\nContinuous variables can take decimal values (e.g., height in cm)\n\nCategorical variables are variables that have categories, where each category is called a level\n\nNominal variables do not have an order (e.g., eye color)\nOrdinal variables do have an order (e.g., education categories)\n\n\nExercise\nIn your group, discuss the following:\n\nClassify each of the survey questions as discrete, continuous, nominal, or ordinal.\nWhat does it mean to explore data?\nWhat does it mean to clean data? Identify how the survey data may need to be cleaned just by looking at the questions."
  },
  {
    "objectID": "unit0b.html#first-steps-in-r",
    "href": "unit0b.html#first-steps-in-r",
    "title": "Cleaning and exploring data in R",
    "section": "First steps in R",
    "text": "First steps in R\nHopefully you have already installed R/RStudio on your computer. If so, you can copy and paste the code below into your own script. If you haven’t yet installed R/RStudio, you can run code directly from this page.\nLoading\n  webR...\n\n\n  \n\n\nLoading\n  webR...\n\n\n  \n\n\nLet’s remove the timestamp variable\nLoading\n  webR...\n\n\n  \n\n\nLet’s make our variable names more concise (but still descriptive!)\nLoading\n  webR..."
  },
  {
    "objectID": "unit0b.html#cleaning-and-exploring-variables",
    "href": "unit0b.html#cleaning-and-exploring-variables",
    "title": "Cleaning and exploring data in R",
    "section": "Cleaning and exploring variables",
    "text": "Cleaning and exploring variables\n\nSiblings\nLet’s start with the Siblings variable. What information do we need to know to clean the variable?\nLoading\n  webR...\n\n\n  \n\n\nAlways always always:\n\ncreate a new variable instead of overwriting the original\nperform a quality control check\n\nLoading\n  webR...\n\n\n  \n\n\nNow that the variable is clean, let’s explore it more:\nLoading\n  webR...\n\n\n  \n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\nSushi\nNow consider the sushi variable.\nLoading\n  webR...\n\n\n  \n\n\nIt’s important to pay attention to implausible values. What would be an implausible value in this case? How should we handle it?\nLoading\n  webR...\n\n\n  \n\n\nNow let’s generate a plot to visualize the sushi variable\nLoading\n  webR...\n\n\n  \n\n\n\n\nLanguages\nLoading\n  webR...\n\n\n  \n\n\nOften, we need to combine categories if we have too few observations in multiple categories. How should we combine categories in this case?"
  },
  {
    "objectID": "unit0b.html#exercises",
    "href": "unit0b.html#exercises",
    "title": "Cleaning and exploring data in R",
    "section": "Exercises",
    "text": "Exercises\nIn your group, complete the following:\n\nFor the application area of interest variable, how many students responded with “other”? What does this say about the survey design?\nExplore, clean, and visualize the remaining variables in the dataset. Note that you may have to look up some functions to help. For example, the “substr” function will be useful for the course excitement variable."
  },
  {
    "objectID": "unit0a.html",
    "href": "unit0a.html",
    "title": "Key Principles of Statistics",
    "section": "",
    "text": "By the end of this session, students should be able to:\n\ndistinguish between a population and a sample\ndescribe sampling variability\nfit a simple linear regression model in R"
  },
  {
    "objectID": "unit0a.html#load-the-data",
    "href": "unit0a.html#load-the-data",
    "title": "Key Principles of Statistics",
    "section": "Load the data",
    "text": "Load the data\nToday we will use the births14 dataset in the openintro R package. You can read more about the dataset and see a data dictionary at this link.\n\n#load the packages we need\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#load the dataset from the openintro package\ndata(births14)\n\n#get an overview of the data\nglimpse(births14)"
  },
  {
    "objectID": "unit0a.html#exercise",
    "href": "unit0a.html#exercise",
    "title": "Key Principles of Statistics",
    "section": "Exercise",
    "text": "Exercise\nExplore the births14 data:\n\nUsing the data dictionary at the link above, classify the variables as numeric or categorical. Do the variables seem to be correctly structured in R?\nUse the summary() function to determine if there are missing values in the dataset"
  },
  {
    "objectID": "unit0a.html#hypothetically",
    "href": "unit0a.html#hypothetically",
    "title": "Key Principles of Statistics",
    "section": "Hypothetically…",
    "text": "Hypothetically…\nImagine that this dataset contains information about the entire population of interest (e.g., all babies born in Bull City). Then, say we have the following research question:\nWhat is the relationship between length of pregnancy in weeks and weight of the baby in pounds in Bull City?\nWe can explore this relationship graphically:\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\", y=\"baby weight (lbs)\") \n  #always use labels!"
  },
  {
    "objectID": "unit0a.html#linear-regression",
    "href": "unit0a.html#linear-regression",
    "title": "Key Principles of Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nTo further characterize the relationship between length of pregnancy and baby weight, we can fit a line to the plot:\n\nmod_bullcity <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births14)\n\ntidy(mod_bullcity, conf.int=TRUE)\n\n\nExercise\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\n\nLooking at the estimate column of the tidy output, how would you interpret the intercept here? how would you interpret the weeks estimate?\n\n\n\nStandard error\nTo better conceptualize the standard error, consider the premise above that these data represent the entire city. Now imagine that we could not actually obtain all of these data. Instead, we were only able to obtain a sample of 200 babies. Using only a sample of 200, if we fit a line in the same way as above, we have many different lines that we could have obtained:\n\nset.seed(823)\nbirths_sample1 <- births14 |> slice_sample(n=200)\n\nggplot(births_sample1, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\nmod_sample1 <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births_sample1)\n\ntidy(mod_sample1, conf.int=TRUE)\n\n\n\nExercise\nFill in the code below to simulate the process of taking 250 different samples and store the weeks coefficient estimate in a vector\n\nweeks.coefs <- c() #create empty vector to store coefficient estimates\n\nfor(i in 1:250){ #create loop for 250 different samples\n  print(i)\n  set.seed(823+i) #set a unique seed each iteration\n  \n  #sample data\n  births_sample <-\n  \n  #fit model\n  mod_sample <- \n    \n  #store output\n  weeks.coefs[i] <- tidy(mod_sample)$estimate[2]\n}\n\n \n \n \nNow let’s plot the coefficient estimates we have for the 250 samples:\n\nweeks.coefs.dat <- data.frame(weeks.coefs)\n\nggplot(weeks.coefs.dat, aes(x=weeks.coefs))+\n  geom_histogram()+\n  labs(x=\"weeks coefficient estimate\")\n\nWe see that there is variability in the coefficient estimates for weeks. The standard deviation of this collection of possible estimates is the standard error of the estimate.\n\n\nConfidence interval and p-value\nWe can also use this collection of estimates to provide a plausible range for the “true” coefficient value:\n\nquantile(weeks.coefs, probs=c(.025,.975))\n\nOr, we can look at the collection of estimates and see that none of them are 0. So, because we collected 250 different samples and none of them had a coefficient estimate of 0, we are quite confident that the “true” coefficient is not zero.\n \n \nIn reality, we typically cannot many samples from the same population. So, we often rely on assumptions related to probability distributions to derive confidence intervals and p-values."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "",
    "text": "Welcome to the IDS 702 course site!"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course Overview",
    "text": "Course Overview\nMeeting times: Tuesdays and Thursdays 3:05-4:20 PM, Gross Hall 107\nInstructor \nAndrea Lane, PhD \nandrea.lane@duke.edu \nGross Hall 223 \nOffice hours: Tues/Thurs 4:20-5:20 PM\n \nTeaching Assistants \nXiaoquan Liu \nx.liu@duke.edu \nOffice hours: \n \nDingkun Yang \ndingkun.yang@duke.edu \nOffice hours:"
  },
  {
    "objectID": "index.html#textbook",
    "href": "index.html#textbook",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Textbook",
    "text": "Textbook\nAn Introduction to Statistical Learning with Applications in R, 2nd edition by James, G., Witten, D., Hastie, T., and Tibshirani, R.\nUse the link above to download a PDF of the book"
  },
  {
    "objectID": "index.html#important-dates",
    "href": "index.html#important-dates",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Important Dates",
    "text": "Important Dates\n\n\n  \n    \n      Tuesday, Aug. 29\n      First day of class\n    \n    \n      Tuesday, Oct. 17\n      Fall break - no class meeting\n    \n    \n      Thursday, Nov. 23 \n      Thanksgiving holiday - no class meeting \n    \n        \n      Friday, Dec 1 \n      Classes end, final reports due"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "test page",
    "section": "",
    "text": "Linear regression"
  },
  {
    "objectID": "reflections.html",
    "href": "reflections.html",
    "title": "Statistics Reflections",
    "section": "",
    "text": "In the MIDS program, we emphasize thinking critically about data analysis and upholding principles of diversity, equity, and inclusion. Quantitative fields like data science are often viewed as “amoral,” but human judgment always plays a role in data collection and analysis. As data scientists, we must carefully consider the societal factors that play a role in our work. The materials presented with this assignment explore how statistics/data science interact with society at large.\nThis assignment connects to the third course learning objective: Make careful and critical decisions about model building and consider real-world implications."
  },
  {
    "objectID": "reflections.html#instructions",
    "href": "reflections.html#instructions",
    "title": "Statistics Reflections",
    "section": "Instructions",
    "text": "Instructions\nYou are required to complete four statistics reflections throughout the semester. You can select any four from the list of materials below.\n\nBegin your assignment with a header that includes your name and the title and source of your selected material\nReflect on the material selected. What did it make you think about? How does it affect your work as a data scientist? Note that you are required to engage with the material and provide your thoughts/reactions; you should NOT be summarizing the piece.\nWhile there is no minimum word count for the reflections, you are expected to meaningfully engage with the material (1-2 paragraphs). You can use the suggested questions to get started, but you are not required to answer them in your response.\nIn Gradescope, select the appropriate reflection assignment based on the due date. All of the assignments are already available, so you can complete them at any time!\n\nI am always available if you have any questions or comments about the content presented in these materials. Additionally, if you come across a piece that is not on this list and you would like to use it for a statistics reflection, you are welcome to send me an email. Please include a link to the piece and a brief description of how it connects data science and society."
  },
  {
    "objectID": "reflections.html#deadlines",
    "href": "reflections.html#deadlines",
    "title": "Statistics Reflections",
    "section": "Deadlines",
    "text": "Deadlines\n\nSeptember 15, 11:59 PM\nOctober 6, 11:59 PM\nOctober 27, 11:59 PM\nNovember 17, 11:59 PM"
  },
  {
    "objectID": "reflections.html#materials",
    "href": "reflections.html#materials",
    "title": "Statistics Reflections",
    "section": "Materials",
    "text": "Materials\n\n  \n    \n      \n        A Primer on Non-Binary Gender and Big Data (article)\n      \n    \n    \n      \n        A Primer on Non-Binary Gender and Big Data \n        The author offers several questions you may want to consider in your response: \n        \n          What potential insights might we derive from working with non-binary gender and data?\n          What are the risks to gener minorities in relation to data?\n          What kinds of variation do we see across culture, context, and history?\n          How might non-binary gender and data deal with intersectionality (Click this link to learn more about intersectionality)\n        \n        Additionally, you may want to consider: \n        \n          Is it always useful/important to collect data on gender? In which domains might it be more important than others?\n        \n      \n    \n  \n  \n    \n      \n        How Eugenics Shaped Statistics (article - highly recommended!)\n      \n    \n    \n      \n        How eugenics shaped statistics \n        \n          Consider this quote: \"The separation was everything—not how much, what else might explain it, or why it mattered, just that it was there.\" Reflect on what this means for you as a data scientist\n          The article argues that you cannot separate the science from the scientist. Do you agree?\n          Reflect on the argument that Galton, Pearson, and Fisher's views are \"a product of their time.\"\n        \n        \n      \n    \n  \n  \n    \n      \n        Abolish Big Data (video)\n      \n    \n    \n      \n        Abolish Big Data \n        \n          What does Milner mean when she says \"abolish big data?\"\n          What role does data literacy play in the use of big data tools? What role do data scientists have in the implementation of these tools?\n        \n      \n    \n  \n    \n    \n      \n        Data sonification (videos)\n      \n    \n    \n      \n        Data sonification - from deep space research to improving lives through cancer research AND \n        Making data sing | Margaret Anne Schedel \n        \n          What are the advantages and disadvantages of data sonification?\n          How might data sonification make data more accessible to people with disabilities? Can you think of any other ways data could be made more accessible?\n        \n      \n    \n  \n    \n    \n      \n        Fairness in Machine Learning with Sherri Rose (podcast)\n      \n    \n    \n      \n        Fairness in Machine Learning with Sherri Rose  (interview starts at 8:15 and ends at 46:00)\n        \n          Reflect on Dr. Rose's recommendations for ensuring fairness in machine learning\n          Consider Dr. Rose's comments about the \"single metric leaderboard\" and what it means for you as a data scientist.\n        \n      \n    \n  \n    \n    \n      \n        Peter Donnelly: How stats fool juries (video)\n      \n    \n    \n      \n        Peter Donnelly: How stats fool juries (you can skip past the stats jokes and start at 3:30) \n        \n          This talk is from 2007. Can you think of more recent examples of misleading statistics/misuse of statistical principles?\n          How do you think situations like the trial Donnelly describes can be avoided?"
  },
  {
    "objectID": "unit0.html",
    "href": "unit0.html",
    "title": "Key Principles of Statistics",
    "section": "",
    "text": "By the end of this session, students should be able to:\n\ndistinguish between a population and a sample\ndescribe sampling variability\nfit a simple linear regression model in R"
  },
  {
    "objectID": "unit0.html#load-the-data",
    "href": "unit0.html#load-the-data",
    "title": "Key Principles of Statistics",
    "section": "Load the data",
    "text": "Load the data\nToday we will use the births14 dataset in the openintro R package. You can read more about the dataset and see a data dictionary at this link.\n\n#If you would like the full qmd file, you can run this in the console\ndownload.file(\"https://raw.githubusercontent.com/anlane611/datasets/main/unit0.qmd\",destfile = \"unit0.qmd\")\n\n\n#load the packages we need\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#load the dataset from the openintro package\ndata(births14)\n\n#get an overview of the data\nglimpse(births14)\n\nNote: As an alternative to using RStudio on your local machine, you can use the Duke container: https://cmgr.oit.duke.edu/containers"
  },
  {
    "objectID": "unit0.html#exercise",
    "href": "unit0.html#exercise",
    "title": "Key Principles of Statistics",
    "section": "Exercise",
    "text": "Exercise\nExplore the births14 data:\n\nUsing the data dictionary at the link above, classify the variables as numeric or categorical. Do the variables seem to be correctly structured in R?\nUse the summary() function to determine if there are missing values in the dataset"
  },
  {
    "objectID": "unit0.html#hypothetically",
    "href": "unit0.html#hypothetically",
    "title": "Key Principles of Statistics",
    "section": "Hypothetically…",
    "text": "Hypothetically…\nImagine that this dataset contains information about the entire population of interest (e.g., all babies born in Bull City). Then, say we have the following research question:\nWhat is the relationship between length of pregnancy in weeks and weight of the baby in pounds in Bull City?\nWe can explore this relationship graphically:\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\", y=\"baby weight (lbs)\") \n  #always use labels!"
  },
  {
    "objectID": "unit0.html#linear-regression",
    "href": "unit0.html#linear-regression",
    "title": "Key Principles of Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nTo further characterize the relationship between length of pregnancy and baby weight, we can fit a line to the plot:\n\nmod_bullcity <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births14)\n\ntidy(mod_bullcity, conf.int=TRUE)\n\n\nExercise\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\n\nLooking at the estimate column of the tidy output, how would you interpret the intercept here? how would you interpret the weeks estimate?\n\n\n\nStandard error\nTo better conceptualize the standard error, consider the premise above that these data represent the entire city. Now imagine that we could not actually obtain all of these data. Instead, we were only able to obtain a sample of 200 babies. Using only a sample of 200, if we fit a line in the same way as above, we have many different lines that we could have obtained:\n\nset.seed(823)\nbirths_sample1 <- births14 |> slice_sample(n=200)\n\nggplot(births_sample1, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\nmod_sample1 <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births_sample1)\n\ntidy(mod_sample1, conf.int=TRUE)\n\n\n\nExercise\nFill in the code below to simulate the process of taking 250 different samples and store the weeks coefficient estimate in a vector\n\nweeks.coefs <- c() #create empty vector to store coefficient estimates\n\nfor(i in 1:250){ #create loop for 250 different samples\n  print(i)\n  set.seed(823+i) #set a unique seed each iteration\n  \n  #sample data\n  births_sample <-\n  \n  #fit model\n  mod_sample <- \n    \n  #store output\n  weeks.coefs[i] <- tidy(mod_sample)$estimate[2]\n}\n\n \n \n \nNow let’s plot the coefficient estimates we have for the 250 samples:\n\nweeks.coefs.dat <- data.frame(weeks.coefs)\n\nggplot(weeks.coefs.dat, aes(x=weeks.coefs))+\n  geom_histogram()+\n  labs(x=\"weeks coefficient estimate\")\n\nWe see that there is variability in the coefficient estimates for weeks. The standard deviation of this collection of possible estimates is the standard error of the estimate.\n\n\nConfidence interval and p-value\nWe can also use this collection of estimates to provide a plausible range for the “true” coefficient value:\n\nquantile(weeks.coefs, probs=c(.025,.975))\n\nOr, we can look at the collection of estimates and see that none of them are 0. So, because we collected 250 different samples and none of them had a coefficient estimate of 0, we are quite confident that the “true” coefficient is not zero.\n \n \nIn reality, we typically cannot many samples from the same population. So, we often rely on assumptions related to probability distributions to derive confidence intervals and p-values."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "",
    "text": "Developing an understanding of statistical modeling is a key component of becoming a data scientist. Statistical models are used to answer research questions and obtain meaningful insights from many kinds of data.\nBroadly, this course will cover the following topics:\n\nLinear Regression\nGeneralized Linear Models\nSpecial topics, including survival models and hierarchical models\n\nBut here in the MIDS program, understanding the content is only the beginning. Successful data scientists are critical thinkers, problem solvers, effective communicators, and enthusiastic collaborators. With that in mind, this course aims to meet four key learning objectives:\nBy the end of the course, students should be able to\n\nFit and interpret statistical models, including linear and generalized linear models.\nMap a research question and dataset to the appropriate statistical model\nMake careful and critical decisions about model building and consider real-world implications\nCommunicate (through written and oral communication) model results to a broad audience"
  }
]