[
  {
    "objectID": "materials/unit2/multinomial.html",
    "href": "materials/unit2/multinomial.html",
    "title": "10.12: Multinomial logistic regression",
    "section": "",
    "text": "Identify when to use a multinomial logistic regression model\nInterpret a multinomial logistic regression model\nGenerate a multinomial logistic regression model in R"
  },
  {
    "objectID": "materials/unit2/multinomial.html#classwise-videos",
    "href": "materials/unit2/multinomial.html#classwise-videos",
    "title": "10.12: Multinomial logistic regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nIf you want to type the code as you follow along the lecture, you can use the following code to load the data:\n\nlibrary(foreign) #install the package in the console! The package contains the function `read.dta` that is used to access the data\nml <- read.dta(\"https://stats.idre.ucla.edu/stat/data/hsbdemo.dta\")"
  },
  {
    "objectID": "materials/unit2/multinomial.html#textbook",
    "href": "materials/unit2/multinomial.html#textbook",
    "title": "10.12: Multinomial logistic regression",
    "section": "Textbook",
    "text": "Textbook\nISLR briefly covers multinomial logistic regression in section 4.3.5"
  },
  {
    "objectID": "materials/unit2/multinomial.html#application-exercise",
    "href": "materials/unit2/multinomial.html#application-exercise",
    "title": "10.12: Multinomial logistic regression",
    "section": "Application exercise",
    "text": "Application exercise\nUsing the dataset from the lecture (code provided above to access), select your own predictors and fit, interpret, and assess a multinomial model. Select at least one categorical predictor and at least one continuous predictor (do not use only ses and write since those were the two used in the lecture).\n\nPractice writing out the separate logistic models for each level of the outcome\nWrite interpretations for the coefficient estimates and 95% confidence intervals\nAssess the model with the confusion matrix metrics\nGenerate the plot of the predicted probabilities"
  },
  {
    "objectID": "materials/unit2/logisticmetrics.html",
    "href": "materials/unit2/logisticmetrics.html",
    "title": "10.10: Logistic Regression assessment",
    "section": "",
    "text": "Identify which metrics from linear regression can be extended to logistic regression and why\nAssess a logistic regression model with a confusion matrix\nExplain what an ROC curve shows and generate one in R"
  },
  {
    "objectID": "materials/unit2/logisticmetrics.html#classwise-videos",
    "href": "materials/unit2/logisticmetrics.html#classwise-videos",
    "title": "10.10: Logistic Regression assessment",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nIf you’d like to run the code yourself as you go through the lecture, you can download the pumpkin seeds dataset at this link. Note that the ROC curve on the last slide of the second video uses a model with only Area and Perimeter as predictors, but the confusion matrix is based on the model that was used in video 1, which uses Area, Perimeter, Major axis length, and Solidity as predictors.\n\n\n\nSupplemental resource:\nResource on interpreting interactions"
  },
  {
    "objectID": "materials/unit2/logisticmetrics.html#textbook",
    "href": "materials/unit2/logisticmetrics.html#textbook",
    "title": "10.10: Logistic Regression assessment",
    "section": "Textbook",
    "text": "Textbook\nISLR doesn’t explicitly cover metrics for logistic regression, but section 4.4.2 describes some of the same concepts (confusion matrix, sensitivity and specificity, ROC curve). Start on page 148."
  },
  {
    "objectID": "materials/unit2/logisticmetrics.html#application-exercise",
    "href": "materials/unit2/logisticmetrics.html#application-exercise",
    "title": "10.10: Logistic Regression assessment",
    "section": "Application exercise",
    "text": "Application exercise\nGroups for this week\nGo through the logistic regression lab in ISLR: 4.7.1 and 4.7.2\nAdd: Generate the ROC curve"
  },
  {
    "objectID": "materials/unit2/poisson.html",
    "href": "materials/unit2/poisson.html",
    "title": "10.26: Poisson regression",
    "section": "",
    "text": "Identify when to use a poisson regression model\nInterpret a poisson regression model\nGenerate a poisson regression model in R"
  },
  {
    "objectID": "materials/unit2/poisson.html#classwise-videos",
    "href": "materials/unit2/poisson.html#classwise-videos",
    "title": "10.26: Poisson regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nIf you want to type the code as you follow along the lecture, you can use the following code to load the data:\n\npdat <- read.csv(\"https://stats.idre.ucla.edu/stat/data/poisson_sim.csv\")"
  },
  {
    "objectID": "materials/unit2/poisson.html#textbook",
    "href": "materials/unit2/poisson.html#textbook",
    "title": "10.26: Poisson regression",
    "section": "Textbook",
    "text": "Textbook\nISLR 4.6.2"
  },
  {
    "objectID": "materials/unit2/poisson.html#application-exercise",
    "href": "materials/unit2/poisson.html#application-exercise",
    "title": "10.26: Poisson regression",
    "section": "Application exercise",
    "text": "Application exercise\nGroups for this week\nISLR Lab 4.7.7\nWrite interpretations for a few of the coefficient estimates (use the lecture slide titled “Interpretation” as a guide)"
  },
  {
    "objectID": "materials/unit2/logisticintro.html",
    "href": "materials/unit2/logisticintro.html",
    "title": "10.3: Introduction to GLMs",
    "section": "",
    "text": "describe why linear regression won’t work for a binary variable\ndescribe the purpose of a link function\ncompute an odds ratio from a 2x2 table"
  },
  {
    "objectID": "materials/unit2/logisticintro.html#classwise-videos",
    "href": "materials/unit2/logisticintro.html#classwise-videos",
    "title": "10.3: Introduction to GLMs",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThese videos cover a few concepts that will lay the groundwork for logistic regression. We are not fitting the model yet; we will do that in the next set of videos.\nThe first video describes why we need generalized linear models (and specifically logistic regression) and some basic GLM terminology.\n\nBernoulli distribution video\nThe second video introduces odds ratios, which we will need to understand to interpret logistic regression coefficients."
  },
  {
    "objectID": "materials/unit2/logisticintro.html#textbook",
    "href": "materials/unit2/logisticintro.html#textbook",
    "title": "10.3: Introduction to GLMs",
    "section": "Textbook",
    "text": "Textbook\nISLR 4.2, 4.3 intro and 4.3.1"
  },
  {
    "objectID": "materials/unit2/logisticintro.html#application-exercise",
    "href": "materials/unit2/logisticintro.html#application-exercise",
    "title": "10.3: Introduction to GLMs",
    "section": "Application exercise",
    "text": "Application exercise\nGroups for this week\n\nComprehension questions\n\nIn logistic regression, which distribution is assumed for the outcome Y?\nWhat is a link function?\nWhy do we use link functions?\nWhy do we use log odds instead of directly modeling \\(Y\\) or \\(p\\)?\nHow do we define odds?\n\n\n\nPractice problem (you don’t need to use R)\nA study is conducted to assess the effectiveness of a new drug to treat back pain. 735 participants first rate their baseline pain level. 366 are then assigned to the experimental drug and everyone else is assigned to the placebo group (participants do not know which group they are in). After 2 weeks, participants rate their level of back pain again. Responses are compared to initial ratings and participants are grouped into either \"decreased pain\" or \"increase/no change.\" 482 participants experienced decreased pain, of which 289 were in the experimental drug group.\n\nDraw the 2x2 table for this problem\nCalculate the probability of decreased pain in the experimental drug group and the placebo group\nCalculate the odds ratio of decreased pain for the experimental group compared to the placebo group\nWrite a sentence to interpret the odds ratio in the context of the problem\nIf we were to conduct a hypothesis test to assess statistical significance of the odds ratio, what should the null value be?\n\nWrite your own example relevant to your domain of interest.\n\n\nAnswer\n\n\n\n\nReduced pain\nInc/no change\n\n\n\n\nDrug\n289\n77\n\n\nPlacebo\n193\n176\n\n\n\nP(Red|Drug) = 289/366 = 0.79\nP(Red|Placebo) = 193/369 = 0.52\nOdds(Red|Drug) = 0.8/0.2 = 3.76\nOdds(Red|Placebo) = 0.52/0.48 = 1.08\nOR = 3.76/1.08 = 3.48\n“The odds of reduced pain are 3.42 times higher in the experimental drug group than the placebo group.”"
  },
  {
    "objectID": "materials/unit2/logisticestimation.html",
    "href": "materials/unit2/logisticestimation.html",
    "title": "10.5: Logistic Regression estimation and interpretation",
    "section": "",
    "text": "Describe the estimation procedure for a logistic regression model\nInterpret coefficients, confidence intervals, and p-values in logistic regression\nGenerate predictions from a logistic regression model"
  },
  {
    "objectID": "materials/unit2/logisticestimation.html#classwise-videos",
    "href": "materials/unit2/logisticestimation.html#classwise-videos",
    "title": "10.5: Logistic Regression estimation and interpretation",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\n\n\nSupplemental videos:\nMaximum likelihood vs least squares in linear regression\nLogistic regression: the basics\nLogistic regression: likelihood and deviance"
  },
  {
    "objectID": "materials/unit2/logisticestimation.html#textbook",
    "href": "materials/unit2/logisticestimation.html#textbook",
    "title": "10.5: Logistic Regression estimation and interpretation",
    "section": "Textbook",
    "text": "Textbook\nISLR 4.3.2-4.3.4"
  },
  {
    "objectID": "materials/unit2/logisticestimation.html#application-exercise",
    "href": "materials/unit2/logisticestimation.html#application-exercise",
    "title": "10.5: Logistic Regression estimation and interpretation",
    "section": "Application exercise",
    "text": "Application exercise\nGroups for this week\nThis exercise uses a dataset that contains information on patients and whether or not they were diagnosed with heart disease.\nSource and data dictionary\nKaggle link (may have more info on variables)\nRead in the data:\n\nheart <- read.csv(\"https://raw.githubusercontent.com/anlane611/datasets/main/heart.csv\")\n\n\nExplore the data. Use the data dictionary to determine which variables are numeric and which are categorical. Create factor variables for the categorical variables.\nProvide summary statistics (N and %) for the outcome variable\nCalculate summary statistics for those with and without heart disease for the following variables: age, sex, chest pain type, cholesterol. (which summary statistics are appropriate for each variable?)\nFit a logistic regression model regressing heart disease status on the predictors listed in #3.\n\nWhich variables are significantly associated with heart disease status?\nWhat are the reference levels for the categorical variables?\nWrite interpretations for the coefficient estimates. Interpret the coefficient estimates in terms of log odds and odds/odds ratios.\nObtain confidence intervals for the coefficient estimates on the log odds and the odds scale. Write interpretations.\n\n\n\nInterpretation example\n\nlogistic_mod <- glm(factor(target)~age+factor(sex)+factor(cp)+chol,\n                    data=heart,\n                    family=\"binomial\")\nsummary(logistic_mod)\n\n\nCall:\nglm(formula = factor(target) ~ age + factor(sex) + factor(cp) + \n    chol, family = \"binomial\", data = heart)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3725  -0.7048   0.2500   0.7283   2.3014  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   4.996949   1.272158   3.928 8.57e-05 ***\nage          -0.063873   0.017857  -3.577 0.000348 ***\nfactor(sex)1 -1.893397   0.362270  -5.226 1.73e-07 ***\nfactor(cp)1   2.539393   0.448455   5.663 1.49e-08 ***\nfactor(cp)2   2.369649   0.356264   6.651 2.90e-11 ***\nfactor(cp)3   2.239028   0.536138   4.176 2.96e-05 ***\nchol         -0.004843   0.002860  -1.693 0.090421 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 417.64  on 302  degrees of freedom\nResidual deviance: 290.08  on 296  degrees of freedom\nAIC: 304.08\n\nNumber of Fisher Scoring iterations: 5\n\nexp(coef(logistic_mod))\n\n (Intercept)          age factor(sex)1  factor(cp)1  factor(cp)2  factor(cp)3 \n 147.9610497    0.9381237    0.1505595   12.6719713   10.6936382    9.3842018 \n        chol \n   0.9951684 \n\nconfint(logistic_mod)\n\nWaiting for profiling to be done...\n\n\n                   2.5 %        97.5 %\n(Intercept)   2.56601978  7.5719389233\nage          -0.09988456 -0.0296383710\nfactor(sex)1 -2.63098019 -1.2062295548\nfactor(cp)1   1.69939388  3.4701380328\nfactor(cp)2   1.69363365  3.0951948249\nfactor(cp)3   1.22495261  3.3471173833\nchol         -0.01052805  0.0007980208\n\nexp(confint(logistic_mod))\n\nWaiting for profiling to be done...\n\n\n                   2.5 %       97.5 %\n(Intercept)  13.01392295 1942.9037732\nage           0.90494188    0.9707965\nfactor(sex)1  0.07200785    0.2993237\nfactor(cp)1   5.47063055   32.1411787\nfactor(cp)2   5.43920900   22.0915421\nfactor(cp)3   3.40400477   28.4206895\nchol          0.98952718    1.0007983\n\n\nLog odds scale:\nWith each additional year, the log odds of heart disease decrease by 0.06, all else held constant.\nThe log odds of heart disease for males are 1.89 lower than the log odds of heart disease for females.\nWe are 95% confident that the true difference in log odds of heart disease between males and females is between -2.6 and -1.2.\nOdds/odds ratio scale:\nWith each additional year, the odds of heart disease decrease 0.94 times (or: the odds decrease by 6%).\nThe odds of heart disease for males are .15 times the odds of heart disease for females (or: the odds are 85% lower).\nWe are 95% confidence that the true odds ratio of heart disease for males to females is between 0.07 and 0.3."
  },
  {
    "objectID": "materials/unit2/ordinal.html",
    "href": "materials/unit2/ordinal.html",
    "title": "10.24: Ordinal regression",
    "section": "",
    "text": "Identify when to use an ordinal regression model\nInterpret an ordinal regression model\nGenerate an ordinal regression model in R"
  },
  {
    "objectID": "materials/unit2/ordinal.html#classwise-videos",
    "href": "materials/unit2/ordinal.html#classwise-videos",
    "title": "10.24: Ordinal regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nDr. Väisänan does a great job of explaining ordinal regression, though the code is in Stata. The lab exercise in class will introduce the R code."
  },
  {
    "objectID": "materials/unit2/ordinal.html#textbook",
    "href": "materials/unit2/ordinal.html#textbook",
    "title": "10.24: Ordinal regression",
    "section": "Textbook",
    "text": "Textbook\nISLR does not cover ordinal regression."
  },
  {
    "objectID": "materials/unit2/ordinal.html#application-exercise",
    "href": "materials/unit2/ordinal.html#application-exercise",
    "title": "10.24: Ordinal regression",
    "section": "Application exercise",
    "text": "Application exercise\nGroups for this week\n\nData\nA study looks at factors that influence the decision of whether to apply to graduate school. College juniors are asked if they are unlikely, somewhat likely, or very likely to apply to graduate school.\nSource: https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/\nUse the code below to access the data:\n\nlibrary(foreign) #package to access data type\nlibrary(MASS) #package for model\ndat <- read.dta(\"https://stats.idre.ucla.edu/stat/data/ologit.dta\")\n\n\nData dictionary:\n\napply: response to question “how likely are you to apply to graduate school?” with 3 options: very likely, somewhat likely, unlikely\npared: parental education status (1=at least one parent has a graduate degree, 0 otherwise)\npublic: undergraduate institution type (1=publis, 0=private)\ngpa: current undergraduate GPA (4.0 scale)\n\nTake a glimpse of the data. What is the outcome?\nCalculate some summary statistics for the data. How many students are in each category of apply? What is the average GPA for each category of apply?\n\nNote: For a table showing the number of each parental education status and institution type per level of apply, you can either use table or count. We have seen the count function before, and table works the same way (it’s just not a tidyverse function). Specify the two variables within the function, where the first specified variable will show up in the row of the table and the second variable will show up in the columns (e.g., table(dat$pared, dat$apply)\n\n\n\n\nOrdinal regression model (AKA proportional odds model or cumulative logit model)\nWe can fit the model using the polr function in the MASS package. Note that the syntax is the same as what we’ve seen before, but we don’t need to specify family like we do with glm, because the polr function is specialized for the ordinal model. The Hess=TRUE option just stores the necessary information in the ord_mod object for us to access the summary information; we will forego the technical details here.\n\nord_mod <- polr(apply ~ pared + public + gpa, data=dat, Hess=TRUE)\nsummary(ord_mod)\n\nCall:\npolr(formula = apply ~ pared + public + gpa, data = dat, Hess = TRUE)\n\nCoefficients:\n          Value Std. Error t value\npared   1.04769     0.2658  3.9418\npublic -0.05879     0.2979 -0.1974\ngpa     0.61594     0.2606  2.3632\n\nIntercepts:\n                            Value   Std. Error t value\nunlikely|somewhat likely     2.2039  0.7795     2.8272\nsomewhat likely|very likely  4.2994  0.8043     5.3453\n\nResidual Deviance: 717.0249 \nAIC: 727.0249 \n\n\nRecall from the lecture videos that with the ordinal model, we have the same predictor coefficients for each level of the outcome, but different intercepts. This is why we see two components to the summary output: the Coefficients table and the Intercepts table.\nNotice that the output does not provide p-values by default. We can manually calculate them ourselves and then create a table to show the estimates, standard errors, t values, and p values:\n\npvals <- pnorm(-abs(summary(ord_mod)$coef[,\"t value\"]))*2\nctable <- cbind(summary(ord_mod)$coef,pvals)\n\nctable\n\n                                  Value Std. Error    t value        pvals\npared                        1.04769010  0.2657894  3.9418050 8.087072e-05\npublic                      -0.05878572  0.2978614 -0.1973593 8.435464e-01\ngpa                          0.61594057  0.2606340  2.3632399 1.811594e-02\nunlikely|somewhat likely     2.20391473  0.7795455  2.8271792 4.696004e-03\nsomewhat likely|very likely  4.29936315  0.8043267  5.3452947 9.027008e-08\n\n\nLike other models we have seen, the intercepts are not typically the focus of the interpretations. Let’s focus on interpreting the coefficient estimates. First, let’s exponentiate the estimates and confidence intervals to interpret on the odds ratio scale.\n\nexp_coefs <- exp(cbind(OR=coef(ord_mod),confint(ord_mod)))\n\nWaiting for profiling to be done...\n\n\nWe can interpret the coefficient estimate of pared as follows:\nFor students whose parents did attend college, the odds of being more likely (i.e., very or somewhat likely versus unlikely) to apply to graduate school is 2.85 times that of students whose parents did not go to college, holding constant all other variables.\nWrite the interpretations for the other two predictor variables\nGo Further: What if you wanted to interpret the gpa variable per 0.1 increase instead of per 1.0 unit increase?\n\n\nAssessment\nWe can access predicted probabilities of being in each category:\n\nhead(ord_mod$fitted.values)\n\n   unlikely somewhat likely very likely\n1 0.5488310       0.3593310  0.09183798\n2 0.3055632       0.4759496  0.21848725\n3 0.2293835       0.4781951  0.29242138\n4 0.6161224       0.3126888  0.07118879\n5 0.6560149       0.2833901  0.06059505\n6 0.6609240       0.2797117  0.05936430\n\nhead(predict(ord_mod))\n\n[1] unlikely        somewhat likely somewhat likely unlikely       \n[5] unlikely        unlikely       \nLevels: unlikely somewhat likely very likely\n\n\nGenerate the confusion matrix to assess the accuracy of the predictions.\nFinally, we should assess the proportional odds assumption. To do this, we can compare the predicted probabilities using the multinomial model, which is a more precise model, to the predicted probabilities with the ordinal model. Note that this is a subjective process because it is difficult to know how different the predicted probabilities should be to conclude that the assumption is violated. It is also useful to think through whether or not it is reasonable to assume that the odds of being in one category vs another would increase proportionally.\nTo generate predictions, let’s create a new data frame with different combinations of the predictor values. It is typically easiest to use different combinations of the categorical variables and hold the continuous predictors constant.\n\nnew.data <- data.frame(pared=c(0,1,0,1),\n                       gpa=mean(dat$gpa),\n                       public=c(0,1,1,0))\n\nThe new data contains a constant value of GPA and each unique combination of the values of parental education and institution type\n\nnew.data\n\n  pared      gpa public\n1     0 2.998925      0\n2     1 2.998925      1\n3     0 2.998925      1\n4     1 2.998925      0\n\n\nNow we can compare predicted probabilities from the ordinal model and the multinomial model\n\nlibrary(nnet) #package for multinomial model\nmult_mod <- multinom(apply~pared+gpa+public,\n                     data=dat)\n\n# weights:  15 (8 variable)\ninitial  value 439.444915 \niter  10 value 357.012275\nfinal  value 356.996982 \nconverged\n\npredict(ord_mod, new.data, type=\"probs\")\n\n   unlikely somewhat likely very likely\n1 0.5882547       0.3324677  0.07927756\n2 0.3470234       0.4650134  0.18796324\n3 0.6024157       0.3224929  0.07509137\n4 0.3338251       0.4690740  0.19710087\n\npredict(mult_mod, new.data, type=\"probs\")\n\n   unlikely somewhat likely very likely\n1 0.5840849       0.3426999   0.0732152\n2 0.3690459       0.3689135   0.2620406\n3 0.6387143       0.2465215   0.1147642\n4 0.3316785       0.5040241   0.1642974\n\n\nNotice that the predicted probabilities for the unlikely category are very similar for both models. We do see some differences for the other two categories, but overall, I would conclude that we do not have strong evidence that the proportional odds assumption is violated.\nYou may also want to generate the confusion matrix for the multinomial model and see how it compares to the confusion matrix you generated for the ordinal model."
  },
  {
    "objectID": "materials/unit3/missingdata.html",
    "href": "materials/unit3/missingdata.html",
    "title": "11.7: Missing Data",
    "section": "",
    "text": "Identify 3 mechanisms of missingness\nDescribe 5 imputation methods"
  },
  {
    "objectID": "materials/unit3/missingdata.html#the-problem-of-missingness",
    "href": "materials/unit3/missingdata.html#the-problem-of-missingness",
    "title": "11.7: Missing Data",
    "section": "The Problem of Missingness",
    "text": "The Problem of Missingness\n\nMissing data is a common problem\nAlways start by exploring the missingness!\n\nNumber/proportion of observations with any missing data?\nMissing in one or more variables?\nMissing in outcome, predictors, or both?\nPattern of missingness? (e.g., \\(X_1\\) always missing when \\(X_2=1\\) ?)\n\nEven the best analysis cannot make up for poor study design/data collection"
  },
  {
    "objectID": "materials/unit3/missingdata.html#missing-data-mechanisms",
    "href": "materials/unit3/missingdata.html#missing-data-mechanisms",
    "title": "11.7: Missing Data",
    "section": "Missing Data Mechanisms",
    "text": "Missing Data Mechanisms\n\nMissing completely at random (MCAR)\n\n\nReason for missingness does not depend on the values of the observed data\nEach observation has an equal probability of missingness\nExample: A survey has a front and back, and some participants have missing data for the questions on the back page\n\n\nMissing at random (MAR)\n\n\nReason for missingness depends on the values of the observed data\nProbability of missingness is the same for each participant conditional on observed variables\nExample: Some responses for a survey question about income are missing, but the survey includes questions about age, and younger people are less likely to answer income questions than older people\n\n\nMissing not at random (MNAR)\n\n\nReason for missingness depends on the actual values of the missing data, or unobserved predictors\nExample: People who have higher income are less likely to respond to income-related questions\n\nHow can we tell which mechanism is present?\nIn general, we don’t know, and there is not a statistical way to tell\n\nRare that data are MCAR, though we sometimes assume they are\nPossible, perhaps likely that data are MNAR, but difficult to account for this\nGenerally assume/hope that data are MAR"
  },
  {
    "objectID": "materials/unit3/missingdata.html#types-of-imputation",
    "href": "materials/unit3/missingdata.html#types-of-imputation",
    "title": "11.7: Missing Data",
    "section": "Types of Imputation",
    "text": "Types of Imputation\nIn your group, research your assigned imputation method and create 1-2 slides in this google slide deck with the following information:\n\nExplain the method(s) conceptually\nAddress the pros and cons of your method(s)\nShow how you can implement the method in R using the bikeshare dataset that contains simulated missingness (use the code below to access the data). After imputing the missing values with your assigned method(s), compare the results of the model without missingness (shown below) to the results obtained with your imputed dataset(s).\n\nNOTE: Implement the methods with the basic R functions that we’ve used in the course such as lm. Do not use the MICE package to implement the methods.\nModel using the complete dataset without missingness:\n\n## use this code to access the data that contains missing values\nbikedat.miss <- read.csv(\"https://raw.githubusercontent.com/anlane611/datasets/main/bike_miss.csv\", row.names = 1)\n\n\n## compare results to the model that uses the full dataset (use the same variables)\nbikedat <- read.csv(\"https://raw.githubusercontent.com/anlane611/datasets/main/bike_full.csv\")\n\nsummary(glm(bikers ~ windspeed + hum + temp, family=\"poisson\", data=bikedat))\n\n\nImputation methods\n\nMean/median imputation, complete case analysis\nHot deck imputation, cold deck imputation (you do not need to implement these in R. Focus on the concepts and brainstorm ways that you might implement them)\nRegression imputation - deterministic\nStochastic regression imputation - random\nMultiple imputation (you do not need to implement this in R. Focus on clearly describing the steps)"
  },
  {
    "objectID": "materials/unit3/missingdata.html#textbook",
    "href": "materials/unit3/missingdata.html#textbook",
    "title": "11.7: Missing Data",
    "section": "Textbook",
    "text": "Textbook\nFor more information about missing data, see chapter 3 in Regression Modeling Strategies by Frank E Harrell Jr"
  },
  {
    "objectID": "materials/unit3/missingdata.html#application-exercise",
    "href": "materials/unit3/missingdata.html#application-exercise",
    "title": "11.7: Missing Data",
    "section": "Application exercise",
    "text": "Application exercise\nFor this exercise, we will use the titanic3 dataset in the Hmisc library. The dataset contains information about passengers on the Titanic, including whether or not the passenger survived.\n\nlibrary(tidyverse)\nlibrary(Hmisc)\ngetHdata(titanic3)\n\nFirst, fit a logistic regression model regressing the survived outcome on the predictors pclass, sex, parch, and age using complete case analysis (the default method in R). Note that parch is the number of parents/children the passenger has aboard. What is the sample size that is used for the model?\nNow, let’s explore the missing data. The Hmisc package has some useful functions for exploring missing data. First, we can generate a plot to show the fraction of missing values for each variable.\n\nna.patterns <- naclus(titanic3)\n\nnaplot(na.patterns, 'na per var')\n\nNext, we can generate a plot that shows any hierarchical structure of the missing data.\n\nplot(na.patterns)\n\nThis plot indicates that the variable age is missing when body and/or home.dest are also missing. Confirm that this is true at least for the body variable.\nIt is also useful to examine the characteristics of passengers that have missing data for the age variable. Fit a logistic regression model where the outcome is an indicator for whether or not the age variable is missing. Regress this outcome on sex, pclass, survived, and parch. Focusing on the p-values and the signs of the coefficient estimates, what do you observe about the pattern of missingness in the age variable?\n\nMultiple imputation with the mice package\nRecall the general 3-step process of multiple imputation:\n\nReplicate the dataset \\(m\\) times and impute the missing values on each of the \\(m\\) datasets. Note that the imputation method must involve some degree of randomness so that the \\(m\\) complete datasets are not all the same.\nPerform the analysis on each of the \\(m\\) datasets\nCombine the analysis results across the \\(m\\) datasets\n\nThe options in the mice function indicate the number of \\(m\\) replicated datasets (5 is the default) and the imputation method to use. “pmm” refers to predictive mean matching. Predictive mean matching combines the regression method and the hot deck imputation that we covered last week by taking a donor value from the observation with the predicted value closest to the predicted value of the observation with missing data. This is beneficial because the imputed values will still be in a plausible range.\nLet’s use a subset that only contains the predictors age, pclass, parch, sex, and the outcome survived.\n\nlibrary(mice)\nlibrary(sjlabelled)\nlibrary(tidyverse)\n\ntitanic.sub <- titanic3 |> select(c(\"age\",\"pclass\",\"parch\",\"sex\",\"survived\"))\ntitanic.sub <- unlabel(titanic.sub) #unlabel the data (labels cause problem for the mice function)\ntitanic.imp <- mice(titanic.sub, m=5, method=\"pmm\", print=FALSE)\n\nThe titanic.imp list contains a lot of information about the imputed values. The imp element of the list contains the actual imputed values, with an additional index for each variable that has missing data. Age is the only variable in our set with missing values. Note the dimension of this matrix. Each row represents an observation, and each column contains one of the \\(m=5\\) imputed values.\n\ndim(titanic.imp$imp$age)\n\nNow let’s visualize the distribution of the observed and imputed values of age. What do you observe in this plot?\n\ntitanic.comp <- complete(titanic.imp, \"long\", include=TRUE) #stack the imputed values into one variable and include the observed values\n\ntitanic.comp$age.NA <- cci(titanic3$age) #create an indicator for missingness\n\nggplot(titanic.comp, aes(x= .imp, y=age, col=age.NA))+\n  geom_jitter()\n\nNow we can use the with function to fit the regression model on each of the imputed datasets\n\nwith(titanic.imp, glm(survived ~ pclass + age + sex + parch, family=\"binomial\"))\n\nFinally, we can combine the results from these models using the pool function. How do the results compare to the complete case model?\n\nimp.mods <- with(titanic.imp, glm(survived ~ pclass + age + sex + parch, family=\"binomial\"))\nsummary(pool(imp.mods))"
  },
  {
    "objectID": "materials/unit3/missingdata.html#references",
    "href": "materials/unit3/missingdata.html#references",
    "title": "11.7: Missing Data",
    "section": "References",
    "text": "References\nRegression Modeling Strategies by Frank E Harrell Jr (Book linked above)\nMultiple Imputation"
  },
  {
    "objectID": "materials/unit3/survival2.html",
    "href": "materials/unit3/survival2.html",
    "title": "11.2: The Cox Proportional Hazards Model",
    "section": "",
    "text": "Define the Hazard function\nDescribe the proportional hazards assumption\nFit a Cox proportional hazards model in R"
  },
  {
    "objectID": "materials/unit3/survival2.html#classwise-videos",
    "href": "materials/unit3/survival2.html#classwise-videos",
    "title": "11.2: The Cox Proportional Hazards Model",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class."
  },
  {
    "objectID": "materials/unit3/survival2.html#textbook",
    "href": "materials/unit3/survival2.html#textbook",
    "title": "11.2: The Cox Proportional Hazards Model",
    "section": "Textbook",
    "text": "Textbook\nISLR 11.5"
  },
  {
    "objectID": "materials/unit3/survival2.html#application-exercise",
    "href": "materials/unit3/survival2.html#application-exercise",
    "title": "11.2: The Cox Proportional Hazards Model",
    "section": "Application exercise",
    "text": "Application exercise\nFor this exercise, we will use the breast cancer data used in the first survival analysis lecture.\nCode book:\n\n\n\nVariable\nDescription\n\n\n\n\npid\npatient identifier\n\n\nage\nage, years\n\n\nmeno\nmenopausal status (0=premenopausal, 1=postmenopausal)\n\n\nsize\ntumor size, mm\n\n\ngrade\ntumor grade\n\n\nnodes\nnumber of positive lymph nodes\n\n\npgr\nprogesterone receptors (fmol/l)\n\n\ner\nestrogen receptors (fmol/l)\n\n\nhormon\nhormonal therapy (0=no, 1=yes)\n\n\nrfstime\nrecurrence-free survival time\n\n\nstatus\n0=alive w/o recurrence, 1=recurrence or death\n\n\n\nFirst, get a glimpse of the data and calculate some summary statistics. For example, what percentage of observations are censored?\nUse the code below to generate Kaplan-Meier curves and perform the log-rank test.\n\nlibrary(survival)\nbreastcancer <- read.csv(\"https://raw.githubusercontent.com/anlane611/datasets/main/breastcancer.csv\", row.names = 1)\nattach(breastcancer)\n\n\n#Kaplan-Meier curve for all patients\nsurv.fit <- survfit(Surv(rfstime,status)~1)\nplot(surv.fit, xlab=\"Days\", ylab=\"Estimated probability of survival\")\n\n\n\n#Kaplan-Meier curve by treatment group\nsurv.fit.trt <- survfit(Surv(rfstime, status) ~ factor(hormon))\nplot(surv.fit.trt, xlab=\"Days\", ylab=\"Estimated probability of survival\",\n     col=c(2,4))\nlegend(\"topright\", c(\"Trt\", \"No Trt\"), col=c(4,2), lty=1)\n\n\n\n#Log-rank test\nsurvdiff(Surv(rfstime, status) ~ factor(hormon))\n\nCall:\nsurvdiff(formula = Surv(rfstime, status) ~ factor(hormon))\n\n                   N Observed Expected (O-E)^2/E (O-E)^2/V\nfactor(hormon)=0 440      205      180      3.37      8.56\nfactor(hormon)=1 246       94      119      5.12      8.56\n\n Chisq= 8.6  on 1 degrees of freedom, p= 0.003 \n\n\nNow, let’s fit a Cox proportional hazards model. Let’s start by just using the main predictor of interest, hormone therapy treatment. We can use the coxph function in the survival package to fit the model.\n\nfit.cox <- coxph(Surv(rfstime, status) ~ factor(hormon))\nsummary(fit.cox)\n\nCall:\ncoxph(formula = Surv(rfstime, status) ~ factor(hormon))\n\n  n= 686, number of events= 299 \n\n                   coef exp(coef) se(coef)      z Pr(>|z|)   \nfactor(hormon)1 -0.3640    0.6949   0.1250 -2.911   0.0036 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                exp(coef) exp(-coef) lower .95 upper .95\nfactor(hormon)1    0.6949      1.439    0.5438    0.8879\n\nConcordance= 0.543  (se = 0.014 )\nLikelihood ratio test= 8.82  on 1 df,   p=0.003\nWald test            = 8.47  on 1 df,   p=0.004\nScore (logrank) test = 8.57  on 1 df,   p=0.003\n\n\nExamine the summary output for the model with only hormonal treatment group as a predictor.\n\nWhat are the meanings and values of n and number of events?\nHow does the p-value of the hormonal treatment variable compare to the p-value obtained from the log-rank test?\n\nNote that the exponentiated value of the coefficient estimate is already provided in the summary output. We can interpret exp(coef)=0.7 by saying the risk of death/recurrence for the treatment group is 30% lower than the risk of death/recurrence for the non-experimental treatment group.\nCalculate the mean survival time for each treatment group without considering censoring. What is the difference between the groups and how does this compare to the results obtained with the model?\nRecall that the Cox model relies on the key assumption of proportional hazards: the ratio of hazards is constant over time. Let’s check this assumption for the model. We can do this using the cox.zph function in the survival package. This generates a p-value for each predictor to test the proportional hazards assumption. A significant p-value here indicates that the assumption may be violated.\nThe GLOBAL line performs a test for the full model. Here, since we only have one predictor, the global test is the same as the predictor test.\n\ntest.ph <- cox.zph(fit.cox)\ntest.ph\n\n               chisq df    p\nfactor(hormon) 0.227  1 0.63\nGLOBAL         0.227  1 0.63\n\n\nWe can also look at a plot of the Schoenfeld Residuals, which are a residual measure unique to survival models that are commonly used to test the proportional hazards assumption. A straight line indicates proportional hazards. Here, we see a fairly straight line with some veering off at later time points.\n\nplot(test.ph)\n\n\n\n\nNow, add a few predictors to the model that you think are most relevant to accurately assess the relationship between treatment and survival time.\n\nFit the model and interpret the coefficient estimates. Which predictor(s) are statistically significant? Controlling for the other predictors, is there still a significant relationship between hormonal treatment group and survival time?\nUse the cox.zph function to assess the proportional hazards assumption."
  },
  {
    "objectID": "materials/unit3/survival2.html#additional-practice",
    "href": "materials/unit3/survival2.html#additional-practice",
    "title": "11.2: The Cox Proportional Hazards Model",
    "section": "Additional practice",
    "text": "Additional practice\nLabs in ISLR section 11.8"
  },
  {
    "objectID": "materials/unit3/survival1.html",
    "href": "materials/unit3/survival1.html",
    "title": "10.31: Survival Analysis I",
    "section": "",
    "text": "Give an example of a research question for which survival analysis could be used\nDescribe the purpose of the Kaplan-Meier curve\nGenerate a Kaplan-Meier curve in R"
  },
  {
    "objectID": "materials/unit3/survival1.html#classwise-videos",
    "href": "materials/unit3/survival1.html#classwise-videos",
    "title": "10.31: Survival Analysis I",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class."
  },
  {
    "objectID": "materials/unit3/survival1.html#textbook",
    "href": "materials/unit3/survival1.html#textbook",
    "title": "10.31: Survival Analysis I",
    "section": "Textbook",
    "text": "Textbook\nISLR chapter 11 through section 11.4"
  },
  {
    "objectID": "materials/unit3/survival1.html#application-exercise",
    "href": "materials/unit3/survival1.html#application-exercise",
    "title": "10.31: Survival Analysis I",
    "section": "Application exercise",
    "text": "Application exercise\nISLR Lab 11.8. Stop when it says “Next, we fit the Cox model”\nAs you work through the lab, discuss the following:\n\nWhat does the status variable mean?\nWhat is the outcome?\nWhat does the y-axis of the Kaplan-Meier plot mean?\nWhat do you observe with the Kaplan-Meier plot?\nWhat do you conclude from the log-rank test?\nCreate another Kaplan-Meier plot using a covariate other than sex. Compute the log-rank test. What do you observe from the plot and what do you conclude from the test?"
  },
  {
    "objectID": "materials/unit1/prediction.html",
    "href": "materials/unit1/prediction.html",
    "title": "9.19 and 9.21: Prediction",
    "section": "",
    "text": "distinguish between inference and predictive modeling\nuse cross validation to assess predictive models"
  },
  {
    "objectID": "materials/unit1/prediction.html#classwise-videos",
    "href": "materials/unit1/prediction.html#classwise-videos",
    "title": "9.19 and 9.21: Prediction",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nHaving technical issues, but you can click the links to watch the videos and download the annotated notes.\nVideo 1: Prediction intro\nVideo 2: Prediction modeling metrics\nVideo 3: Cross validation\nNotes:\nVideo 1 \nVideo 2 \nVideo 3"
  },
  {
    "objectID": "materials/unit1/prediction.html#textbook",
    "href": "materials/unit1/prediction.html#textbook",
    "title": "9.19 and 9.21: Prediction",
    "section": "Textbook",
    "text": "Textbook\nISLR 2.1.1, 2.1.3, 2.2"
  },
  {
    "objectID": "materials/unit1/prediction.html#application-exercise-919",
    "href": "materials/unit1/prediction.html#application-exercise-919",
    "title": "9.19 and 9.21: Prediction",
    "section": "Application Exercise (9/19)",
    "text": "Application Exercise (9/19)\nGroups for today’s exercise\nToday’s exercise will help you to solidify your understanding of (R)MSE and k-fold cross validation by “manually” implementing them in R.\nYou should be familiar with the following coding concepts: writing functions, for loops, and if-else statements. If you are not familiar with how to write these things in R, consult the R for Data Science resource (Functions, Iteration).\nWrite a function that performs \\(K\\)-fold cross validation. The function should take 3 inputs: a dataset, a value of \\(K\\), and an evaluation metric. The options for the evaluation metric should be adjusted \\(R^2\\) , MSE, and RMSE.\nThe end goal is to be able to compare predictive ability of different models. For example, you may want to use your function with the Auto dataset to do the following:\n\nlibrary(ISLR2)\ndata(\"Auto\")\n\n#you can name your function whatever you'd like. Note that to compare different models, we want to use the same metric and value of K. You can specify the models you want to compare within the function. For example, you may want to compare three models with the Auto dataset: mpg regressed on displacement, weight, and acceleration; mpg regressed on displacement, weight, acceleration, and a factor variable for cylinder; and mpg regressed on displacement, weight, acceleration and interaction terms for displacement and factored cylinders and weight and factored cylinders. You can also take the extra step of making the function more general for comparing models, but that is more complicated.\ncrossval(Auto, K=10, metric=\"RMSE\")\n\nYou are welcome to make the function more complex (additional inputs, etc). For example, maybe you’d like your function to take multiple models and return the model with the best metric (lowest MSE/RMSE or highest Adj \\(R^2\\) )\nYou should consider using the following:\n\nthe predict() function takes a model object and “newdata” and returns all of the predicted values. You can use this to calculate test MSE and RMSE. Use the formula for MSE and RMSE and nested functions to calculate each of these in a single line of code. Run ?predict in the console to learn more.\nAdjusted \\(R^2\\) can be accessed in the summary(lm()) output, i.e., summary(mod_object)$adj.r.squared\nThe caret package has a function called createFolds() that you can use in your function to create the \\(K\\) folds in the given dataset. You can also try doing this manually with the sample(), cut(), or split() functions.\n\n\nGoing Further\nIf you have extra time, you can consider some extensions:\n\nAdd function inputs to make it more general. For example, the user could specify models to compare\nUse the trainControl() and train() functions from the caret package to perform k-fold cross validation. Compare the results to what you get using your function.\nSimulate data and use your function to better understand the effects of sample size and value of \\(k\\). The rnorm() function generates a vector of random values from the normal distribution. You can specify the mean and standard deviation of the distribution from which you take random draws. You can then add outliers to your predictors to see the effect of small samples and extreme values in the cross validation splits."
  },
  {
    "objectID": "materials/unit1/prediction.html#application-exercise-921",
    "href": "materials/unit1/prediction.html#application-exercise-921",
    "title": "9.19 and 9.21: Prediction",
    "section": "Application Exercise (9/21)",
    "text": "Application Exercise (9/21)\nUse the same groups that you were in on Tuesday.\nNote: Focus on #1-4. Particularly for folks who are new to stats/R, skip the “go further” parts and come back to them if you have time.\nFor this exercise, we will use the Boston dataset from the ISLR2 package.\nClick here for the data dictionary\nWe want to build a model to predict the median home value from various predictors.\n\nStart by using the data dictionary to determine if any data cleaning needs to be done. Is there any missing data?\nFit the full model. The code below uses the caret package to perform k-fold cross validation and produces RMSE, \\(R^2\\) , and MAE. The trainControl function establishes the method you will use to evaluate your model. In this case, we use the cross validation option for method (“cv”) and set number=10 for 10-fold cross validation. Then, the train function performs 10-fold CV on the indicated model. Note that the model syntax is the same as what we’ve used in lm (the “.” indicates that we want to regress on all variables in the dataset except the outcome). Then we specify method=\"lm\" for a linear model, and trControl=train_control to use the 10-fold CV method we stored in the train_control object. Finally, the print function gives us the model metrics.\n\nGo further: Run ?R2 in the console to find out how caret calculates \\(R^2\\) here. This may help to provide a more intuitive interpretation of out-of-sample \\(R^2\\)\n\n#note that cross validation involves a random sampling component, so we should use a seed for reproducibility\nset.seed(921) \n\ntrain_control <- trainControl(method = \"cv\",\n                                          number = 10)\n\nmod_full <- train(medv ~., data = Boston,\n                     method = \"lm\",\n                     trControl = train_control)\n\n#get model metrics\nprint(mod_full)\n\n\nLook at the diagnostics for the full model. Which assumptions appear to be violated (if any)? Would it help to transform the outcome or predictor variable(s)? Would an interaction term help? If our focus is prediction, how much should we prioritize model interpretability when we’re considering variable transformations?\n\nGo further: There are several R packages that can help efficiently visualize your data. As we’ve seen before, visualizing can help determine if variable transformations/interaction terms may improve the model. You can explore packages like DataExplorer and SmartEDA.\n\nAfter you determine which transformations/interaction terms improve the model diagnostics, perform cross validation again on your new model. Do you notice a reduction in RMSE?\nWe can also use cross validation to perform variable selection. This can help to determine which combination of features leads to the best predictions. The freControl function establishes that we will use linear regression and cross validation. The rfe function performs the variable selection procedure. Using cross validation, we will assess the out-of-sample RMSE for a 1-variable model, 2-variable model, etc, and select the optimal predictors based on the lowest RMSE.\n\nset.seed(921)\n\nctrl <- rfeControl(functions = lmFuncs,\n                   method = \"cv\")\n\n# standardize the predictors so that they are comparable\n# You will need to edit this code if you transformed any variables or added interaction terms\nboston_standardize <- as.data.frame(scale(Boston))\nboston_standardize <- boston_standardize |> select(-c(\"medv\"))\n\nlmProfile <- rfe(boston_standardize, Boston$medv, #specify the X and Y variables\n                 sizes=c(1:12), # specify the number of variables you want to compare. Here we are assessing all possible numbers from 1-12 predictor variables\n                 rfeControl = ctrl)\n\nlmProfile #this gives the model metrics and shows which number of variables has been selected as optimal\npredictors(lmProfile) #this lists the predictors that were selected"
  },
  {
    "objectID": "materials/unit1/prediction.html#key-takeaways",
    "href": "materials/unit1/prediction.html#key-takeaways",
    "title": "9.19 and 9.21: Prediction",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nThe first exercise is designed to help you think through the steps of cross validation. Below is an example function (provided by one of your classmates 😃)\n\n\n#first, a function is written to calculate MSE\nMSE <- function(real_value, estimated_value){\n    result = (1/length(real_value))*sum((real_value-estimated_value)^2)\n    return(result)\n}\n\ncrossval <- function(df, k) { #CV function takes the data & # folds\n  metrics = c()\n  split_lst = df %>% #split the dataset into folds (could also use createFolds)\n    group_by((row_number()-1) %/% (n()/k)) %>%\n    nest %>%\n    pull(data)\n  for (i in 1:k) { #loop through folds\n    test_df <- split_lst[[i]]\n    train_df <- bind_rows(split_lst[-i]) #designates train & test set\n    model <- lm(data=train_df, mpg ~ acceleration + horsepower)\n    #calculate predicted values for MSE\n    preds = predict(model, test_df[c('acceleration', 'horsepower')])\n    mse = MSE(test_df[c('mpg')], preds) #use MSE function \n    metrics <- c(metrics, mse) #store test MSE for all values of k\n  }\n  return(meanMSE=mean(metrics)) #output the mean test MSE\n}\n\ncrossval(df=Auto, k=10) #run the function\n\n\nThe second exericse walks through the implementation of cross validation using the caret package. Note that with prediction problems, we don’t prioritize interpretation of the model. So, there is more flexibility to add variable transformations to improve model diagnostics. The biggest takeaway here was that adding transformations improve model diagnostics and reduce RMSE, thereby improving prediction accuracy of the model.\nWe can also perform variable selection with cross validation, which is a different process than the model selection procedures we introduced last week. Forward/backward/stepwise selection base inclusion decisions on p-values, which is frowned upon in the statistics community. The procedure in this exercise bases variable selection on cross validation and RMSE to improve predictions."
  },
  {
    "objectID": "materials/unit1/introMLR.html",
    "href": "materials/unit1/introMLR.html",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "",
    "text": "distinguish between the simple linear regression model and the multiple linear regression (MLR) model\ninterpret coefficient estimates for continuous and categorical variables in MLR\ninterpret interaction terms in MLR\nfit MLR models in R"
  },
  {
    "objectID": "materials/unit1/introMLR.html#classwise-videos",
    "href": "materials/unit1/introMLR.html#classwise-videos",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nThese videos cover the concepts. We’ll look at how to do these things in R during class on Thursday. If you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nClick this invite link to join the Classwise course: Classwise join link\nIf you have problems with the invite link, try going directly to classwise.org and click “Login” and then “School SSO.” Then you should be able to use your email to access the videos directly on this page or on the classwise site. You do not need to create a new account.\nAfter joining the course, you should be able to view the videos directly from the course website"
  },
  {
    "objectID": "materials/unit1/introMLR.html#textbook",
    "href": "materials/unit1/introMLR.html#textbook",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Textbook",
    "text": "Textbook\nISLR sections 3.1-3.3"
  },
  {
    "objectID": "materials/unit1/introMLR.html#survey",
    "href": "materials/unit1/introMLR.html#survey",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Survey",
    "text": "Survey\nClick here to complete the survey"
  },
  {
    "objectID": "materials/unit1/introMLR.html#class-code",
    "href": "materials/unit1/introMLR.html#class-code",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Class code",
    "text": "Class code\nIn RStudio, run the following in the console:\n\ndownload.file(\"https://raw.githubusercontent.com/anlane611/702-classcode/main/introtoMLRcode.qmd\", destfile=\"introtomlrcode.qmd\")"
  },
  {
    "objectID": "materials/unit1/introMLR.html#application-exercise",
    "href": "materials/unit1/introMLR.html#application-exercise",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Application exercise",
    "text": "Application exercise\nPalmer penguins data\nData were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\nUse the glimpse() output to determine the following:\n\nsample size and number of variables\nwhich variables are categorical and which are numeric? is there any missing data? are the categorical variables stored appropriately?\n\nSelect an appropriate outcome and primary (continuous) predictor of interest.\n\ngenerate a scatter plot for the two variables (remember to label your axes!)\ncolor the scatter plot by sex. Does an interaction term seem appropriate?\ncolor the scatter plot by species. Does an interaction term seem appropriate?\n\nFit a model regressing the outcome variable you selected onto the primary predictor of interest, sex, and species.\n\nWrite interpretations for the coefficient estimates, p-values, and confidence intervals\nIs the species variable statistically significant? Conduct the appropriate test.\n\nAdd an interaction term that seems appropriate based on the EDA from #2. Interpret the p-value and coefficient estimate for the interaction term in the context of the dataset."
  },
  {
    "objectID": "materials/unit1/miscMLR.html",
    "href": "materials/unit1/miscMLR.html",
    "title": "9.26: Wrapping up MLR",
    "section": "",
    "text": "describe the basics of the bias-variance tradeoff\ndescribe Simpson’s paradox\nexplain when it is useful to standardize predictors in linear regression"
  },
  {
    "objectID": "materials/unit1/miscMLR.html#classwise-videos",
    "href": "materials/unit1/miscMLR.html#classwise-videos",
    "title": "9.26: Wrapping up MLR",
    "section": "Classwise videos",
    "text": "Classwise videos\nThese videos cover three miscellaneous topics to wrap up our conversation about linear regression.\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThe first video introduces the bias-variance tradeoff. This is more relevant to machine learning than inferential statistical modeling, so you will learn more about it next semester. However, I want to go ahead and introduce the concept.\n\nThe second video discusses Simpson’s paradox. This relates to the concept of confounding and emphasizes the importance of using multiple linear regression rather than simple linear regression. The video also covers tidyverse functions group_by() and count() which will be useful as you explore data.\n\nFinally, see this tutorial on standardizing predictors. Focus on the z-score and centering, and the sections on when and when not to standardize. Note that this is much more relevant when prediction is the goal. Standardizing predictors changes the interpretation of the coefficient estimates; therefore, when inference/interpreting estimates the goal, we generally do not standardize."
  },
  {
    "objectID": "materials/unit1/miscMLR.html#textbook",
    "href": "materials/unit1/miscMLR.html#textbook",
    "title": "9.26: Wrapping up MLR",
    "section": "Textbook",
    "text": "Textbook\nBias-variance tradeoff: ISLR 2.2.2"
  },
  {
    "objectID": "materials/unit1/miscMLR.html#application-exercise",
    "href": "materials/unit1/miscMLR.html#application-exercise",
    "title": "9.26: Wrapping up MLR",
    "section": "Application Exercise",
    "text": "Application Exercise\nSimpson’s Paradox\n\nAir travelers would like their flights to be on time. Airlines collect data about on-time arrivals and report them to the Department of Transportation (DoT). Here is one month’s data for flights for two airlines from five western cities.\n\n\n\n\nAirline\nOn time\nLate\n\n\n\n\nAlaska Airlines\n3274\n501\n\n\nAmerica West\n6438\n787\n\n\n\n\nCalculate the percentage of flights that are on time for each airline and the percentage of flights that are late for each airline.\nBased on the calculated percentages, which airline has the better on-time record?\n\nIn the table below, the data are broken down by city.\n\n\n\nCity\nAA - on time\nAA - late\nAW - on time\nAW - late\n\n\n\n\nLos Angeles\n497\n62\n694\n117\n\n\nPhoenix\n221\n12\n4840\n415\n\n\nSan Diego\n212\n20\n383\n65\n\n\nSan Francisco\n503\n102\n320\n129\n\n\nSeattle\n1841\n305\n201\n61\n\n\nTotal\n3274\n501\n6438\n787\n\n\n\n\nCompute the percentage on-time and percentage late values for each airline and city\nWhich airline has the best on-time record for each city?\n\nLos Angeles:\nPhoenix:\nSan Diego:\nSan Francisco:\nSeattle:\n\nExplain why this is an example of Simpson’s paradox\n\n\nExplain how the following image relates to Simpson’s paradox. \nSimpson’s paradox with COVID vaccination data\n\n\nReferences\nSimpson’s paradox airline activity: http://facweb.cs.depaul.edu/brewster/lsp121/Files/Activity%206-ans.pdf\nSimpson’s paradox image: https://stats.stackexchange.com/questions/478463/examples-of-simpsons-paradox-being-resolved-by-choosing-the-aggregate-data"
  },
  {
    "objectID": "materials/unit1/miscMLR.html#key-takeaways",
    "href": "materials/unit1/miscMLR.html#key-takeaways",
    "title": "9.26: Wrapping up MLR",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nThe key takeaway of this exercise is that aggregated data can mask the relationship between two variables that changes with the inclusion of a third variable. This is one reason that we do multiple linear regression instead of simple linear regression.\nThe exercise also helps to develop statistical literacy. When you see aggregated data/percentages in the news, consider if it might be misleading. Is there a third variable that would help to shed light on the relationship between the two variables?"
  },
  {
    "objectID": "materials/unit1/estimation.html",
    "href": "materials/unit1/estimation.html",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "",
    "text": "define “sum of squared errors”\ndescribe the concept of ordinary least squares\ndescribe (adjusted) \\(R^2\\) and how it relates to model assessment"
  },
  {
    "objectID": "materials/unit1/estimation.html#classwise-videos",
    "href": "materials/unit1/estimation.html#classwise-videos",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nI know many students are having trouble with classwise recognizing videos as completed. I will not count classwise completion grades until we sort out the technical issues.\n\n\nThe third video is optional. This video shows the derivation of the OLS estimators."
  },
  {
    "objectID": "materials/unit1/estimation.html#textbook",
    "href": "materials/unit1/estimation.html#textbook",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Textbook",
    "text": "Textbook\nISLR sections 3.1-3.3"
  },
  {
    "objectID": "materials/unit1/estimation.html#application-exercise-to-complete-during-the-class-meeting",
    "href": "materials/unit1/estimation.html#application-exercise-to-complete-during-the-class-meeting",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Application exercise (to complete during the class meeting)",
    "text": "Application exercise (to complete during the class meeting)\nPalmer penguins data\nData were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\nUse the glimpse() output to determine the following:\n\nsample size and number of variables\nwhich variables are categorical and which are numeric? is there any missing data? are the categorical variables stored appropriately?\n\nSelect an appropriate outcome and primary (continuous) predictor of interest.\n\ngenerate a scatter plot for the two variables (remember to label your axes!)\ncolor the scatter plot by sex. Does an interaction term seem appropriate?\ncolor the scatter plot by species. Does an interaction term seem appropriate?\n\nFit a model regressing the outcome variable you selected onto the primary predictor of interest, sex, and species.\n\nWrite interpretations for the coefficient estimates, p-values, and confidence intervals\nIs the species variable statistically significant? Conduct the appropriate test.\n\nNote: The anova function computes a nested F test:\n\n\n\n\nmod_reduced <- #reduced model object here\nmod_full <- #full model object here\n\nanova(mod_reduced, mod_full, test=\"F\")\n\n\nAdd an interaction term that seems appropriate based on the EDA from #2. Interpret the p-value and coefficient estimate for the interaction term in the context of the dataset.\nInterpret the adjusted \\(R^2\\) value for the model with the interaction term. Compare the value to the adjusted \\(R^2\\) value obtained from a model that does not include the interaction term. What do you conclude from this comparison?\n\n\nNote: You can see the \\(R^2\\) and adjusted \\(R^2\\) values in the summary(model_object) output that we used last week"
  },
  {
    "objectID": "materials/unit1/estimation.html#key-takeaways",
    "href": "materials/unit1/estimation.html#key-takeaways",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nThis will vary depending on the variables you selected, but you probably saw that an interaction term appears to be necessary for the species variable but not necessarily sex. We see this because it appears that the slope is different for at least one species compared to the others.\nWhen an interaction term is meaningful, you should see an increase in the adjusted \\(R^2\\) value for the model with the interaction term compared to the model without. This means that the interaction term increases how much variance of the outcome is explained by the predictors."
  },
  {
    "objectID": "materials/unit1/penalized.html",
    "href": "materials/unit1/penalized.html",
    "title": "9.28: Penalized Regression",
    "section": "",
    "text": "describe why penalized regression methods are useful\nfit and interpret a LASSO regression model"
  },
  {
    "objectID": "materials/unit1/penalized.html#classwise-videos",
    "href": "materials/unit1/penalized.html#classwise-videos",
    "title": "9.28: Penalized Regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThe first video introduces the challenges of high-dimensional data.\n\nThe second video discusses penalized regression with a focus on LASSO."
  },
  {
    "objectID": "materials/unit1/penalized.html#textbook",
    "href": "materials/unit1/penalized.html#textbook",
    "title": "9.28: Penalized Regression",
    "section": "Textbook",
    "text": "Textbook\nShrinkage methods: ISLR 6.2\nConsiderations in high dimensions: ISLR 6.4"
  },
  {
    "objectID": "materials/unit1/penalized.html#application-exercise",
    "href": "materials/unit1/penalized.html#application-exercise",
    "title": "9.28: Penalized Regression",
    "section": "Application exercise",
    "text": "Application exercise\nFollow this tutorial to fit a lasso model with the Boston housing data we used last week (the dataset is in the ISLR2 package). The tutorial does a nice job of building the code piece by piece to connect the concepts we’ve discussed: lasso, standardizing predictors, cross validation, and tuning the lambda parameter. You can skip the “Basic Lasso Regression in R” section and go straight to using the caret package that we’ve used before, though you will also need to install and load the elasticnet package.\n\nGo further\n\nCompare your results to the RMSE you get from least squares estimation\nCompare your results to Ridge regression using method='ridge'"
  },
  {
    "objectID": "materials/unit1/assumptions.html",
    "href": "materials/unit1/assumptions.html",
    "title": "9.07: Addressing the assumptions",
    "section": "",
    "text": "list the four assumptions of MLR\nexplain why we use residual plots to assess the assumptions\ninterpret residual plots"
  },
  {
    "objectID": "materials/unit1/assumptions.html#classwise-videos",
    "href": "materials/unit1/assumptions.html#classwise-videos",
    "title": "9.07: Addressing the assumptions",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nI know many students are having trouble with classwise recognizing videos as completed. I will not count classwise completion grades until we sort out the technical issues."
  },
  {
    "objectID": "materials/unit1/assumptions.html#textbook",
    "href": "materials/unit1/assumptions.html#textbook",
    "title": "9.07: Addressing the assumptions",
    "section": "Textbook",
    "text": "Textbook\nISLR sections 3.1-3.3 (specifically 3.3.3)"
  },
  {
    "objectID": "materials/unit1/assumptions.html#application-exercise",
    "href": "materials/unit1/assumptions.html#application-exercise",
    "title": "9.07: Addressing the assumptions",
    "section": "Application exercise",
    "text": "Application exercise\nAccess the Auto dataset:\n\nlibrary(tidyverse)\nlibrary(ISLR2)\ndata(Auto)\n\n\nUse this page as a data dictionary. Identify which variables are categorical. Are they stored correctly in R? If not, create factor variables.\nFit a model regressing mpg on horsepower, displacement, acceleration, cylinders, and origin.\n\nWhat do you notice about the standard errors of the cylinders levels compared to the other predictors?\nUse the count() function to generate a table showing how many cars are in each cylinder level. Only having a few observations for a particular level of a categorical variable causes problems for the model. We can either 1) exclude those observations, or 2) create a new variable combining levels. Decide which option you would like to use here and clean the data accordingly. (Note: if you choose to exclude the observations, you can use the filter() function to subset the data).\nLook at the residual and qq plots for this model. What do you observe? Do any of the regression assumptions appear to be violated here? If so, which one(s)? Note that you can generate certain plots using the which option, i.e., plot(model_object, which=1) generates the residual plot, and plot(model_object, which=2) generates the qq-plot.\n\nGenerate a plot of mpg and displacement. Do you think a transformation of the displacement variable might be appropriate? If so, which one and why? Then, add color to your plot for cylinders. Is an interaction term appropriate? Finally, replace cylinders to color by origin. Is an interaction term appropriate?\nRepeat #3 for the other predictor variables: acceleration and horsepower\nDecide if you want to use a transformation on displacement, acceleration, and/or horsepower, or interaction term(s). Consider the implications of estimate interpretations. Fit the model with the additional terms that you choose, and generate the residual and qq plots. What do you notice compared to what you saw in #2?\nFit the model using log(mpg) as the outcome. Generate the residual and qq plots and comment on the difference(s) that you observe. Consider the implications for model interpretation. Do you think the transformation of the outcome variable is useful here?"
  },
  {
    "objectID": "materials/unit1/assumptions.html#key-takeaways",
    "href": "materials/unit1/assumptions.html#key-takeaways",
    "title": "9.07: Addressing the assumptions",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nThere is an argument to be made for treating the cylinders variable as either numeric or categorical. To me, it seemed better suited as a categorical variable. A takeaway here is that when a categorical variable has very few observations for a particular level, the standard error is inflated\nWe see that the linearity assumption appears to be violated. Upon further exploratory inspection, we see a non-linear relationship between mpg and displacement and horsepower. The relationship we see indicates that a log transformation of these predictor variables is necessary. However, when we look at the relationship with cylinder and origin, we see that an interaction term could also be used. Either one will improve the residual plot, so at this point we might consider which one is more interpretable. Since we are interested in inference, I would lean toward using an interaction term, which is easier to interpret than a log transformation.\nA log transformation of the outcome variable will improve the qq-plot. If we do this, the coefficient estimates are interpreted as multiplicative instead of additive (see this link for helpful info on interpreting coefficients after log transformations). Since the violation isn’t too bad, and linear regressions are robust to violations of normality, I would probably forego using the transformation here. However, it’s not incorrect to use it."
  },
  {
    "objectID": "materials/unit1/SLR.html",
    "href": "materials/unit1/SLR.html",
    "title": "8.29: Simple linear regression",
    "section": "",
    "text": "describe the linear regression model with statistical terminology (population parameter, estimate, random variable, probability distribution)\nInterpret regression output (estimates, standard errors, test statistics, p-values, and confidence intervals)\n\nDownload annotated notes"
  },
  {
    "objectID": "materials/unit1/SLR.html#statistics-vocabulary",
    "href": "materials/unit1/SLR.html#statistics-vocabulary",
    "title": "8.29: Simple linear regression",
    "section": "Statistics vocabulary",
    "text": "Statistics vocabulary\n\nPopulation parameter: an unknown quantity related to the population of interest (e.g., true mean resting heart rate of professional athletes in Europe)\nEstimate: quantity obtained from data to estimate the population parameter (e.g., sample mean of resting heart rate of 100 professional athletes in Europe)\nRandom variable: a variable whose possible values are numerical outcomes of a random phenomenon. Random variables can be discrete or continuous\nProbability distribution: a function that maps a random variable’s numeric outcomes to their probability. Probability distributions are defined by their parameters\nThe normal distribution is a continuous probability distribution defined by two parameters: mean \\(\\mu\\) and standard deviation \\(\\sigma\\) (or variance \\(\\sigma^2\\))\ne.g., let \\(X\\) be the random variable that represents the resting heart rate of a given professional athlete. We could say that \\(X \\sim N(\\mu=70,\\sigma=5)\\)\n\n\nExercise\nWrite your own example of a continuous random variable and normal distribution. You can use the normal distribution link to obtain plausible values for the mean and standard deviation."
  },
  {
    "objectID": "materials/unit1/SLR.html#simple-linear-regression-model",
    "href": "materials/unit1/SLR.html#simple-linear-regression-model",
    "title": "8.29: Simple linear regression",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\n\n\n\n\n\nWe define the simple linear regression model as:\n\\[\nY = \\beta_0 + \\beta_1X + \\epsilon, \\epsilon \\sim N(0,\\sigma^2)\n\\]\nWe can also write this as:\n\\[\nY \\sim N(\\beta_0 + \\beta_1X, \\sigma^2)\n\\]\n\nExercise\nMatch the vocabulary above with the regression model\n\nWhich variable(s) are random? Which are fixed?\nWhat is the probability distribution for the random variable(s)?\nWhat are the population parameters?"
  },
  {
    "objectID": "materials/unit1/SLR.html#estimated-regression-line",
    "href": "materials/unit1/SLR.html#estimated-regression-line",
    "title": "8.29: Simple linear regression",
    "section": "Estimated regression line",
    "text": "Estimated regression line\nWe write the estimated regression line as:\n\\[\n\\hat{Y}=\\hat{\\beta_0}+\\hat{\\beta_1}X\n\\]\nand write the residuals \\(r\\) (\\(\\hat{e}\\)) as \\(r=Y-\\hat{Y}\\)"
  },
  {
    "objectID": "materials/unit1/SLR.html#putting-all-the-pieces-together",
    "href": "materials/unit1/SLR.html#putting-all-the-pieces-together",
    "title": "8.29: Simple linear regression",
    "section": "Putting all the pieces together",
    "text": "Putting all the pieces together\n\nExercise\nWrite the estimated regression line for the births14 data\n\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept)   -3.60     0.523      -6.88 1.03e-11   -4.62     -2.57 \n2 weeks          0.279    0.0135     20.7  1.80e-79    0.253     0.306\n\n\n \n \n \n\n\nSampling distribution of \\(\\hat{\\beta}\\)\nBecause the estimated value \\(\\hat{\\beta_1}\\) is calculated from a sample, and the sample arose from a random process, \\(\\hat{\\beta_1}\\) is a random variable with its own probability distribution!\nIt turns out that with the specification given above, \\(\\hat{\\beta_1}\\) has a normal distribution. The estimated standard deviation of this distribution is the standard error of \\(\\hat{\\beta_1}\\)\n\n\nTest statistic & p-value\n\np-value: probability of obtaining results at least as extreme as those observed assuming the null hypothesis is true\nIn other words, if we assume that nothing special is going on, what is the probability that we observe a relationship at least as extreme as what we see in the data?\n\nIn regression, the null hypothesis, or the assumption that there is no relationship between the variables, is \\(H_0: \\beta_1=0\\)\nBecause \\(\\hat{\\beta_1}\\) has a normal distribution (and skipping some technical details), we can use the following test statistic to calculate the desired probability\n\\[\n\\frac{\\hat{\\beta_1}}{SE(\\hat{\\beta_1})} \\sim t_{n-2}\n\\]\nWe use the t-distribution when the population standard deviation is unknown (as is the case for the distribution of \\(\\hat{\\beta_1}\\) ). So, we can use this quantity and the t-distribution to calculate the p-value.\n\n\nConfidence interval\nSimilarly, we can use the t-distribution to calculate the confidence interval, or a plausible range for the true value of the population parameter \\(\\beta_1\\)\n\\[\n\\hat{\\beta_1} \\pm t^*_{n-2}[SE(\\hat{\\beta_1})]\n\\]\n\n\nExercise\nSee for yourself: use the estimate and standard error from the regression output to calculate the test statistic, p-value, and confidence interval. The pt() R function calculates (cumulative) probabilities for the t-distribution, and the qt() function calculates critical values."
  },
  {
    "objectID": "materials/unit1/SLR.html#interpreting-regression-output",
    "href": "materials/unit1/SLR.html#interpreting-regression-output",
    "title": "8.29: Simple linear regression",
    "section": "Interpreting regression output",
    "text": "Interpreting regression output\nWhen reporting results from a regression model, we primarily focus on the estimates, p-values, and confidence intervals. (It is important to check the standard errors though! Inflated standard errors can indicate a problem with the model. We will talk about this more in a later lecture)\n\n\n# A tibble: 2 × 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept)   -3.60     0.523      -6.88 1.03e-11   -4.62     -2.57 \n2 weeks          0.279    0.0135     20.7  1.80e-79    0.253     0.306\n\n\n\nFor each additional week of pregnancy, infant birth weight increases by 0.28 lbs, on average. The association between weeks of pregnancy and infant birth weight is statistically significant (p<.001, 95% CI: [0.25, 0.31])\nAssuming there is no association between weeks of pregnancy and infant birth weight, the probability of observing results as extreme as these is <.001. Therefore, we have evidence that there is a relationship between weeks of pregnancy and infant birth weight.\nIf we repeated this experiment 100 times and constructed a confidence interval in the same way, we would expect 95 of the intervals to contain the true value of \\(\\beta_1\\). Therefore, we are 95% confident that the true value of \\(\\beta_1\\) is between 0.25 and 0.31.\n\n\nIncorrect interpretations\n\nThe probability that the null hypothesis is false is <0.001\nThere is a 95% chance that the true value of \\(\\beta_1\\) is between 0.25 and 0.31\nWe are 95% confidence that \\(\\hat{\\beta_1}\\) is between 0.25 and 0.31"
  },
  {
    "objectID": "materials/unit1/SLR.html#references",
    "href": "materials/unit1/SLR.html#references",
    "title": "8.29: Simple linear regression",
    "section": "References",
    "text": "References\nhttp://www.stat.yale.edu/Courses/1997-98/101/ranvar.htm"
  },
  {
    "objectID": "materials/unit1/problems.html",
    "href": "materials/unit1/problems.html",
    "title": "9.12: Problems that can arise",
    "section": "",
    "text": "interpret plots of leverage and Cook’s distance\nunderstand the problem of multicollinearity"
  },
  {
    "objectID": "materials/unit1/problems.html#classwise-videos",
    "href": "materials/unit1/problems.html#classwise-videos",
    "title": "9.12: Problems that can arise",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class."
  },
  {
    "objectID": "materials/unit1/problems.html#textbook",
    "href": "materials/unit1/problems.html#textbook",
    "title": "9.12: Problems that can arise",
    "section": "Textbook",
    "text": "Textbook\nISLR 3.3.3"
  },
  {
    "objectID": "materials/unit1/problems.html#application-exercise",
    "href": "materials/unit1/problems.html#application-exercise",
    "title": "9.12: Problems that can arise",
    "section": "Application exercise",
    "text": "Application exercise\nFor this exercise, we will use the Hitters dataset from the ISLR2 package\n\nlibrary(ISLR2)\ndata(\"Hitters\")\n?Hitters #run this for the data dictionary\n\n\nWe want to understand how hitter statistics are associated with salaries. More specifically, we want to assess the model regressing Salary on the following predictors: Hits, HmRun, Runs, RBI, Years, CHits, CHmRun, CRuns, and CRBI. Let’s first create a correlation plot of the 9 predictors. Comment on what you observe in the correlation plot.\n\nlibrary(corrplot) #you will need to install this package\ncorrplot(cor(Hitters[,c(\"Hits\", \"HmRun\", \"Runs\", \"RBI\", \"Years\", \n                        \"CHits\", \"CHmRun\",\"CRuns\",\"CRBI\")]))\n\nNow, fit the model. Take note of the output.\nUse the vif() function in the car package to calculate VIF values for each predictors. Do any of the predictors have high VIF values? If so, which one(s)?\nFit another model but without the career variables (i.e., using Hits, HmRun, Runs, RBI, and Years). Note differences in the model output for these predictors between this model and the model you fit in #2 in terms of estimates, standard errors, and p-values.\nLook at the model diagnostics plots.\n\nAre there any influential points? If so, fit the model without those observation(s) and note any differences in the summary output and/or the diagnostic plots.\nDo you notice any other potential violations in model assumptions? If so, what adjustments could be made?"
  },
  {
    "objectID": "materials/unit1/problems.html#key-takeaways",
    "href": "materials/unit1/problems.html#key-takeaways",
    "title": "9.12: Problems that can arise",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nFrom the correlation plot, you should see that the single-season variables and the career variables are highly correlated with each other\nWe see very high VIF values for the career variables. I recommended removing those because they are so high and much higher than the other predictors. I encourage you not to rely strictly on the >10 threshold.\nAfter removing the career variables, we see that the standard errors for the single-season variables generally decrease. Perhaps the most notable and intuitive difference in the output is in the Years variable. We would expect that salaries generally increase as years in the league increase. In the first model, we had high collinearity between the Years variable and the career variables, and the estimate was negative. After removing the career variables with which the Years variable was highly correlated, the standard error for Years is quite a bit lower and the estimate is positive (and statistically significant)\nFor the model diagnostic plots, we see potential violation of homoscedasticity and normality. If we log-transform the outcome, the model diagnostic plots are more “cloud-like.” Log-transformations are often necessary when outcome variables have to do with money (salary, price, income, etc.).\nWe see a few outliers and high-leverage points, though no influential points identified with Cook’s distance. If we remove Mike Schmidt, Rickey Henderson, and Terry Kennedy, the model output is slightly different but we don’t see substantial differences (i.e., conclusions drawn from p-values are not different)"
  },
  {
    "objectID": "materials/unit1/modelselection.html",
    "href": "materials/unit1/modelselection.html",
    "title": "9.14: Model selection",
    "section": "",
    "text": "understand forward and backward selection\nunderstand the argument against forward and backward selection"
  },
  {
    "objectID": "materials/unit1/modelselection.html#classwise-videos",
    "href": "materials/unit1/modelselection.html#classwise-videos",
    "title": "9.14: Model selection",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThere are no chat sessions for this lecture.\nThe first video explains the forward and backward model selection procedures.\n\nThe reading below presents an argument against using forward and backward selection (these methods are also known as stepwise selection). Read the full introduction (pages 1-5) and the conclusion. You can skip the methods and results sections."
  },
  {
    "objectID": "materials/unit1/modelselection.html#textbook",
    "href": "materials/unit1/modelselection.html#textbook",
    "title": "9.14: Model selection",
    "section": "Textbook",
    "text": "Textbook\nISLR 6.1.2"
  },
  {
    "objectID": "materials/unit1/modelselection.html#application-exercise",
    "href": "materials/unit1/modelselection.html#application-exercise",
    "title": "9.14: Model selection",
    "section": "Application exercise",
    "text": "Application exercise\nClass exercise vote\nGroups for today’s exercise\nIn your group, discuss the following based on the video and article:\n\nSummarize the forward and backward stepwise selection procedures.\nWhy are forward and backward selection appealing?\nWhat statistical arguments does Smith make against stepwise selection?\nConsider this sentence: “The standard errors of the coefficient estimates are underestimated, which makes the confidence intervals too narrow, the t statistics too high, and the p-values too low…” Think about the relationship between standard errors and the other quantities mentioned. Why would underestimated standard errors lead to the outcomes listed?\nExplain how big data has renewed the interest in stepwise selection and why Smith argues that big data exacerbates the problems with stepwise selection\nWhat alternative approaches to model selection does Smith recommend?\nImagine yourself working on a data science team in the future. A colleague recommends using the following two approaches. Based on the reading, which of these approaches seems reasonable? If none of them seem reasonable, how do you explain this to your colleague and how do you recommend moving forward?\n\nFit a model with pre-specified predictors and use backward selection to arrive at a “final model.” Interpret the output and draw conclusions based on the final model.\nFit a model with pre-specified predictors. Remove any variables with p-values that are above 0.05. Re-fit the model and interpret the output.\nFit simple linear regression models with each predictor individually. Then, fit a multiple linear regression model with the predictors that had significant p-values in the SLR model. Interpret the MLR output."
  },
  {
    "objectID": "materials/unit1/introtomlrcode.html",
    "href": "materials/unit1/introtomlrcode.html",
    "title": "Intro to MLR",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2…\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, …\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34…\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16…\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385…\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, …\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7…\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, …\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa…\n\n\n\nlibrary(tidyverse)\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2…\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, …\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34…\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16…\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385…\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, …\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7…\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, …\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa…\n\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\")\n\n\n\n\n\n#MLR model regressing mpg on weight and origin\nmlr_mod_auto <- lm(mpg~weight+origin,\n                   data=Auto)\n\nsummary(mlr_mod_auto)\n\n\nCall:\nlm(formula = mpg ~ weight + origin, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.0698  -2.7888  -0.3122   2.4489  15.4816 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.4908175  1.3266161   32.03  < 2e-16 ***\nweight      -0.0070071  0.0003136  -22.34  < 2e-16 ***\norigin       1.1540278  0.3306915    3.49 0.000539 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.272 on 389 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.7004 \nF-statistic: 458.1 on 2 and 389 DF,  p-value: < 2.2e-16\n\n\n\n#create a factor variable\nAuto$origin_fac <- factor(Auto$origin,\n                          levels=c(1,2,3),\n                          labels=c(\"American\",\n                                   \"European\",\n                                   \"Japanese\"))\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n\n\n\n\nmlr_mod_fac <- lm(mpg~weight+origin_fac,\n                  data=Auto)\n\nsummary(mlr_mod_fac)\n\n\nCall:\nlm(formula = mpg ~ weight + origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1339  -2.7358  -0.3032   2.4307  15.4544 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        43.7322362  1.1134286  39.277  < 2e-16 ***\nweight             -0.0070271  0.0003201 -21.956  < 2e-16 ***\norigin_facEuropean  0.9709056  0.6587673   1.474 0.141340    \norigin_facJapanese  2.3271499  0.6648043   3.501 0.000518 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.277 on 388 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.6997 \nF-statistic: 304.7 on 3 and 388 DF,  p-value: < 2.2e-16\n\n\nOn average, European cars’ mpg is 0.97 higher than American cars’ mpg, holding all else constant. This difference is not statistically significant at the 0.05 level (p=0.14).\nOn average, per increase in weight (lb), mpg decreases by 0.007, all else constant. This is statistically significant (p<0.001), so vehicle weight is associated with mpg."
  },
  {
    "objectID": "materials/unit1/introtomlrcode.html#interaction",
    "href": "materials/unit1/introtomlrcode.html#interaction",
    "title": "Intro to MLR",
    "section": "Interaction",
    "text": "Interaction\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nmlr_mod_interact <- lm(mpg~weight*origin_fac,\n                       data=Auto)\nsummary(mlr_mod_interact)\n\n\nCall:\nlm(formula = mpg ~ weight * origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4928  -2.7715  -0.3895   2.2397  15.5163 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                4.315e+01  1.186e+00  36.378  < 2e-16 ***\nweight                    -6.854e-03  3.423e-04 -20.020  < 2e-16 ***\norigin_facEuropean         1.125e+00  2.878e+00   0.391  0.69616    \norigin_facJapanese         1.111e+01  3.574e+00   3.109  0.00202 ** \nweight:origin_facEuropean  3.575e-06  1.111e-03   0.003  0.99743    \nweight:origin_facJapanese -3.865e-03  1.541e-03  -2.508  0.01255 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.253 on 386 degrees of freedom\nMultiple R-squared:  0.7068,    Adjusted R-squared:  0.703 \nF-statistic: 186.1 on 5 and 386 DF,  p-value: < 2.2e-16\n\n\nPer lb increase in weight, mpg increases by an additional 0.0000036, on average, all else held constant, for European cars compared to American cars. This difference is not statistically significant (p>0.99).\nPer lb increase in weight, mpg decreases by 0.011, on average, for European cars. For American cars, mpg decreases by 0.007, on average, per lb increase in weight. The difference in effects, 0.004, is statistically significant at the 0.05 level (p=0.013)."
  },
  {
    "objectID": "materials/unit0/unit0b.html",
    "href": "materials/unit0/unit0b.html",
    "title": "Cleaning and exploring data in R",
    "section": "",
    "text": "A crucial first step of data analysis is exploring the dataset (and then cleaning, as needed). Today, we will practice exploring and cleaning data in R."
  },
  {
    "objectID": "materials/unit0/unit0b.html#types-of-variables",
    "href": "materials/unit0/unit0b.html#types-of-variables",
    "title": "Cleaning and exploring data in R",
    "section": "Types of variables",
    "text": "Types of variables\nNumeric variables take numerical values and it makes sense to perform calculations on the values (e.g., addition, mean)\n\nDiscrete variables can not take decimal values (e.g., Number of required statistics courses in a major)\nContinuous variables can take decimal values (e.g., height in cm)\n\nCategorical variables are variables that have categories, where each category is called a level\n\nNominal variables do not have an order (e.g., eye color)\nOrdinal variables do have an order (e.g., education categories)\n\n\nExercise\nIn your group, discuss the following:\n\nClassify each of the survey questions as discrete, continuous, nominal, or ordinal.\nWhat does it mean to explore data?\nWhat does it mean to clean data? Identify how the survey data may need to be cleaned just by looking at the questions."
  },
  {
    "objectID": "materials/unit0/unit0b.html#first-steps-in-r",
    "href": "materials/unit0/unit0b.html#first-steps-in-r",
    "title": "Cleaning and exploring data in R",
    "section": "First steps in R",
    "text": "First steps in R\nHopefully you have already installed R/RStudio on your computer. If so, you can copy and paste the code below into your own script. If you haven’t yet installed R/RStudio, you can run code directly from this page.\nLoading\n  webR...\n\n\n  \n\n\nLoading\n  webR...\n\n\n  \n\n\nLet’s remove the timestamp variable\nLoading\n  webR...\n\n\n  \n\n\nLet’s make our variable names more concise (but still descriptive!)\nLoading\n  webR..."
  },
  {
    "objectID": "materials/unit0/unit0b.html#cleaning-and-exploring-variables",
    "href": "materials/unit0/unit0b.html#cleaning-and-exploring-variables",
    "title": "Cleaning and exploring data in R",
    "section": "Cleaning and exploring variables",
    "text": "Cleaning and exploring variables\n\nSiblings\nLet’s start with the Siblings variable. What information do we need to know to clean the variable?\nLoading\n  webR...\n\n\n  \n\n\nAlways always always:\n\ncreate a new variable instead of overwriting the original\nperform a quality control check\n\nLoading\n  webR...\n\n\n  \n\n\nNow that the variable is clean, let’s explore it more:\nLoading\n  webR...\n\n\n  \n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\nSushi\nNow consider the sushi variable.\nLoading\n  webR...\n\n\n  \n\n\nIt’s important to pay attention to implausible values. What would be an implausible value in this case? How should we handle it?\nLoading\n  webR...\n\n\n  \n\n\nNow let’s generate a plot to visualize the sushi variable\nLoading\n  webR...\n\n\n  \n\n\n\n\nLanguages\nLoading\n  webR...\n\n\n  \n\n\nOften, we need to combine categories if we have too few observations in multiple categories. How should we combine categories in this case?"
  },
  {
    "objectID": "materials/unit0/unit0b.html#exercises",
    "href": "materials/unit0/unit0b.html#exercises",
    "title": "Cleaning and exploring data in R",
    "section": "Exercises",
    "text": "Exercises\nIn your group, complete the following:\n\nFor the application area of interest variable, how many students responded with “other”? What does this say about the survey design?\nExplore, clean, and visualize the remaining variables in the dataset. Note that you may have to look up some functions to help. For example, the “substr” function will be useful for the course excitement variable."
  },
  {
    "objectID": "materials/unit0/unit0a.html",
    "href": "materials/unit0/unit0a.html",
    "title": "Key Principles of Statistics",
    "section": "",
    "text": "By the end of this session, students should be able to:\n\ndistinguish between a population and a sample\ndescribe sampling variability\nfit a simple linear regression model in R"
  },
  {
    "objectID": "materials/unit0/unit0a.html#load-the-data",
    "href": "materials/unit0/unit0a.html#load-the-data",
    "title": "Key Principles of Statistics",
    "section": "Load the data",
    "text": "Load the data\nToday we will use the births14 dataset in the openintro R package. You can read more about the dataset and see a data dictionary at this link.\n\n#load the packages we need\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#load the dataset from the openintro package\ndata(births14)\n\n#get an overview of the data\nglimpse(births14)"
  },
  {
    "objectID": "materials/unit0/unit0a.html#exercise",
    "href": "materials/unit0/unit0a.html#exercise",
    "title": "Key Principles of Statistics",
    "section": "Exercise",
    "text": "Exercise\nExplore the births14 data:\n\nUsing the data dictionary at the link above, classify the variables as numeric or categorical. Do the variables seem to be correctly structured in R?\nUse the summary() function to determine if there are missing values in the dataset"
  },
  {
    "objectID": "materials/unit0/unit0a.html#hypothetically",
    "href": "materials/unit0/unit0a.html#hypothetically",
    "title": "Key Principles of Statistics",
    "section": "Hypothetically…",
    "text": "Hypothetically…\nImagine that this dataset contains information about the entire population of interest (e.g., all babies born in Bull City). Then, say we have the following research question:\nWhat is the relationship between length of pregnancy in weeks and weight of the baby in pounds in Bull City?\nWe can explore this relationship graphically:\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\", y=\"baby weight (lbs)\") \n  #always use labels!"
  },
  {
    "objectID": "materials/unit0/unit0a.html#linear-regression",
    "href": "materials/unit0/unit0a.html#linear-regression",
    "title": "Key Principles of Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nTo further characterize the relationship between length of pregnancy and baby weight, we can fit a line to the plot:\n\nmod_bullcity <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births14)\n\ntidy(mod_bullcity, conf.int=TRUE)\n\n\nExercise\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\n\nLooking at the estimate column of the tidy output, how would you interpret the intercept here? how would you interpret the weeks estimate?\n\n\n\nStandard error\nTo better conceptualize the standard error, consider the premise above that these data represent the entire city. Now imagine that we could not actually obtain all of these data. Instead, we were only able to obtain a sample of 200 babies. Using only a sample of 200, if we fit a line in the same way as above, we have many different lines that we could have obtained:\n\nset.seed(823)\nbirths_sample1 <- births14 |> slice_sample(n=200)\n\nggplot(births_sample1, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\nmod_sample1 <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births_sample1)\n\ntidy(mod_sample1, conf.int=TRUE)\n\n\n\nExercise\nFill in the code below to simulate the process of taking 250 different samples and store the weeks coefficient estimate in a vector\n\nweeks.coefs <- c() #create empty vector to store coefficient estimates\n\nfor(i in 1:250){ #create loop for 250 different samples\n  print(i)\n  set.seed(823+i) #set a unique seed each iteration\n  \n  #sample data\n  births_sample <-\n  \n  #fit model\n  mod_sample <- \n    \n  #store output\n  weeks.coefs[i] <- tidy(mod_sample)$estimate[2]\n}\n\n \n \n \nNow let’s plot the coefficient estimates we have for the 250 samples:\n\nweeks.coefs.dat <- data.frame(weeks.coefs)\n\nggplot(weeks.coefs.dat, aes(x=weeks.coefs))+\n  geom_histogram()+\n  labs(x=\"weeks coefficient estimate\")\n\nWe see that there is variability in the coefficient estimates for weeks. The standard deviation of this collection of possible estimates is the standard error of the estimate.\n\n\nConfidence interval and p-value\nWe can also use this collection of estimates to provide a plausible range for the “true” coefficient value:\n\nquantile(weeks.coefs, probs=c(.025,.975))\n\nOr, we can look at the collection of estimates and see that none of them are 0. So, because we collected 250 different samples and none of them had a coefficient estimate of 0, we are quite confident that the “true” coefficient is not zero.\n \n \nIn reality, we typically cannot many samples from the same population. So, we often rely on assumptions related to probability distributions to derive confidence intervals and p-values."
  },
  {
    "objectID": "materials/unit0/unit0.html",
    "href": "materials/unit0/unit0.html",
    "title": "Key Principles of Statistics",
    "section": "",
    "text": "By the end of this session, students should be able to:\n\ndistinguish between a population and a sample\ndescribe sampling variability\nfit a simple linear regression model in R"
  },
  {
    "objectID": "materials/unit0/unit0.html#load-the-data",
    "href": "materials/unit0/unit0.html#load-the-data",
    "title": "Key Principles of Statistics",
    "section": "Load the data",
    "text": "Load the data\nToday we will use the births14 dataset in the openintro R package. You can read more about the dataset and see a data dictionary at this link.\n\n#If you would like the full qmd file, you can run this in the console\ndownload.file(\"https://raw.githubusercontent.com/anlane611/datasets/main/unit0.qmd\",destfile = \"unit0.qmd\")\n\n\n#load the packages we need\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#load the dataset from the openintro package\ndata(births14)\n\n#get an overview of the data\nglimpse(births14)\n\nNote: As an alternative to using RStudio on your local machine, you can use the Duke container: https://cmgr.oit.duke.edu/containers"
  },
  {
    "objectID": "materials/unit0/unit0.html#exercise",
    "href": "materials/unit0/unit0.html#exercise",
    "title": "Key Principles of Statistics",
    "section": "Exercise",
    "text": "Exercise\nExplore the births14 data:\n\nUsing the data dictionary at the link above, classify the variables as numeric or categorical. Do the variables seem to be correctly structured in R?\nUse the summary() function to determine if there are missing values in the dataset"
  },
  {
    "objectID": "materials/unit0/unit0.html#hypothetically",
    "href": "materials/unit0/unit0.html#hypothetically",
    "title": "Key Principles of Statistics",
    "section": "Hypothetically…",
    "text": "Hypothetically…\nImagine that this dataset contains information about the entire population of interest (e.g., all babies born in Bull City). Then, say we have the following research question:\nWhat is the relationship between length of pregnancy in weeks and weight of the baby in pounds in Bull City?\nWe can explore this relationship graphically:\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\", y=\"baby weight (lbs)\") \n  #always use labels!"
  },
  {
    "objectID": "materials/unit0/unit0.html#linear-regression",
    "href": "materials/unit0/unit0.html#linear-regression",
    "title": "Key Principles of Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nTo further characterize the relationship between length of pregnancy and baby weight, we can fit a line to the plot:\n\nmod_bullcity <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births14)\n\ntidy(mod_bullcity, conf.int=TRUE)\n\n\nExercise\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\n\nLooking at the estimate column of the tidy output, how would you interpret the intercept here? how would you interpret the weeks estimate?\n\n\n\nStandard error\nTo better conceptualize the standard error, consider the premise above that these data represent the entire city. Now imagine that we could not actually obtain all of these data. Instead, we were only able to obtain a sample of 200 babies. Using only a sample of 200, if we fit a line in the same way as above, we have many different lines that we could have obtained:\n\nset.seed(823)\nbirths_sample1 <- births14 |> slice_sample(n=200)\n\nggplot(births_sample1, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\nmod_sample1 <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births_sample1)\n\ntidy(mod_sample1, conf.int=TRUE)\n\n\n\nExercise\nFill in the code below to simulate the process of taking 250 different samples and store the weeks coefficient estimate in a vector\n\nweeks.coefs <- c() #create empty vector to store coefficient estimates\n\nfor(i in 1:250){ #create loop for 250 different samples\n  print(i)\n  set.seed(823+i) #set a unique seed each iteration\n  \n  #sample data\n  births_sample <-\n  \n  #fit model\n  mod_sample <- \n    \n  #store output\n  weeks.coefs[i] <- tidy(mod_sample)$estimate[2]\n}\n\n \n \n \nNow let’s plot the coefficient estimates we have for the 250 samples:\n\nweeks.coefs.dat <- data.frame(weeks.coefs)\n\nggplot(weeks.coefs.dat, aes(x=weeks.coefs))+\n  geom_histogram()+\n  labs(x=\"weeks coefficient estimate\")\n\nWe see that there is variability in the coefficient estimates for weeks. The standard deviation of this collection of possible estimates is the standard error of the estimate.\n\n\nConfidence interval and p-value\nWe can also use this collection of estimates to provide a plausible range for the “true” coefficient value:\n\nquantile(weeks.coefs, probs=c(.025,.975))\n\nOr, we can look at the collection of estimates and see that none of them are 0. So, because we collected 250 different samples and none of them had a coefficient estimate of 0, we are quite confident that the “true” coefficient is not zero.\n \n \nIn reality, we typically cannot many samples from the same population. So, we often rely on assumptions related to probability distributions to derive confidence intervals and p-values."
  },
  {
    "objectID": "DAA/DA1.html",
    "href": "DAA/DA1.html",
    "title": "Data analysis assignment 1",
    "section": "",
    "text": "Airbnb wants to help new hosts set prices for their Airbnb listings in Asheville, NC. They have hired your data science consulting company to build a model to generate prices based on a variety of factors.\nFor this assignment, you will write your report in two parts: 1) a report (1-2 pages) describing your model to (non-technical) Airbnb executives, and 2) a report (3-4 pages) justifying your model to your (technical) data science team"
  },
  {
    "objectID": "DAA/DA1.html#the-dataset",
    "href": "DAA/DA1.html#the-dataset",
    "title": "Data analysis assignment 1",
    "section": "The dataset",
    "text": "The dataset\nClick here to download the data\nThe data is from Inside Airbnb.\nClick here for the data dictionary"
  },
  {
    "objectID": "DAA/DA1.html#cleaning-and-model-requirements",
    "href": "DAA/DA1.html#cleaning-and-model-requirements",
    "title": "Data analysis assignment 1",
    "section": "Cleaning and model requirements",
    "text": "Cleaning and model requirements\nYou must include the following variables in your model:\n\nroom_type (you may need to combine categories)\nnumber of bedrooms\nnumber of bathrooms (note that this variable needs to be cleaned, as the bathrooms variable is empty. I recommend using the str_sub() function from the stringr package and as.numeric() to extract the number of bathrooms\ncreate a new variable that gives the distance to downtown. There may be multiple ways to do this, but you can use the code below. This uses the apply function, which is a useful function in R to perform an operation on all rows (or columns) of a matrix. Then it uses the distm() function in the geosphere package to calculate the distance in meters from a latitude and longitude in downtown Asheville. Finally, it multiplies by the appropriate constant to convert the value to miles.\n\n\nlibrary(geosphere) #you will need to install this package\nairbnb$dist_to_dt <- apply(airbnb[,c(\"longitude\",\"latitude\")],1,function(x) distm(\n  c(-82.55481168521978,35.59701329976918),\n  x,fun=distHaversine))*0.00062137\n\nNote that you will also need to clean the price variable. You can use the str_sub() function again here.\nChoose at least one other variable to include in your model. Consider what is appropriate for a new host to set a price.\n\n  Extra credit\n  \n    Earn extra points on this assignment by finding a way to incorporate amenity features in your model. For example, a host may want to change the price based on whether or not they allow pets.\n    \n  \n\nAs you fit and assess your model, consider the following elements that we have discussed in class:\n\nIs this a prediction or inference problem? Should model interpretability be prioritized in this situation?\nLook at the diagnostic plots for your model. Determine if you need to transform predictor(s) or the outcome variable to improve the model.\nEvaluate influential points and multicollinearity and make adjustments accordingly. If you remove any observations, be sure to include this information in your report.\nWhich model metric(s) are appropriate to assess the model?"
  },
  {
    "objectID": "DAA/DA1.html#deliverables",
    "href": "DAA/DA1.html#deliverables",
    "title": "Data analysis assignment 1",
    "section": "Deliverables",
    "text": "Deliverables\n\nReport for Airbnb executives (1-2 pages)\nThe report for the Airbnb executives should explain your model to a non-technical audience. No code or “raw” R output should be in the report.\nSpecifically, your report should contain the following elements:\n\nIntroduction: Provide an overview of the dataset and the goals of the analysis. Provide basic information about the data (e.g., sample size). You may choose to include summary statistics or basic plots.\nMethods: Explain the model you used to analyze the data without getting into technical details. Why did you decide to use that model for this dataset and how does it accomplish their goal? Which variables did you include in the model and why?\nResults: Justify your model with the appropriate model metric(s). Explain them in non-technical terms. Then, provide an example of how the model can be used by giving the projected price for a particular combination of variables in your model (e.g., “for a listing with 2 bedrooms, 2 bathrooms, …, the price would be —”)\nConclusion: Do you feel that the model is good enough to be deployed? If not, can you think of additional data that Airbnb could collect to improve the model?\n\n\n\nReport for data science team\nThe second part of the assignment will be a 3-4 page report that is suitable for other data scientists. Here, you will present details of your model to justify the conclusions you presented to the client. This section should present technical details that someone with a data science background can understand. This report must include the following, though you may wish to provide additional details relevant to the analysis:\n\nIntroduction: Provide details about the dataset, including any data cleaning that needed to be done. Was there any missing data? Did you make any assumptions during the data cleaning process?\nMethods: Describe your model assessment and building process. Did you include any interaction terms? Why or why not? Did you transform any variables? If so, why? Provide the model diagnostic plots. Did you exclude any observations? Did you make any adjustments because of multicollinearity? How did you assess your model?\nConclusion: What do you conclude about the validity of this analysis?\n\n\n\n  Submission & Formatting Instructions/Tips\n  \n    You will submit two files to gradescope: 1) a PDF that contains the two requested reports, and 2) the qmd file you used to produce the reports \n    \n      All code must be hidden in the PDF. You can hide all code by adding the following to your YAML Header: execute:   echo: false\n      Your quarto document should be rendered directly to PDF, not to HTML and then saved as a PDF\n      The PDF should be 5-6 pages: 1-2 pages for the non-technical report and 3-4 pages for the technical report. These ranges are intentional; reports that fall outside of this range will be penalized. \n      Any plots (including diagnostic plots) must be appropriately formatted (axis labels, legends where appropriate)\n      \"Raw\" R output and variable names should not be in the report. For example, in the writing, tables, plots, etc, you should say \"room type\" instead of \"room_type\"\n      The quarto website includes lots of helpful information for generating your report. I recommend that you use the visual editor  to make formatting easier. The visual editor has several features that look like a generic word processor\n      PDF Basics \n      Gallery for advanced Quarto formatting (not necessary, but could be helpful) \n    \n  \n\n\nExample of good formatting\nThis is a different assignment structure, but notice the following elements of this report:\n\ncode is hidden\ntables/plots are labeled with the variable descriptions instead of the variable names\nsections are labeled\nvariables in the text are referred to by description instead of variable name\nAll output is presented in text, table, or plot (no raw output)"
  },
  {
    "objectID": "DAA/DA2.html",
    "href": "DAA/DA2.html",
    "title": "Data analysis assignment 2",
    "section": "",
    "text": "First due date for peer review: Thursday, October 19 in class (Log in to canvas.duke.edu with your Duke netID and click “Assignments > Data analysis assignment 2 - peer review” to submit your assignment for peer review. You can do this before class or during the first few minutes of class)\nFinal product due date: Friday, October 27, 11:59 PM"
  },
  {
    "objectID": "DAA/DA2.html#logistic-regression-model-documentation",
    "href": "DAA/DA2.html#logistic-regression-model-documentation",
    "title": "Data analysis assignment 2",
    "section": "Logistic regression model documentation",
    "text": "Logistic regression model documentation\nAn important part of being a data scientist is documenting your modeling process. You are often not the only person who will analyze a given dataset. A data scientist who analyzes data after you should be able to clearly understand (and be able to replicate) your modeling decisions.\nFor this assignment, you will be assigned one of two datasets. Your deliverable will be a model documentation report for your dataset. Then, you will swap with someone with the other dataset, and you will each evaluate the documentation based on clarity. After the peer review, you will be able to revise your documentation before final submission.\nGiven this structure, your grade will be based on the following three components:\n\nQuality of your peer review for a classmate (Oct 19)\nFeedback from peer review of your initial document (Oct 19)\nYour final documentation report (due Oct 27)"
  },
  {
    "objectID": "DAA/DA2.html#the-datasets",
    "href": "DAA/DA2.html#the-datasets",
    "title": "Data analysis assignment 2",
    "section": "The datasets",
    "text": "The datasets\nClick here for the dataset assignments (you must use the one you are assigned).\n\n  \n    \n      \n        Financial independence survey\n      \n    \n    \n      \n         This dataset contains a subset of the official results of the 2020 Financial Independence Survey from Reddit. \n        Research Question: Which factors contribute to whether or not someone considers themselves to be financially independent?\n        Click here for the data dictionary and source information \n        You can access the data using the openintro library:\n        library(openintro)data(\"reddit_finance\")\n      \n    \n  \n  \n    \n      \n        Resume data\n      \n    \n    \n      \n         This dataset contains experimental data from a study seeking to understand factors that influence whether or not a resume is selected for a callback. \n        Research Question: How do race and gender influence job application callback rates?\n        Click here for the data dictionary and source information \n        You can access the data using the openintro library:\n        library(openintro)data(\"resume\")"
  },
  {
    "objectID": "DAA/DA2.html#deliverables",
    "href": "DAA/DA2.html#deliverables",
    "title": "Data analysis assignment 2",
    "section": "Deliverables:",
    "text": "Deliverables:\n\nModel documentation (3-5 pages)\nYour model documentation should demonstrate how you analyzed the dataset and justify the decisions you made during the analysis. The intended audience is someone who is familiar with statistical modeling but new to the project/dataset. You can choose how to organize and format your report. For example, you may choose to use bullet points in some sections instead of paragraphs. You may also include code chunks in the documentation, but presenting code should have a clear purpose.\nYour documentation should cover the following elements:\n\nOverview: Provide an overview of the dataset and the goals of the analysis. Provide basic information about the data (e.g., sample size).\nData cleaning: Which variables required cleaning? Are there any missing values? Did you make any assumptions during the data cleaning process?\nModeling:\n\nJustify the choice to use logistic regression to answer the research question.\nVariable selection: Which variables did you include in your model? Start with a priori variable selection, keeping in mind the principle of confounding. If you decide to exclude variables after the initial a priori selection, explain why/how you selected the variables. You do not need to do feature selection with cross validation, but you can if you want to. Remember that we should not select variables based on p-values.\nSummary output table: coefficient estimates, standard errors, p-values, confidence intervals\nModel assessment: Which metric did you use to assess your model and why? Include at least one figure that relates to the model assessment.\n\nResults: Interpret key results that relate to the research question. Include at least one figure to illustrate results. Note that this should be a descriptive figure related to the relationship of interest in the research question; this should not be a diagnostic plot.\nFuture work: What are the strengths and limitations of this analysis?\n\n\n\nPeer Review\nIn class on Oct 19, you will evaluate a classmate’s documentation. Detailed instructions will be provided on that day. Part of your grade for this assignment is based on the quality of the feedback you give your classmate and the feedback you receive from your classmate.\nLog in to canvas.duke.edu to submit your assignment for peer review. You can do this before class or at the beginning of class.\nSubmit the review of your peer’s assignment by Friday, Oct 20 11:59 PM.\n\n  \n  Important!\n  You need to tell me ahead of time if you cannot be in class on Oct 19. Contact me by Oct 12 if you know you will not be in class that day so that I can make alternative arrangements for your peer review. The peer review should be anonymous, but to do this, you will need to make sure your name is not shown in the pdf that you submit.\n\n\n  Submission & Formatting Instructions/Tips\n  \n    You will submit two files to gradescope for the final submission on Oct 27: 1) a PDF that contains the documentation report, and 2) the qmd file you used to produce the reports \n    \n      Your quarto document should be rendered directly to PDF, not to HTML and then saved as a PDF, and not with a different word processor.\n      Any plots must be appropriately formatted (axis labels, legends where appropriate)\n      The quarto website includes lots of helpful information for generating your report. I recommend that you use the visual editor  to make formatting easier. The visual editor has several features that look like a generic word processor\n      PDF Basics \n      Gallery for advanced Quarto formatting (not necessary, but could be helpful)"
  },
  {
    "objectID": "DAA/DA3.html#generalized-linear-model-tutorial",
    "href": "DAA/DA3.html#generalized-linear-model-tutorial",
    "title": "Data analysis assignment 3",
    "section": "Generalized Linear Model Tutorial",
    "text": "Generalized Linear Model Tutorial\nFor this assignment, you will write a tutorial for one of three generalized linear models that we have covered. Writing a tutorial will help you to solidify your conceptual understanding of the model and practice applying the model in R. You will be assigned one of three types of GLMs: multinomial, ordinal, or poisson.\nClick here for your GLM assignment (you must use the one you are assigned)"
  },
  {
    "objectID": "DAA/DA3.html#datasets",
    "href": "DAA/DA3.html#datasets",
    "title": "Data analysis assignment 3",
    "section": "Datasets",
    "text": "Datasets\nClick on the link below to download the dataset that corresponds to the model you have been assigned. Note that these are simulated datasets, which means I generated them using probability distribution functions in R. They are all clean, contain no missing data, and have three variables: Y, X1, and X2. While it is ok to use these variable names, I encourage you to create your own variable names that apply to your area of interest. You should note in your tutorial that the data are simulated. More detail about the data generation is included at the end of this page if you are interested.\nMultinomial data\nOrdinal data\nPoisson data"
  },
  {
    "objectID": "DAA/DA3.html#deliverable-4-6-pages",
    "href": "DAA/DA3.html#deliverable-4-6-pages",
    "title": "Data analysis assignment 3",
    "section": "Deliverable (4-6 pages)",
    "text": "Deliverable (4-6 pages)\nYour tutorial should describe and demonstrate the GLM using the appropriate dataset. The intended audience is someone who is familiar with linear regression but unfamiliar with GLMs.\nFor this assignment, it is important to include code chunks in your tutorial. Your task is to explain the concepts and provide the code that your audience will need to replicate the example. Recall that you can do this with the echo: TRUE option under eval in your YAML header. Note that only code that is directly relevant to the tutorial should be included. Extraneous code such as install.packages() or debugging code should not be included. You should also show relevant “raw” output, such as the summary(model) output, to describe how to interpret it.\nYour tutorial should contain the following sections and content:\n\nOverview: Provide a few sentences describing the purpose of GLMs and the general structure of a GLM. As part of this, describe the purpose of a link function. Provide a few sentences to describe the purpose of your particular GLM. Include 2 examples of research questions that could be answered with your GLM.\nProbability Distribution: Briefly describe the probability distribution that is assumed for the outcome. What is the support? What are the parameters and what values can they take?\nThe Model: Write out the general form of your GLM. What is the link function and why is it appropriate for that type of outcome? What are the model assumptions?\nData Example:\n\nIntroduce the dataset. Provide a few summary statistics and/or plots. Include the fact that this is a simulated dataset.\nFit the model. Include all relevant code, including library() for packages if needed.\nExplain how to interpret coefficient estimates for the predictors.\nShow and describe a plot that illustrates the results of the model.\nDescribe how to assess the model and include the code to do so. Include how to assess any assumptions that are unique to that model (e.g., proportional odds, overdispersion). Note: For the ordinal model, assess the assumption using the method shown in the class exercise, not the hypothesis test shown in the videos."
  },
  {
    "objectID": "DAA/DA3.html#example-tutorial",
    "href": "DAA/DA3.html#example-tutorial",
    "title": "Data analysis assignment 3",
    "section": "Example tutorial",
    "text": "Example tutorial\nGetting started with linear regression"
  },
  {
    "objectID": "DAA/DA3.html#data-generation",
    "href": "DAA/DA3.html#data-generation",
    "title": "Data analysis assignment 3",
    "section": "Data Generation",
    "text": "Data Generation\nSee the code below if you want to learn more about how the datasets were generated. This is not required. If you would like to change the values of the coefficients or the mean/sd of the predictor(s) to better fit your application of interest, you are welcome to do that.\nReferences to learn more:\nSimulating multinomial logistic regression data (also used for ordinal)\nSimulating data for count models\n\n# simulating data for GLMs\n\n#first, we specify the sample size and generate the predictors\nn <- 344\nx1 <- rnorm(n=n, mean=20, sd=3)\nx2a <- runif(n=n, min=0, max=1)\nx2 <- ifelse(x2<0.3,1,0)\n\n#for each model, we generate the outcome based on the specified model\n\n#poisson\nlambda.out <- exp(-3.5 + 0.2*x1 + 0.5*x2) #first generate the mean\ny <- rpois(n=n, lambda=lambda.out) #use the mean to generate the poisson outcome\n\npois_dat <- data.frame(Y=y,X1=x1,X2=x2) #create the dataframe\n\n\n#multinomial\n\n#recall that multinomial fits different logistic models. Here, we want an outcome with 3 levels, so we specify two different logistic models below.\nlp2 <- 3 + -0.2*x1 + -0.7*x2\nlp3 <- -4 + 0.2*x1 + -0.3*x2\n\nden <- (1+exp(lp2)+exp(lp3)) #ensures the probabilities sum to 1\n#we generate a probability of each outcome level for each subject\np1 <- 1/den\np2 <- exp(lp2)/den\np3 <- exp(lp3)/den\n\np <- cbind(p1, p2, p3)\nhead(p) #shows the matrix structure of the probabilities\n\n#the apply function takes each row of probabilities and generates and outcome based on those probabilities for each subject.\ny.mult <- apply(p, MARGIN=1, function(x) sample(x=1:3, size=1, prob=x))\nmult_dat <- data.frame(Y=y.mult,X1=x1,X2=x2)\n\n#ordinal - same as multinomial above, I just used different coefficients\nlp2 <- 4 + -0.2*x1 + -0.6*x2\nlp3 <- -4 + 0.2*x1 + -0.2*x2\n\nden <- (1+exp(lp2)+exp(lp3))\np1 <- 1/den\np2 <- exp(lp2)/den\np3 <- exp(lp3)/den\n\np <- cbind(p1, p2, p3)\nhead(p)\n\ny.ord <- apply(p, MARGIN=1, function(x) sample(x=1:3, size=1, prob=x))\nord_dat <- data.frame(Y=y.ord,X1=x1,X2=x2)\ntable(y.ord)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "",
    "text": "Welcome to the IDS 702 course site!"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course Overview",
    "text": "Course Overview\nMeeting times: Tuesdays and Thursdays 3:05-4:20 PM, Gross Hall 107\nInstructor \nAndrea Lane, PhD \nandrea.lane@duke.edu \nGross Hall 223 \nOffice hours: Tues/Thurs 4:20-5:20 PM\n \nTeaching Assistants \nXiaoquan Liu \nx.liu@duke.edu \nOffice hours: Mon 8:15-9:15AM on Zoom (click here for Zoom link), Thurs 11:30AM-12:30PM Gross Hall 2nd floor conference room\n \nDingkun Yang \ndingkun.yang@duke.edu \nOffice hours: Tues 11:35AM-12:35PM Gross Hall 2nd floor conference room, Weds 3:15-4:15PM on Zoom (click here for Zoom link)"
  },
  {
    "objectID": "index.html#important-links",
    "href": "index.html#important-links",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Important Links",
    "text": "Important Links\nGradescope (join course with code 2PGWK8)\nSlack: join the 702-fa23 channel in the MIDS workspace\nDuke R container"
  },
  {
    "objectID": "index.html#textbook",
    "href": "index.html#textbook",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Textbook",
    "text": "Textbook\nAn Introduction to Statistical Learning with Applications in R, 2nd edition by James, G., Witten, D., Hastie, T., and Tibshirani, R.\nUse the link above to download a PDF of the book"
  },
  {
    "objectID": "index.html#important-dates",
    "href": "index.html#important-dates",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Important Dates",
    "text": "Important Dates\n\n\n  \n    \n      Tuesday, Aug. 29\n      First day of class\n    \n    \n      Friday, Oct. 6 11:59 PM\n      Statistics reflection due\n    \n    \n      Tuesday, Oct. 17\n      Fall break - no class meeting\n    \n    \n      Thursday, Oct. 19 IN CLASS\n      DA2 due for peer review in class\n    \n    \n      Tuesday, Oct. 24 11:59 PM\n      Project - EDA Report due\n    \n    \n      Friday, Oct. 27 11:59 PM\n      DA2 due\n    \n    \n      Sunday, Oct. 29 11:59 PM\n      Statistics reflection due\n    \n   \n      Friday, Nov 3 11:59 PM\n      Project - Statistical Analysis Plan due\n    \n   \n      Friday, Nov. 17 11:59 PM\n      DA3 due\n    \n    \n      Sunday, Nov. 19 11:59 PM\n      Statistics reflection due\n    \n    \n      Tuesday, Nov. 21 \n      Thanksgiving holiday - no class meeting (project office hours on zoom) \n    \n   \n      Wednesday, Nov 22 11:59 PM\n      Project (OPTIONAL) - Submit final report draft for feedback\n    \n    \n      Thursday, Nov. 23 \n      Thanksgiving holiday - no class meeting \n    \n   \n      Tuesday, Nov 28 in class\n      Project presentations - odd number groups\n    \n   \n      Thursday, Nov 30 in class\n      Project presentations - even number groups\n    \n   \n      Friday, Dec 1 11:59 PM\n      Project final reports - even number groups\n    \n   \n      Sunday, Dec 3 11:59 PM\n      Project final reports - odd number groups\n    \n\n        \n      Friday, Dec 1 \n      Classes end"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "test page",
    "section": "",
    "text": "Linear regression"
  },
  {
    "objectID": "project/eda.html",
    "href": "project/eda.html",
    "title": "Exploratory Data Analysis Report",
    "section": "",
    "text": "The purpose of the exploratory data analysis report is to practice thinking critically about your dataset and how it connects to your research questions. You will always need to explore data before you analyze it, but this should be an intentional process. Additionally, when you present EDA results to a client, they should always be well-formatted and clearly connected to the research question. Therefore, the purpose of this part of the group project is to practice exploring data and effectively communicating the results of the exploratory data analysis."
  },
  {
    "objectID": "project/eda.html#eda-report",
    "href": "project/eda.html#eda-report",
    "title": "Exploratory Data Analysis Report",
    "section": "EDA Report",
    "text": "EDA Report\nYou will generate a report (in Quarto) detailing your exploratory data analysis results. The report is required to be at most 5 pages, including tables and figures. Tables and figures must be well-formatted with clear labels and descriptions. This means you should always use variable descriptions instead of “raw” variable names (e.g., “Salary ($)” instead of “salary_in_usd”).\nThe report should be organized in the following sections.\n\nData Overview: Provide the chief characteristics of your data, including sample size, number of variables, and source (you can use any citation format, but include more than just the link). Briefly describe how the data were collected. What does each row represent? Include your research questions in this section.\nOutcome variables: Present a plot for each of your outcome variables. Describe the plots.\nPrimary relationships of interest: Present descriptive statistics and exploratory plots in whichever format you think is best (tables, figures) for your primary relationship of interest (dependent variable and primary independent variable, if applicable). Describe your findings. Whether you have one primary independent variable of interest or multiple will depend on your research question.\nOther characteristics: Briefly describe other variables in the data. If there are many, do not list them all. Rather, describe the types of variables that are present (e.g., “demographic information”).\nPotential challenges: Describe aspects of the data that may present challenges in the modeling stage. For example, might certain categorical variables need to be collapsed? Do you have any missingness, particularly in key variables of interest? Could the size of the dataset present model selection challenges?\n\nNo data cleaning is required for the EDA report, with the exception of combining datasets or creating an outcome variable, if applicable. Your report is required to be generated with Quarto and rendered directly to PDF. You will not be required to submit the quarto file. You will submit a single qmd when you submit your final report at the end of the semester.\nSubmit one report per group. One person will submit and select the other group members in the Gradescope submission. Be sure to assign pages in Gradescope when you submit."
  },
  {
    "objectID": "project/eda.html#suggestions",
    "href": "project/eda.html#suggestions",
    "title": "Exploratory Data Analysis Report",
    "section": "Suggestions",
    "text": "Suggestions\n\nYou might consider using one of the EDA packages mentioned in one of the class exercises: DataExplorer and SmartEDA. Make sure you can modify the table and figure labels.\nIf you have a binary/categorical variable of interest, you should consider generating a table 1, in which descriptive statistics are given for different levels of a categorical variable. This page has examples, but if you use the package, make sure it will render to pdf.\nIt is fine to use visual editor to produce tables. However, if you want to generate a more advanced (and “prettier”) table, the kableExtra package is a good option.\nUse github to share code among group members. As a group, plan the tables and figures you want to generate, and split them up among the group members. Then you can consolidate your code to generate the report."
  },
  {
    "objectID": "project/sap.html",
    "href": "project/sap.html",
    "title": "Statistical Analysis Plan",
    "section": "",
    "text": "The purpose of the statistical analysis plan is to practice articulating the process you will use to answer your research questions. Some decisions about the modeling and analysis process must be made a priori. This is a chance to practice making those decisions and get feedback on your analysis plan prior to completing your final report."
  },
  {
    "objectID": "project/sap.html#statistical-analysis-plan",
    "href": "project/sap.html#statistical-analysis-plan",
    "title": "Statistical Analysis Plan",
    "section": "Statistical Analysis Plan",
    "text": "Statistical Analysis Plan\nYou will generate a 1-2 page statistical analysis plan that contains the elements listed below. You do not need to run any code for this, so you can generate this plan however you’d like (e.g., quarto, Rmd, Word). Note that you should always use variable descriptions instead of “raw” variable names (e.g., “Salary ($)” instead of “salary_in_usd”).\n\nData Overview: Provide the chief characteristics of your data, including sample size, number of variables, and source (you can use any citation format, but include more than just the link). Briefly describe how the data were collected. What does each row represent? Include your research questions in this section. (This is exactly the same as the EDA report, so you can copy and paste).\nModeling: For each research question, address the following:\n\nWhat kind of model will you fit?\nIs your question related to inference or prediction? How does this affect your modeling process including variable selection and model assessment?\nList the variables that you are selecting a priori to include in your model (if there are many predictors in your dataset, you can specify broad categories instead of specific variables. Remember to use variable labels instead of raw variable names).\nYou are required to include at least one interaction term in your model. Specify the interaction term that is meaningful for your research question. For example, you could say something like “we are interested in how the relationship between vaccination rate and COVID infection totals changed over time, so we will include an interaction term with month and vaccination rate.”\n\nPotential challenges: How might you address the challenges that you identified in your EDA report?\n\nSubmit one report per group. One person will submit and select the other group members in the Gradescope submission. Be sure to assign pages in Gradescope when you submit."
  },
  {
    "objectID": "project/reportandpres.html",
    "href": "project/reportandpres.html",
    "title": "Final Report and Presentation",
    "section": "",
    "text": "Odd number groups:\n\nPresentation: Nov 28\nReport: Dec 3\n\nEven number groups:\n\nPresentation: Nov 30\nReport: Dec 1"
  },
  {
    "objectID": "project/reportandpres.html#purpose",
    "href": "project/reportandpres.html#purpose",
    "title": "Final Report and Presentation",
    "section": "Purpose",
    "text": "Purpose\nNow that you have selected and explored a dataset and written a statistical analysis plan, it is time to carry out your analysis and present your results! Your team will present your results that address your research questions in two ways: a report and a presentation."
  },
  {
    "objectID": "project/reportandpres.html#final-report",
    "href": "project/reportandpres.html#final-report",
    "title": "Final Report and Presentation",
    "section": "Final Report",
    "text": "Final Report\nYour report will be an 8-10 page self-contained document describing your analysis. It should be written as a professional document that can be understood by someone with limited statistics background (e.g., a client). You are also required to submit a single QMD file that includes your code for the EDA and analysis. The report should be organized as follows:\n\nAbstract: A few sentences describing the purpose of the analysis, the data, and key results\nIntroduction: Provide more background on the data and research questions. Be sure to cite the data and background information appropriately (APA style is fine). Why are these questions worth exploring?\nMethods: Describe the process you used to conduct analysis. This includes EDA and any relevant data cleaning information (e.g., did you exclude missing values? If so, how many? Did you collapse categories for any variables?). Then describe the models you fit, and how you planned to assess the model, including influential points, multicollinearity, and diagnostics. The organization of this section may depend on your particular dataset/analysis, but you may want to break it into subsections such as “Data,” “Models,” and “Model assessment.” Note that you do not present any results in this section. This section reflects your statistical analysis plan. For example, you will state how you went about EDA but you will not present findings of the EDA.\nResults: Here you should present results for all aspects of the analysis. The structure of this section should mirror the structure of the methods section. For example, you can start with a few key EDA results (e.g., a table of descriptive statistics), then present model results, then address assessment. This is the section where you will primarily refer to tables and figures. You should have at least 1 figure for each research question that illustrates a key result of the analysis (not a diagnostic plot).\nConclusion: Describe the key takeaways from your analysis, limitations, and future work that can be done to advance knowledge in this area.\n\nA few things to keep in mind:\n\nYou should never refer to actual variable names in the text, tables, or figures. For example, if a variable for height is called “ht__cm,” you should always say “height,” and the first time you mention it you should state that it is measured in cm. In plots and tables, it should say “height (cm)”\nThe report should be produced in Quarto and rendered to PDF. All tables and figures should use appropriate labels.\nSomeone should be able to read the abstract and look at the tables and figures and have a pretty good idea of 1) the goals of your analysis, and 2) the key results.\nI recommend using colorblind-friendly color palettes in your figures. It can be even better to differentiate with line types or symbols instead of relying on color.\nKeep you audience in mind! A non-statistician should be able to read your report and have a good idea of what you did, even if they may not understand all of the technical details.\nYou can have an appendix if tables or figures are too large to fit into the main text. For example, if you have several predictors, you may want to put a table of model results in the appendix."
  },
  {
    "objectID": "project/reportandpres.html#presentations",
    "href": "project/reportandpres.html#presentations",
    "title": "Final Report and Presentation",
    "section": "Presentations",
    "text": "Presentations\nYour team will record an 8-minute presentation on your analysis. All team members are required to participate in the presentation. We will play the recorded presentations in class and then allow time for 1-2 questions for the team. The presentation schedule will be tight, so be sure that your presentation does not exceed 8 minutes. The presentation should be organized as follows:\n\nBackground: Provide clear motivation, data source, and research questions\nMethods: Briefly describe the models you used to answer your research questions\nResults: What did you find? (This should be the majority of your presentation)\nConclusion: Present limitations and future directions\n\nThings to keep in mind:\n\nEach team member must present\nThe presentation should be focused on the motivation and results of your analysis rather than data cleaning or technical details of the model. Prioritize creating clear plots/visuals that communicate your message.\nFocus on storytelling. Why is it important/interesting to answer these research questions? What did you find that is compelling? How might the work be continued in the future?\nYou can use any program you’d like to create your slides (powerpoint, keynote, Quarto, etc.)\nPlan to spend a lot of time creating nice slides. This is not something that should be thrown together at the last minute. I am happy to review slides and offer feedback."
  },
  {
    "objectID": "project/reportandpres.html#submission",
    "href": "project/reportandpres.html#submission",
    "title": "Final Report and Presentation",
    "section": "Submission",
    "text": "Submission\nSubmit one report and one qmd file per group. One person will submit and select the other group members in the Gradescope submission. Be sure to assign pages in Gradescope when you submit.\nOptional: If you would like me to provide some feedback on your report, you can submit a draft by Nov 22."
  },
  {
    "objectID": "project/reportandpres.html#example",
    "href": "project/reportandpres.html#example",
    "title": "Final Report and Presentation",
    "section": "Example",
    "text": "Example\nRefer to this paper that presents a statistical analysis on low birth weight infants who receive blood transfusions. In particular, notice the distinction between the methods and results section. Notice how the methods section describes how the analysis was carried out without reporting any results.\nThe length of the sections of this paper will likely differ from your report. I would expect your introduction and conclusion sections to be shorter, but your methods and results to be longer (if for no other reason than you have two research questions to present)."
  },
  {
    "objectID": "project/proposal.html",
    "href": "project/proposal.html",
    "title": "Proposal",
    "section": "",
    "text": "The purpose of the team project is to provide an opportunity to complete a data analysis project from start to finish. This includes:\n\nSelecting data\nWriting research questions\nPerforming exploratory data analysis\nDeveloping appropriate statistical models\nCommunicating results through a written report and presentation\nWorking with a team"
  },
  {
    "objectID": "project/proposal.html#teams",
    "href": "project/proposal.html#teams",
    "title": "Proposal",
    "section": "Teams",
    "text": "Teams\nSee this sheet for your team assignment. You are responsible for dividing the work equitably among team members. Every team member is required to contribute to each portion of the project: coding, writing, and presenting. Learn from each other and, most of all, be kind. You will receive individual grades for the project that incorporate feedback from fellow team members."
  },
  {
    "objectID": "project/proposal.html#data",
    "href": "project/proposal.html#data",
    "title": "Proposal",
    "section": "Data",
    "text": "Data\nYour first step is to select the dataset that you are most interested in analyzing. Below is a list of datasets or sources that you can consider using to find a dataset. You are not require to use these.\nYour dataset must have at least 500 observations, 10 variables, and a mix of numeric and categorical variables. You may not use a dataset that we have used in class.\n\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nPew Research\n2021 CDC Behavioral Risk Factor Surveillance System Survey\nWorld Inequality Database\n\nYou are welcome to specify a subset of a particular dataset (e.g., only North Carolina in the CDC BRFSS). Be sure to look at the data to understand its scope."
  },
  {
    "objectID": "project/proposal.html#proposal",
    "href": "project/proposal.html#proposal",
    "title": "Proposal",
    "section": "Proposal",
    "text": "Proposal\nYour proposal should list the following:\n\nTeam member names\n2 or 3 datasets of interest (list in order of preference with 1 being the top choice). For each dataset, provide:\n\n\nThe source of the data, when and how it was originally collected, and a brief description of the observations. This information is likely found on the website where you found the data, so be sure to cite your source\nTWO research questions you are interested in exploring for each dataset. Explicitly state the outcome variables in the dataset that you will use to answer each question. You are required to use two different types of outcome variables for your research questions. For example, one research question may use a continuous outcome variable while the other uses an ordinal outcome variable. Variable types may include: continuous, binary, ordinal, nominal, time-to-event\na glimpse() of each dataset to show that you can access it in R\n\nConsult this helpful guide for writing a good research question\nNo data cleaning is required in the proposal. Your proposal should be generated with a Quarto document, but you will not be required to submit the code.\nSubmit one proposal per group. One person will submit and select the other group members in the Gradescope submission. After you submit, I will provide feedback to help you decide which dataset to choose for your project."
  },
  {
    "objectID": "reflections.html",
    "href": "reflections.html",
    "title": "Statistics Reflections",
    "section": "",
    "text": "In the MIDS program, we emphasize thinking critically about data analysis and upholding principles of diversity, equity, and inclusion. Quantitative fields like data science are often viewed as “amoral,” but human judgment always plays a role in data collection and analysis. As data scientists, we must carefully consider the societal factors that play a role in our work. The materials presented with this assignment explore how statistics/data science interact with society at large.\nThis assignment connects to the third course learning objective: Make careful and critical decisions about model building and consider real-world implications."
  },
  {
    "objectID": "reflections.html#instructions",
    "href": "reflections.html#instructions",
    "title": "Statistics Reflections",
    "section": "Instructions",
    "text": "Instructions\nYou are required to complete four statistics reflections throughout the semester. You can select any four from the list of materials below.\n\nBegin your assignment with a header that includes your name and the title and source of your selected material\nReflect on the material selected. What did it make you think about? How does it affect your work as a data scientist? Note that you are required to engage with the material and provide your thoughts/reactions; you should NOT be summarizing the piece.\nWhile there is no minimum word count for the reflections, you are expected to meaningfully engage with the material (2-3 paragraphs). You can use the suggested questions to get started, but you are not required to answer them in your response.\nIn Gradescope, select the appropriate reflection assignment based on the due date. All of the assignments are already available, so you can complete them at any time!\n\nI am always available if you have any questions or comments about the content presented in these materials. Additionally, if you come across a piece that is not on this list and you would like to use it for a statistics reflection, you are welcome to send me an email. Please include a link to the piece and a brief description of how it connects data science and society."
  },
  {
    "objectID": "reflections.html#deadlines",
    "href": "reflections.html#deadlines",
    "title": "Statistics Reflections",
    "section": "Deadlines",
    "text": "Deadlines\n\nSeptember 15, 11:59 PM\nOctober 6, 11:59 PM\nOctober 27, 11:59 PM\nNovember 17, 11:59 PM\n\nSubmit your reflection to the appropriate assignment on Gradescope"
  },
  {
    "objectID": "reflections.html#materials",
    "href": "reflections.html#materials",
    "title": "Statistics Reflections",
    "section": "Materials",
    "text": "Materials\n\n  \n    \n      \n        A Primer on Non-Binary Gender and Big Data (article)\n      \n    \n    \n      \n        A Primer on Non-Binary Gender and Big Data \n        The author offers several questions you may want to consider in your response: \n        \n          What potential insights might we derive from working with non-binary gender and data?\n          What are the risks to gener minorities in relation to data?\n          What kinds of variation do we see across culture, context, and history?\n          How might non-binary gender and data deal with intersectionality (Click this link to learn more about intersectionality)\n        \n        Additionally, you may want to consider: \n        \n          Is it always useful/important to collect data on gender? In which domains might it be more important than others?\n        \n      \n    \n  \n  \n    \n      \n        How Eugenics Shaped Statistics (article - highly recommended!)\n      \n    \n    \n      \n        How eugenics shaped statistics \n        \n          Consider this quote: \"The separation was everything—not how much, what else might explain it, or why it mattered, just that it was there.\" Reflect on what this means for you as a data scientist\n          The article argues that you cannot separate the science from the scientist. Do you agree?\n          Reflect on the argument that Galton, Pearson, and Fisher's views are \"a product of their time.\"\n        \n        \n      \n    \n  \n  \n    \n      \n        Abolish Big Data (video)\n      \n    \n    \n      \n        Abolish Big Data \n        \n          What does Milner mean when she says \"abolish big data?\"\n          What role does data literacy play in the use of big data tools? What role do data scientists have in the implementation of these tools?\n        \n      \n    \n  \n    \n    \n      \n        Data sonification (videos)\n      \n    \n    \n      \n        Data sonification - from deep space research to improving lives through cancer research AND \n        Making data sing | Margaret Anne Schedel \n        \n          What are the advantages and disadvantages of data sonification?\n          How might data sonification make data more accessible to people with disabilities? Can you think of any other ways data could be made more accessible?\n        \n      \n    \n  \n    \n    \n      \n        Fairness in Machine Learning with Sherri Rose (podcast)\n      \n    \n    \n      \n        Fairness in Machine Learning with Sherri Rose  (interview starts at 8:15 and ends at 46:00)\n        \n          Reflect on Dr. Rose's recommendations for ensuring fairness in machine learning\n          Consider Dr. Rose's comments about the \"single metric leaderboard\" and what it means for you as a data scientist.\n        \n      \n    \n  \n    \n    \n      \n        Peter Donnelly: How stats fool juries (video)\n      \n    \n    \n      \n        Peter Donnelly: How stats fool juries (you can skip past the stats jokes and start at 3:30) \n        \n          This talk is from 2007. Can you think of more recent examples of misleading statistics/misuse of statistical principles?\n          How do you think situations like the trial Donnelly describes can be avoided?"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "",
    "text": "Developing an understanding of statistical modeling is a key component of becoming a data scientist. Statistical models are used to answer research questions and obtain meaningful insights from many kinds of data.\nBroadly, this course will cover the following topics:\n\nLinear Regression\nGeneralized Linear Models\nSpecial topics, including survival models and hierarchical models\n\nBut here in the MIDS program, understanding the content is only the beginning. Successful data scientists are critical thinkers, problem solvers, effective communicators, and enthusiastic collaborators. With that in mind, this course aims to meet four key learning objectives:\nBy the end of the course, students should be able to\n\nFit and interpret statistical models, including linear and generalized linear models.\nMap a research question and dataset to the appropriate statistical model\nMake careful and critical decisions about model building and consider real-world implications\nCommunicate (through written and oral communication) model results to a broad audience"
  },
  {
    "objectID": "syllabus.html#course-components",
    "href": "syllabus.html#course-components",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course Components",
    "text": "Course Components\n\nClasswise\nWe will use a platform called Classwise for lecture videos before class meetings. You will be required to engage with prep materials (mostly videos) and answer comprehension questions in Classwise before coming to class. The prep materials will primarily cover theoretical modeling concepts. Class meetings will then focus on implementation in R and application exercises. Classwise materials will be posted on the course website.\nThe Classwise course component connects to the first learning objective: Fit and interpret statistical models, including linear and generalized linear models.\n\n\nApplication exercises\nDuring class meetings, we will complete application exercises. The goal of these exercises is to practice implementing and interpreting statistical models in R. You are encouraged to work on these exercises in small groups.\nThe application exercise course component connects to the first learning objective: Fit and interpret statistical models, including linear and generalized linear models.\n\n\nData analysis assignments\nYou will have three data analysis assignments to complete during the semester. Data analysis assignments require fitting and interpreting statistical models and communicating results to a broad audience. Each assignment will have a unique structure to develop written and oral communication skills.\nYou are encouraged to talk to each other about general concepts, or to the instructor/TAs. However, the write-ups, solutions, and code MUST be entirely your own work. The assignments must be typed up using Quarto and submitted on Gradescope. Note that you will not be able to make online submissions after the due date, so be sure to submit before the Gradescope-specified deadline.\nData analysis assignments connect to all four learning objectives.\n\n\nStatistics reflections\nYou will be responsible for four statistics reflections throughout the semester. I have assigned six pieces that cover various topics related to the interaction between data science and society. You are to write a written reflection about the material that you select. Questions are provided as prompts, but you are not required to answer them in your reflection. Grades will be based on completion and thoughtful engagement. The chosen articles/videos address topics that may be sensitive and/or uncomfortable, including racism, eugenics, and gender identity. It is crucial that you engage in the reflections thoughtfully and respectfully. I seek to create a classroom environment that not only acknowledges diversity in all forms, but celebrates it. In that endeavor, I would be remiss not to acknowledge the discriminatory ways statistical science has been used both historically and currently. In having these important discussions, I want you to critically examine and appreciate the power (good and bad) of statistics as you begin your career as a data scientist. More information can be found on the statistics reflections page on the course website.\nStatistics reflections connect to the third course learning objective: Make careful and critical decisions about model building and consider real-world implications\n\n\nTeam project\nYou and your team will apply the knowledge and skills learned throughout this course to analyze a dataset that interests you. The project should be an in-depth statistical analysis of a particular research question. Your team will select the dataset. Teams will be assigned. More detailed information will be available on the course website. The project will have multiple components:\n\nProposal\nExploratory data analysis report\nStatistical analysis plan\nFinal deliverable and presentation\nTeam member evaluation\n\nThe team project connects to all four course learning objectives."
  },
  {
    "objectID": "syllabus.html#grade-calculation",
    "href": "syllabus.html#grade-calculation",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Grade Calculation",
    "text": "Grade Calculation\n\n\n\nComponent\nPercentage\n\n\n\n\nParticipation (Classwise)\n10%\n\n\nStatistics reflections\n15%\n\n\nData analysis assignments\n45%\n\n\nTeam project\n30%\n\n\n\nLetter grade scales may be adjusted at the end of the semester. Cumulative averages \\(\\geq 90\\%\\) are guaranteed at least an A-, cumulative averages \\(\\geq 80\\%\\) are guaranteed at least a B-, and cumulative averages \\(\\geq 70\\%\\) are guaranteed at least a C-\nRegrade requests can be made on Gradescope within 24 hours of the assignment’s grade release. Regrade requests for final project reports/presentations must be made within 12 hours of grade release.\nThere are no make-ups for any graded work except for cases of medical/personal/familial emergencies. Make-ups/extension requests must be made to the instructor BEFORE the assignment deadline."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course policies",
    "text": "Course policies\n\nLate submissions\nYou (or your team when applicable) will lose 50% of the total points on each assignment if you submit within the first 24 hours after it is due. You will lose 100% of the total points if you submit later than that without explicit approval from the instructor.\n\n\nClass meeting attendance\nI expect all students to attend all class meetings. However, I know that things come up once in a while. Therefore, I expect 90% attendance each class period. If class meeting attendance begins to consistently drop below the 90% threshold, I will institute a more stringent, individual attendance policy. Note that class meetings will not be recorded.\n\n\nAcademic integrity\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course. This means that the work you submit is your own, even if you discuss assignments with your classmates. Additionally, when consulting resources (books, internet articles including stackexchange, chatgpt), you must cite them. If you have any questions about what should be cited in your work, feel free to reach out to the instructor.\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s commitment to diversity and inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, I encourage you to speak with MIDS administrators.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know."
  },
  {
    "objectID": "syllabus.html#resources",
    "href": "syllabus.html#resources",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Resources",
    "text": "Resources\n\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS offers many services to Duke students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations. The Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nThe Academic resource center provides learning resources to help you maximize your academic capabilities."
  },
  {
    "objectID": "introtomlrcode.html",
    "href": "introtomlrcode.html",
    "title": "Intro to MLR",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.4.0     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2…\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, …\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34…\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16…\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385…\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, …\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7…\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, …\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa…\n\n\n\nlibrary(tidyverse)\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2…\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, …\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34…\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16…\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385…\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, …\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7…\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, …\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa…\n\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\")\n\n\n\n\n\n#MLR model regressing mpg on weight and origin\nmlr_mod_auto <- lm(mpg~weight+origin,\n                   data=Auto)\n\nsummary(mlr_mod_auto)\n\n\nCall:\nlm(formula = mpg ~ weight + origin, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.0698  -2.7888  -0.3122   2.4489  15.4816 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.4908175  1.3266161   32.03  < 2e-16 ***\nweight      -0.0070071  0.0003136  -22.34  < 2e-16 ***\norigin       1.1540278  0.3306915    3.49 0.000539 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.272 on 389 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.7004 \nF-statistic: 458.1 on 2 and 389 DF,  p-value: < 2.2e-16\n\n\n\n#create a factor variable\nAuto$origin_fac <- factor(Auto$origin,\n                          levels=c(1,2,3),\n                          labels=c(\"American\",\n                                   \"European\",\n                                   \"Japanese\"))\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n\n\n\n\nmlr_mod_fac <- lm(mpg~weight+origin_fac,\n                  data=Auto)\n\nsummary(mlr_mod_fac)\n\n\nCall:\nlm(formula = mpg ~ weight + origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1339  -2.7358  -0.3032   2.4307  15.4544 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        43.7322362  1.1134286  39.277  < 2e-16 ***\nweight             -0.0070271  0.0003201 -21.956  < 2e-16 ***\norigin_facEuropean  0.9709056  0.6587673   1.474 0.141340    \norigin_facJapanese  2.3271499  0.6648043   3.501 0.000518 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.277 on 388 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.6997 \nF-statistic: 304.7 on 3 and 388 DF,  p-value: < 2.2e-16\n\n\nOn average, European cars’ mpg is 0.97 higher than American cars’ mpg, holding all else constant. This difference is not statistically significant at the 0.05 level (p=0.14).\nOn average, per increase in weight (lb), mpg decreases by 0.007, all else constant. This is statistically significant (p<0.001), so vehicle weight is associated with mpg."
  },
  {
    "objectID": "introtomlrcode.html#interaction",
    "href": "introtomlrcode.html#interaction",
    "title": "Intro to MLR",
    "section": "Interaction",
    "text": "Interaction\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nmlr_mod_interact <- lm(mpg~weight*origin_fac,\n                       data=Auto)\nsummary(mlr_mod_interact)\n\n\nCall:\nlm(formula = mpg ~ weight * origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4928  -2.7715  -0.3895   2.2397  15.5163 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                4.315e+01  1.186e+00  36.378  < 2e-16 ***\nweight                    -6.854e-03  3.423e-04 -20.020  < 2e-16 ***\norigin_facEuropean         1.125e+00  2.878e+00   0.391  0.69616    \norigin_facJapanese         1.111e+01  3.574e+00   3.109  0.00202 ** \nweight:origin_facEuropean  3.575e-06  1.111e-03   0.003  0.99743    \nweight:origin_facJapanese -3.865e-03  1.541e-03  -2.508  0.01255 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.253 on 386 degrees of freedom\nMultiple R-squared:  0.7068,    Adjusted R-squared:  0.703 \nF-statistic: 186.1 on 5 and 386 DF,  p-value: < 2.2e-16\n\n\nPer lb increase in weight, mpg increases by an additional 0.0000036, on average, all else held constant, for European cars compared to American cars. This difference is not statistically significant (p>0.99).\nPer lb increase in weight, mpg decreases by 0.011, on average, for European cars. For American cars, mpg decreases by 0.007, on average, per lb increase in weight. The difference in effects, 0.004, is statistically significant at the 0.05 level (p=0.013)."
  },
  {
    "objectID": "extracredit.html",
    "href": "extracredit.html",
    "title": "Extra Credit Assignment",
    "section": "",
    "text": "Friday, December 15, 11:59 PM\nNote: ate submissions will not be accepted because I have to submit final grades shortly after the deadline."
  },
  {
    "objectID": "extracredit.html#extra-credit-calculation",
    "href": "extracredit.html#extra-credit-calculation",
    "title": "Extra Credit Assignment",
    "section": "Extra credit calculation",
    "text": "Extra credit calculation\nIf you complete this assignment, the score will count for 50% of your lowest data analysis assignment score. In other words, I will take the mean of your score on this assignment and your lowest DAA score and that will be 15% of your final course grade. If you complete this assignment and the score happens to be lower than your lowest DAA score, then I will not factor this into your final grade."
  },
  {
    "objectID": "extracredit.html#assignment",
    "href": "extracredit.html#assignment",
    "title": "Extra Credit Assignment",
    "section": "Assignment",
    "text": "Assignment\nImagine that a friend approaches you and makes the following claim:\n“I heard that the COVID vaccine gives people amnesia”\nYou find this journal article that relates to your friend’s statement:\nMerino, D., Gérard, A. O., Van Obberghen, E. K., Ben Othman, N., Ettore, E., Giordana, B., ... & Drici, M. D. (2022). COVID-19 vaccine-associated transient global amnesia: A disproportionality analysis of the WHO safety database. Frontiers in Pharmacology, 13, 909412.\nClick here to download the article\nFor this assignment, you will write a report that answers the following question: Does the statistical analysis presented in the article support your friend’s statement?\nThere is no page limit or minimum for this assignment; you are expected to thoroughly respond to the question above using the principles and concepts we have discussed throughout the semester. No code needs to be written for this, so you do not need to generate the report in R/Quarto. You will submit your report as a PDF. Be sure to cite the journal article appropriately.\nAddress the questions below in your report to guide your response (note: this should still be written as a report, not as bulleted answers to the list of questions):\n\nWhat is the research question that the article seeks to answer?\nWhat is the outcome of interest?\nHow were the data collected?\nWhat are the comparison groups?\nWhat is the statistical analysis method used?\nIs the statistical analysis method appropriate? How can it be improved?\nGiven your answers to the questions about the structure of the data and the analysis, distinguish between the following:\n\nthe conclusion that your friend drew\nthe conclusion that the authors drew\nthe conclusion that can be drawn based on the analysis"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Getting started with R and RStudio\nR for Data Science\nCheatsheets (RStudio, Quarto, ggplot2, dplyr)\nQuarto documentation"
  },
  {
    "objectID": "resources.html#statistics",
    "href": "resources.html#statistics",
    "title": "Resources",
    "section": "Statistics",
    "text": "Statistics\nPractical Statistics for Data Scientists (available online)\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nDr. Mine Çetinkaya-Rundel’s YouTube channel (includes R)"
  }
]