[
  {
    "objectID": "materials/unit1/prediction.html",
    "href": "materials/unit1/prediction.html",
    "title": "9.19 and 9.21: Prediction",
    "section": "",
    "text": "distinguish between inference and predictive modeling\nuse cross validation to assess predictive models"
  },
  {
    "objectID": "materials/unit1/prediction.html#classwise-videos",
    "href": "materials/unit1/prediction.html#classwise-videos",
    "title": "9.19 and 9.21: Prediction",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nHaving technical issues, but you can click the links to watch the videos and download the annotated notes.\nVideo 1: Prediction intro\nVideo 2: Prediction modeling metrics\nVideo 3: Cross validation\nNotes:\nVideo 1 \nVideo 2 \nVideo 3"
  },
  {
    "objectID": "materials/unit1/prediction.html#textbook",
    "href": "materials/unit1/prediction.html#textbook",
    "title": "9.19 and 9.21: Prediction",
    "section": "Textbook",
    "text": "Textbook\nISLR 2.1.1, 2.1.3, 2.2"
  },
  {
    "objectID": "materials/unit1/prediction.html#application-exercise-919",
    "href": "materials/unit1/prediction.html#application-exercise-919",
    "title": "9.19 and 9.21: Prediction",
    "section": "Application Exercise (9/19)",
    "text": "Application Exercise (9/19)\nGroups for today‚Äôs exercise\nToday‚Äôs exercise will help you to solidify your understanding of (R)MSE and k-fold cross validation by ‚Äúmanually‚Äù implementing them in R.\nYou should be familiar with the following coding concepts: writing functions, for loops, and if-else statements. If you are not familiar with how to write these things in R, consult the R for Data Science resource (Functions, Iteration).\nWrite a function that performs \\(K\\)-fold cross validation. The function should take 3 inputs: a dataset, a value of \\(K\\), and an evaluation metric. The options for the evaluation metric should be adjusted \\(R^2\\) , MSE, and RMSE.\nThe end goal is to be able to compare predictive ability of different models. For example, you may want to use your function with the Auto dataset to do the following:\n\nlibrary(ISLR2)\ndata(\"Auto\")\n\n#you can name your function whatever you'd like. Note that to compare different models, we want to use the same metric and value of K. You can specify the models you want to compare within the function. For example, you may want to compare three models with the Auto dataset: mpg regressed on displacement, weight, and acceleration; mpg regressed on displacement, weight, acceleration, and a factor variable for cylinder; and mpg regressed on displacement, weight, acceleration and interaction terms for displacement and factored cylinders and weight and factored cylinders. You can also take the extra step of making the function more general for comparing models, but that is more complicated.\ncrossval(Auto, K=10, metric=\"RMSE\")\n\nYou are welcome to make the function more complex (additional inputs, etc). For example, maybe you‚Äôd like your function to take multiple models and return the model with the best metric (lowest MSE/RMSE or highest Adj \\(R^2\\) )\nYou should consider using the following:\n\nthe predict() function takes a model object and ‚Äúnewdata‚Äù and returns all of the predicted values. You can use this to calculate test MSE and RMSE. Use the formula for MSE and RMSE and nested functions to calculate each of these in a single line of code. Run ?predict in the console to learn more.\nAdjusted \\(R^2\\) can be accessed in the summary(lm()) output, i.e., summary(mod_object)$adj.r.squared\nThe caret package has a function called createFolds() that you can use in your function to create the \\(K\\) folds in the given dataset. You can also try doing this manually with the sample(), cut(), or split() functions.\n\n\nGoing Further\nIf you have extra time, you can consider some extensions:\n\nAdd function inputs to make it more general. For example, the user could specify models to compare\nUse the trainControl() and train() functions from the caret package to perform k-fold cross validation. Compare the results to what you get using your function.\nSimulate data and use your function to better understand the effects of sample size and value of \\(k\\). The rnorm() function generates a vector of random values from the normal distribution. You can specify the mean and standard deviation of the distribution from which you take random draws. You can then add outliers to your predictors to see the effect of small samples and extreme values in the cross validation splits."
  },
  {
    "objectID": "materials/unit1/prediction.html#application-exercise-921",
    "href": "materials/unit1/prediction.html#application-exercise-921",
    "title": "9.19 and 9.21: Prediction",
    "section": "Application Exercise (9/21)",
    "text": "Application Exercise (9/21)\nUse the same groups that you were in on Tuesday.\nNote: Focus on #1-4. Particularly for folks who are new to stats/R, skip the ‚Äúgo further‚Äù parts and come back to them if you have time.\nFor this exercise, we will use the Boston dataset from the ISLR2 package.\nClick here for the data dictionary\nWe want to build a model to predict the median home value from various predictors.\n\nStart by using the data dictionary to determine if any data cleaning needs to be done. Is there any missing data?\nFit the full model. The code below uses the caret package to perform k-fold cross validation and produces RMSE, \\(R^2\\) , and MAE. The trainControl function establishes the method you will use to evaluate your model. In this case, we use the cross validation option for method (‚Äúcv‚Äù) and set number=10 for 10-fold cross validation. Then, the train function performs 10-fold CV on the indicated model. Note that the model syntax is the same as what we‚Äôve used in lm (the ‚Äú.‚Äù indicates that we want to regress on all variables in the dataset except the outcome). Then we specify method=\"lm\" for a linear model, and trControl=train_control to use the 10-fold CV method we stored in the train_control object. Finally, the print function gives us the model metrics.\n\nGo further: Run ?R2 in the console to find out how caret calculates \\(R^2\\) here. This may help to provide a more intuitive interpretation of out-of-sample \\(R^2\\)\n\n#note that cross validation involves a random sampling component, so we should use a seed for reproducibility\nset.seed(921) \n\ntrain_control <- trainControl(method = \"cv\",\n                                          number = 10)\n\nmod_full <- train(medv ~., data = Boston,\n                     method = \"lm\",\n                     trControl = train_control)\n\n#get model metrics\nprint(mod_full)\n\n\nLook at the diagnostics for the full model. Which assumptions appear to be violated (if any)? Would it help to transform the outcome or predictor variable(s)? Would an interaction term help? If our focus is prediction, how much should we prioritize model interpretability when we‚Äôre considering variable transformations?\n\nGo further: There are several R packages that can help efficiently visualize your data. As we‚Äôve seen before, visualizing can help determine if variable transformations/interaction terms may improve the model. You can explore packages like DataExplorer and SmartEDA.\n\nAfter you determine which transformations/interaction terms improve the model diagnostics, perform cross validation again on your new model. Do you notice a reduction in RMSE?\nWe can also use cross validation to perform variable selection. This can help to determine which combination of features leads to the best predictions. The freControl function establishes that we will use linear regression and cross validation. The rfe function performs the variable selection procedure. Using cross validation, we will assess the out-of-sample RMSE for a 1-variable model, 2-variable model, etc, and select the optimal predictors based on the lowest RMSE.\n\nset.seed(921)\n\nctrl <- rfeControl(functions = lmFuncs,\n                   method = \"cv\")\n\n# standardize the predictors so that they are comparable\n# You will need to edit this code if you transformed any variables or added interaction terms\nboston_standardize <- as.data.frame(scale(Boston))\nboston_standardize <- boston_standardize |> select(-c(\"medv\"))\n\nlmProfile <- rfe(boston_standardize, Boston$medv, #specify the X and Y variables\n                 sizes=c(1:12), # specify the number of variables you want to compare. Here we are assessing all possible numbers from 1-12 predictor variables\n                 rfeControl = ctrl)\n\nlmProfile #this gives the model metrics and shows which number of variables has been selected as optimal\npredictors(lmProfile) #this lists the predictors that were selected"
  },
  {
    "objectID": "materials/unit1/prediction.html#key-takeaways",
    "href": "materials/unit1/prediction.html#key-takeaways",
    "title": "9.19 and 9.21: Prediction",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nThe first exercise is designed to help you think through the steps of cross validation. Below is an example function (provided by one of your classmates üòÉ)\n\n\n#first, a function is written to calculate MSE\nMSE <- function(real_value, estimated_value){\n    result = (1/length(real_value))*sum((real_value-estimated_value)^2)\n    return(result)\n}\n\ncrossval <- function(df, k) { #CV function takes the data & # folds\n  metrics = c()\n  split_lst = df %>% #split the dataset into folds (could also use createFolds)\n    group_by((row_number()-1) %/% (n()/k)) %>%\n    nest %>%\n    pull(data)\n  for (i in 1:k) { #loop through folds\n    test_df <- split_lst[[i]]\n    train_df <- bind_rows(split_lst[-i]) #designates train & test set\n    model <- lm(data=train_df, mpg ~ acceleration + horsepower)\n    #calculate predicted values for MSE\n    preds = predict(model, test_df[c('acceleration', 'horsepower')])\n    mse = MSE(test_df[c('mpg')], preds) #use MSE function \n    metrics <- c(metrics, mse) #store test MSE for all values of k\n  }\n  return(meanMSE=mean(metrics)) #output the mean test MSE\n}\n\ncrossval(df=Auto, k=10) #run the function\n\n\nThe second exericse walks through the implementation of cross validation using the caret package. Note that with prediction problems, we don‚Äôt prioritize interpretation of the model. So, there is more flexibility to add variable transformations to improve model diagnostics. The biggest takeaway here was that adding transformations improve model diagnostics and reduce RMSE, thereby improving prediction accuracy of the model.\nWe can also perform variable selection with cross validation, which is a different process than the model selection procedures we introduced last week. Forward/backward/stepwise selection base inclusion decisions on p-values, which is frowned upon in the statistics community. The procedure in this exercise bases variable selection on cross validation and RMSE to improve predictions."
  },
  {
    "objectID": "materials/unit1/introMLR.html",
    "href": "materials/unit1/introMLR.html",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "",
    "text": "distinguish between the simple linear regression model and the multiple linear regression (MLR) model\ninterpret coefficient estimates for continuous and categorical variables in MLR\ninterpret interaction terms in MLR\nfit MLR models in R"
  },
  {
    "objectID": "materials/unit1/introMLR.html#classwise-videos",
    "href": "materials/unit1/introMLR.html#classwise-videos",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nThese videos cover the concepts. We‚Äôll look at how to do these things in R during class on Thursday. If you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nClick this invite link to join the Classwise course: Classwise join link\nIf you have problems with the invite link, try going directly to classwise.org and click ‚ÄúLogin‚Äù and then ‚ÄúSchool SSO.‚Äù Then you should be able to use your email to access the videos directly on this page or on the classwise site. You do not need to create a new account.\nAfter joining the course, you should be able to view the videos directly from the course website"
  },
  {
    "objectID": "materials/unit1/introMLR.html#textbook",
    "href": "materials/unit1/introMLR.html#textbook",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Textbook",
    "text": "Textbook\nISLR sections 3.1-3.3"
  },
  {
    "objectID": "materials/unit1/introMLR.html#survey",
    "href": "materials/unit1/introMLR.html#survey",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Survey",
    "text": "Survey\nClick here to complete the survey"
  },
  {
    "objectID": "materials/unit1/introMLR.html#class-code",
    "href": "materials/unit1/introMLR.html#class-code",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Class code",
    "text": "Class code\nIn RStudio, run the following in the console:\n\ndownload.file(\"https://raw.githubusercontent.com/anlane611/702-classcode/main/introtoMLRcode.qmd\", destfile=\"introtomlrcode.qmd\")"
  },
  {
    "objectID": "materials/unit1/introMLR.html#application-exercise",
    "href": "materials/unit1/introMLR.html#application-exercise",
    "title": "8.31: Introduction to Multiple Linear Regression",
    "section": "Application exercise",
    "text": "Application exercise\nPalmer penguins data\nData were collected and made available by Dr.¬†Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\nUse the glimpse() output to determine the following:\n\nsample size and number of variables\nwhich variables are categorical and which are numeric? is there any missing data? are the categorical variables stored appropriately?\n\nSelect an appropriate outcome and primary (continuous) predictor of interest.\n\ngenerate a scatter plot for the two variables (remember to label your axes!)\ncolor the scatter plot by sex. Does an interaction term seem appropriate?\ncolor the scatter plot by species. Does an interaction term seem appropriate?\n\nFit a model regressing the outcome variable you selected onto the primary predictor of interest, sex, and species.\n\nWrite interpretations for the coefficient estimates, p-values, and confidence intervals\nIs the species variable statistically significant? Conduct the appropriate test.\n\nAdd an interaction term that seems appropriate based on the EDA from #2. Interpret the p-value and coefficient estimate for the interaction term in the context of the dataset."
  },
  {
    "objectID": "materials/unit1/miscMLR.html",
    "href": "materials/unit1/miscMLR.html",
    "title": "9.26: Wrapping up MLR",
    "section": "",
    "text": "describe the basics of the bias-variance tradeoff\ndescribe Simpson‚Äôs paradox\nexplain when it is useful to standardize predictors in linear regression"
  },
  {
    "objectID": "materials/unit1/miscMLR.html#classwise-videos",
    "href": "materials/unit1/miscMLR.html#classwise-videos",
    "title": "9.26: Wrapping up MLR",
    "section": "Classwise videos",
    "text": "Classwise videos\nThese videos cover three miscellaneous topics to wrap up our conversation about linear regression.\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThe first video introduces the bias-variance tradeoff. This is more relevant to machine learning than inferential statistical modeling, so you will learn more about it next semester. However, I want to go ahead and introduce the concept.\n\nThe second video discusses Simpson‚Äôs paradox. This relates to the concept of confounding and emphasizes the importance of using multiple linear regression rather than simple linear regression. The video also covers tidyverse functions group_by() and count() which will be useful as you explore data.\n\nFinally, see this tutorial on standardizing predictors. Focus on the z-score and centering, and the sections on when and when not to standardize. Note that this is much more relevant when prediction is the goal. Standardizing predictors changes the interpretation of the coefficient estimates; therefore, when inference/interpreting estimates the goal, we generally do not standardize."
  },
  {
    "objectID": "materials/unit1/miscMLR.html#textbook",
    "href": "materials/unit1/miscMLR.html#textbook",
    "title": "9.26: Wrapping up MLR",
    "section": "Textbook",
    "text": "Textbook\nBias-variance tradeoff: ISLR 2.2.2"
  },
  {
    "objectID": "materials/unit1/miscMLR.html#application-exercise",
    "href": "materials/unit1/miscMLR.html#application-exercise",
    "title": "9.26: Wrapping up MLR",
    "section": "Application Exercise",
    "text": "Application Exercise\nSimpson‚Äôs Paradox\n\nAir travelers would like their flights to be on time. Airlines collect data about on-time arrivals and report them to the Department of Transportation (DoT). Here is one month‚Äôs data for flights for two airlines from five western cities.\n\n\n\n\nAirline\nOn time\nLate\n\n\n\n\nAlaska Airlines\n3274\n501\n\n\nAmerica West\n6438\n787\n\n\n\n\nCalculate the percentage of flights that are on time for each airline and the percentage of flights that are late for each airline.\nBased on the calculated percentages, which airline has the better on-time record?\n\nIn the table below, the data are broken down by city.\n\n\n\nCity\nAA - on time\nAA - late\nAW - on time\nAW - late\n\n\n\n\nLos Angeles\n497\n62\n694\n117\n\n\nPhoenix\n221\n12\n4840\n415\n\n\nSan Diego\n212\n20\n383\n65\n\n\nSan Francisco\n503\n102\n320\n129\n\n\nSeattle\n1841\n305\n201\n61\n\n\nTotal\n3274\n501\n6438\n787\n\n\n\n\nCompute the percentage on-time and percentage late values for each airline and city\nWhich airline has the best on-time record for each city?\n\nLos Angeles:\nPhoenix:\nSan Diego:\nSan Francisco:\nSeattle:\n\nExplain why this is an example of Simpson‚Äôs paradox\n\n\nExplain how the following image relates to Simpson‚Äôs paradox. \nSimpson‚Äôs paradox with COVID vaccination data\n\n\nReferences\nSimpson‚Äôs paradox airline activity: http://facweb.cs.depaul.edu/brewster/lsp121/Files/Activity%206-ans.pdf\nSimpson‚Äôs paradox image: https://stats.stackexchange.com/questions/478463/examples-of-simpsons-paradox-being-resolved-by-choosing-the-aggregate-data"
  },
  {
    "objectID": "materials/unit1/miscMLR.html#key-takeaways",
    "href": "materials/unit1/miscMLR.html#key-takeaways",
    "title": "9.26: Wrapping up MLR",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nThe key takeaway of this exercise is that aggregated data can mask the relationship between two variables that changes with the inclusion of a third variable. This is one reason that we do multiple linear regression instead of simple linear regression.\nThe exercise also helps to develop statistical literacy. When you see aggregated data/percentages in the news, consider if it might be misleading. Is there a third variable that would help to shed light on the relationship between the two variables?"
  },
  {
    "objectID": "materials/unit1/estimation.html",
    "href": "materials/unit1/estimation.html",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "",
    "text": "define ‚Äúsum of squared errors‚Äù\ndescribe the concept of ordinary least squares\ndescribe (adjusted) \\(R^2\\) and how it relates to model assessment"
  },
  {
    "objectID": "materials/unit1/estimation.html#classwise-videos",
    "href": "materials/unit1/estimation.html#classwise-videos",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nI know many students are having trouble with classwise recognizing videos as completed. I will not count classwise completion grades until we sort out the technical issues.\n\n\nThe third video is optional. This video shows the derivation of the OLS estimators."
  },
  {
    "objectID": "materials/unit1/estimation.html#textbook",
    "href": "materials/unit1/estimation.html#textbook",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Textbook",
    "text": "Textbook\nISLR sections 3.1-3.3"
  },
  {
    "objectID": "materials/unit1/estimation.html#application-exercise-to-complete-during-the-class-meeting",
    "href": "materials/unit1/estimation.html#application-exercise-to-complete-during-the-class-meeting",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Application exercise (to complete during the class meeting)",
    "text": "Application exercise (to complete during the class meeting)\nPalmer penguins data\nData were collected and made available by Dr.¬†Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\nUse the glimpse() output to determine the following:\n\nsample size and number of variables\nwhich variables are categorical and which are numeric? is there any missing data? are the categorical variables stored appropriately?\n\nSelect an appropriate outcome and primary (continuous) predictor of interest.\n\ngenerate a scatter plot for the two variables (remember to label your axes!)\ncolor the scatter plot by sex. Does an interaction term seem appropriate?\ncolor the scatter plot by species. Does an interaction term seem appropriate?\n\nFit a model regressing the outcome variable you selected onto the primary predictor of interest, sex, and species.\n\nWrite interpretations for the coefficient estimates, p-values, and confidence intervals\nIs the species variable statistically significant? Conduct the appropriate test.\n\nNote: The anova function computes a nested F test:\n\n\n\n\nmod_reduced <- #reduced model object here\nmod_full <- #full model object here\n\nanova(mod_reduced, mod_full, test=\"F\")\n\n\nAdd an interaction term that seems appropriate based on the EDA from #2. Interpret the p-value and coefficient estimate for the interaction term in the context of the dataset.\nInterpret the adjusted \\(R^2\\) value for the model with the interaction term. Compare the value to the adjusted \\(R^2\\) value obtained from a model that does not include the interaction term. What do you conclude from this comparison?\n\n\nNote: You can see the \\(R^2\\) and adjusted \\(R^2\\) values in the summary(model_object) output that we used last week"
  },
  {
    "objectID": "materials/unit1/estimation.html#key-takeaways",
    "href": "materials/unit1/estimation.html#key-takeaways",
    "title": "9.05: Estimating coefficients and assessing the model",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nThis will vary depending on the variables you selected, but you probably saw that an interaction term appears to be necessary for the species variable but not necessarily sex. We see this because it appears that the slope is different for at least one species compared to the others.\nWhen an interaction term is meaningful, you should see an increase in the adjusted \\(R^2\\) value for the model with the interaction term compared to the model without. This means that the interaction term increases how much variance of the outcome is explained by the predictors."
  },
  {
    "objectID": "materials/unit1/penalized.html",
    "href": "materials/unit1/penalized.html",
    "title": "9.28: Penalized Regression",
    "section": "",
    "text": "describe why penalized regression methods are useful\nfit and interpret a LASSO regression model"
  },
  {
    "objectID": "materials/unit1/penalized.html#classwise-videos",
    "href": "materials/unit1/penalized.html#classwise-videos",
    "title": "9.28: Penalized Regression",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThe first video introduces the challenges of high-dimensional data.\n\nThe second video discusses penalized regression with a focus on LASSO."
  },
  {
    "objectID": "materials/unit1/penalized.html#textbook",
    "href": "materials/unit1/penalized.html#textbook",
    "title": "9.28: Penalized Regression",
    "section": "Textbook",
    "text": "Textbook\nShrinkage methods: ISLR 6.2\nConsiderations in high dimensions: ISLR 6.4"
  },
  {
    "objectID": "materials/unit1/assumptions.html",
    "href": "materials/unit1/assumptions.html",
    "title": "9.07: Addressing the assumptions",
    "section": "",
    "text": "list the four assumptions of MLR\nexplain why we use residual plots to assess the assumptions\ninterpret residual plots"
  },
  {
    "objectID": "materials/unit1/assumptions.html#classwise-videos",
    "href": "materials/unit1/assumptions.html#classwise-videos",
    "title": "9.07: Addressing the assumptions",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nI know many students are having trouble with classwise recognizing videos as completed. I will not count classwise completion grades until we sort out the technical issues."
  },
  {
    "objectID": "materials/unit1/assumptions.html#textbook",
    "href": "materials/unit1/assumptions.html#textbook",
    "title": "9.07: Addressing the assumptions",
    "section": "Textbook",
    "text": "Textbook\nISLR sections 3.1-3.3 (specifically 3.3.3)"
  },
  {
    "objectID": "materials/unit1/assumptions.html#application-exercise",
    "href": "materials/unit1/assumptions.html#application-exercise",
    "title": "9.07: Addressing the assumptions",
    "section": "Application exercise",
    "text": "Application exercise\nAccess the Auto dataset:\n\nlibrary(tidyverse)\nlibrary(ISLR2)\ndata(Auto)\n\n\nUse this page as a data dictionary. Identify which variables are categorical. Are they stored correctly in R? If not, create factor variables.\nFit a model regressing mpg on horsepower, displacement, acceleration, cylinders, and origin.\n\nWhat do you notice about the standard errors of the cylinders levels compared to the other predictors?\nUse the count() function to generate a table showing how many cars are in each cylinder level. Only having a few observations for a particular level of a categorical variable causes problems for the model. We can either 1) exclude those observations, or 2) create a new variable combining levels. Decide which option you would like to use here and clean the data accordingly. (Note: if you choose to exclude the observations, you can use the filter() function to subset the data).\nLook at the residual and qq plots for this model. What do you observe? Do any of the regression assumptions appear to be violated here? If so, which one(s)? Note that you can generate certain plots using the which option, i.e., plot(model_object, which=1) generates the residual plot, and plot(model_object, which=2) generates the qq-plot.\n\nGenerate a plot of mpg and displacement. Do you think a transformation of the displacement variable might be appropriate? If so, which one and why? Then, add color to your plot for cylinders. Is an interaction term appropriate? Finally, replace cylinders to color by origin. Is an interaction term appropriate?\nRepeat #3 for the other predictor variables: acceleration and horsepower\nDecide if you want to use a transformation on displacement, acceleration, and/or horsepower, or interaction term(s). Consider the implications of estimate interpretations. Fit the model with the additional terms that you choose, and generate the residual and qq plots. What do you notice compared to what you saw in #2?\nFit the model using log(mpg) as the outcome. Generate the residual and qq plots and comment on the difference(s) that you observe. Consider the implications for model interpretation. Do you think the transformation of the outcome variable is useful here?"
  },
  {
    "objectID": "materials/unit1/assumptions.html#key-takeaways",
    "href": "materials/unit1/assumptions.html#key-takeaways",
    "title": "9.07: Addressing the assumptions",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nThere is an argument to be made for treating the cylinders variable as either numeric or categorical. To me, it seemed better suited as a categorical variable. A takeaway here is that when a categorical variable has very few observations for a particular level, the standard error is inflated\nWe see that the linearity assumption appears to be violated. Upon further exploratory inspection, we see a non-linear relationship between mpg and displacement and horsepower. The relationship we see indicates that a log transformation of these predictor variables is necessary. However, when we look at the relationship with cylinder and origin, we see that an interaction term could also be used. Either one will improve the residual plot, so at this point we might consider which one is more interpretable. Since we are interested in inference, I would lean toward using an interaction term, which is easier to interpret than a log transformation.\nA log transformation of the outcome variable will improve the qq-plot. If we do this, the coefficient estimates are interpreted as multiplicative instead of additive (see this link for helpful info on interpreting coefficients after log transformations). Since the violation isn‚Äôt too bad, and linear regressions are robust to violations of normality, I would probably forego using the transformation here. However, it‚Äôs not incorrect to use it."
  },
  {
    "objectID": "materials/unit1/SLR.html",
    "href": "materials/unit1/SLR.html",
    "title": "8.29: Simple linear regression",
    "section": "",
    "text": "describe the linear regression model with statistical terminology (population parameter, estimate, random variable, probability distribution)\nInterpret regression output (estimates, standard errors, test statistics, p-values, and confidence intervals)\n\nDownload annotated notes"
  },
  {
    "objectID": "materials/unit1/SLR.html#statistics-vocabulary",
    "href": "materials/unit1/SLR.html#statistics-vocabulary",
    "title": "8.29: Simple linear regression",
    "section": "Statistics vocabulary",
    "text": "Statistics vocabulary\n\nPopulation parameter: an unknown quantity related to the population of interest (e.g., true mean resting heart rate of professional athletes in Europe)\nEstimate: quantity obtained from data to estimate the population parameter (e.g., sample mean of resting heart rate of 100 professional athletes in Europe)\nRandom variable: a variable whose possible values are numerical outcomes of a random phenomenon. Random variables can be discrete or continuous\nProbability distribution: a function that maps a random variable‚Äôs numeric outcomes to their probability. Probability distributions are defined by their parameters\nThe normal distribution is a continuous probability distribution defined by two parameters: mean \\(\\mu\\) and standard deviation \\(\\sigma\\) (or variance \\(\\sigma^2\\))\ne.g., let \\(X\\) be the random variable that represents the resting heart rate of a given professional athlete. We could say that \\(X \\sim N(\\mu=70,\\sigma=5)\\)\n\n\nExercise\nWrite your own example of a continuous random variable and normal distribution. You can use the normal distribution link to obtain plausible values for the mean and standard deviation."
  },
  {
    "objectID": "materials/unit1/SLR.html#simple-linear-regression-model",
    "href": "materials/unit1/SLR.html#simple-linear-regression-model",
    "title": "8.29: Simple linear regression",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\n\n\n\n\n\nWe define the simple linear regression model as:\n\\[\nY = \\beta_0 + \\beta_1X + \\epsilon, \\epsilon \\sim N(0,\\sigma^2)\n\\]\nWe can also write this as:\n\\[\nY \\sim N(\\beta_0 + \\beta_1X, \\sigma^2)\n\\]\n\nExercise\nMatch the vocabulary above with the regression model\n\nWhich variable(s) are random? Which are fixed?\nWhat is the probability distribution for the random variable(s)?\nWhat are the population parameters?"
  },
  {
    "objectID": "materials/unit1/SLR.html#estimated-regression-line",
    "href": "materials/unit1/SLR.html#estimated-regression-line",
    "title": "8.29: Simple linear regression",
    "section": "Estimated regression line",
    "text": "Estimated regression line\nWe write the estimated regression line as:\n\\[\n\\hat{Y}=\\hat{\\beta_0}+\\hat{\\beta_1}X\n\\]\nand write the residuals \\(r\\) (\\(\\hat{e}\\)) as \\(r=Y-\\hat{Y}\\)"
  },
  {
    "objectID": "materials/unit1/SLR.html#putting-all-the-pieces-together",
    "href": "materials/unit1/SLR.html#putting-all-the-pieces-together",
    "title": "8.29: Simple linear regression",
    "section": "Putting all the pieces together",
    "text": "Putting all the pieces together\n\nExercise\nWrite the estimated regression line for the births14 data\n\n\n# A tibble: 2 √ó 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept)   -3.60     0.523      -6.88 1.03e-11   -4.62     -2.57 \n2 weeks          0.279    0.0135     20.7  1.80e-79    0.253     0.306\n\n\n¬†\n¬†\n¬†\n\n\nSampling distribution of \\(\\hat{\\beta}\\)\nBecause the estimated value \\(\\hat{\\beta_1}\\) is calculated from a sample, and the sample arose from a random process, \\(\\hat{\\beta_1}\\) is a random variable with its own probability distribution!\nIt turns out that with the specification given above, \\(\\hat{\\beta_1}\\) has a normal distribution. The estimated standard deviation of this distribution is the standard error of \\(\\hat{\\beta_1}\\)\n\n\nTest statistic & p-value\n\np-value: probability of obtaining results at least as extreme as those observed assuming the null hypothesis is true\nIn other words, if we assume that nothing special is going on, what is the probability that we observe a relationship at least as extreme as what we see in the data?\n\nIn regression, the null hypothesis, or the assumption that there is no relationship between the variables, is \\(H_0: \\beta_1=0\\)\nBecause \\(\\hat{\\beta_1}\\) has a normal distribution (and skipping some technical details), we can use the following test statistic to calculate the desired probability\n\\[\n\\frac{\\hat{\\beta_1}}{SE(\\hat{\\beta_1})} \\sim t_{n-2}\n\\]\nWe use the t-distribution when the population standard deviation is unknown (as is the case for the distribution of \\(\\hat{\\beta_1}\\) ). So, we can use this quantity and the t-distribution to calculate the p-value.\n\n\nConfidence interval\nSimilarly, we can use the t-distribution to calculate the confidence interval, or a plausible range for the true value of the population parameter \\(\\beta_1\\)\n\\[\n\\hat{\\beta_1} \\pm t^*_{n-2}[SE(\\hat{\\beta_1})]\n\\]\n\n\nExercise\nSee for yourself: use the estimate and standard error from the regression output to calculate the test statistic, p-value, and confidence interval. The pt() R function calculates (cumulative) probabilities for the t-distribution, and the qt() function calculates critical values."
  },
  {
    "objectID": "materials/unit1/SLR.html#interpreting-regression-output",
    "href": "materials/unit1/SLR.html#interpreting-regression-output",
    "title": "8.29: Simple linear regression",
    "section": "Interpreting regression output",
    "text": "Interpreting regression output\nWhen reporting results from a regression model, we primarily focus on the estimates, p-values, and confidence intervals. (It is important to check the standard errors though! Inflated standard errors can indicate a problem with the model. We will talk about this more in a later lecture)\n\n\n# A tibble: 2 √ó 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n1 (Intercept)   -3.60     0.523      -6.88 1.03e-11   -4.62     -2.57 \n2 weeks          0.279    0.0135     20.7  1.80e-79    0.253     0.306\n\n\n\nFor each additional week of pregnancy, infant birth weight increases by 0.28 lbs, on average. The association between weeks of pregnancy and infant birth weight is statistically significant (p<.001, 95% CI: [0.25, 0.31])\nAssuming there is no association between weeks of pregnancy and infant birth weight, the probability of observing results as extreme as these is <.001. Therefore, we have evidence that there is a relationship between weeks of pregnancy and infant birth weight.\nIf we repeated this experiment 100 times and constructed a confidence interval in the same way, we would expect 95 of the intervals to contain the true value of \\(\\beta_1\\). Therefore, we are 95% confident that the true value of \\(\\beta_1\\) is between 0.25 and 0.31.\n\n\nIncorrect interpretations\n\nThe probability that the null hypothesis is false is <0.001\nThere is a 95% chance that the true value of \\(\\beta_1\\) is between 0.25 and 0.31\nWe are 95% confidence that \\(\\hat{\\beta_1}\\) is between 0.25 and 0.31"
  },
  {
    "objectID": "materials/unit1/SLR.html#references",
    "href": "materials/unit1/SLR.html#references",
    "title": "8.29: Simple linear regression",
    "section": "References",
    "text": "References\nhttp://www.stat.yale.edu/Courses/1997-98/101/ranvar.htm"
  },
  {
    "objectID": "materials/unit1/problems.html",
    "href": "materials/unit1/problems.html",
    "title": "9.12: Problems that can arise",
    "section": "",
    "text": "interpret plots of leverage and Cook‚Äôs distance\nunderstand the problem of multicollinearity"
  },
  {
    "objectID": "materials/unit1/problems.html#classwise-videos",
    "href": "materials/unit1/problems.html#classwise-videos",
    "title": "9.12: Problems that can arise",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class."
  },
  {
    "objectID": "materials/unit1/problems.html#textbook",
    "href": "materials/unit1/problems.html#textbook",
    "title": "9.12: Problems that can arise",
    "section": "Textbook",
    "text": "Textbook\nISLR 3.3.3"
  },
  {
    "objectID": "materials/unit1/problems.html#application-exercise",
    "href": "materials/unit1/problems.html#application-exercise",
    "title": "9.12: Problems that can arise",
    "section": "Application exercise",
    "text": "Application exercise\nFor this exercise, we will use the Hitters dataset from the ISLR2 package\n\nlibrary(ISLR2)\ndata(\"Hitters\")\n?Hitters #run this for the data dictionary\n\n\nWe want to understand how hitter statistics are associated with salaries. More specifically, we want to assess the model regressing Salary on the following predictors: Hits, HmRun, Runs, RBI, Years, CHits, CHmRun, CRuns, and CRBI. Let‚Äôs first create a correlation plot of the 9 predictors. Comment on what you observe in the correlation plot.\n\nlibrary(corrplot) #you will need to install this package\ncorrplot(cor(Hitters[,c(\"Hits\", \"HmRun\", \"Runs\", \"RBI\", \"Years\", \n                        \"CHits\", \"CHmRun\",\"CRuns\",\"CRBI\")]))\n\nNow, fit the model. Take note of the output.\nUse the vif() function in the car package to calculate VIF values for each predictors. Do any of the predictors have high VIF values? If so, which one(s)?\nFit another model but without the career variables (i.e., using Hits, HmRun, Runs, RBI, and Years). Note differences in the model output for these predictors between this model and the model you fit in #2 in terms of estimates, standard errors, and p-values.\nLook at the model diagnostics plots.\n\nAre there any influential points? If so, fit the model without those observation(s) and note any differences in the summary output and/or the diagnostic plots.\nDo you notice any other potential violations in model assumptions? If so, what adjustments could be made?"
  },
  {
    "objectID": "materials/unit1/problems.html#key-takeaways",
    "href": "materials/unit1/problems.html#key-takeaways",
    "title": "9.12: Problems that can arise",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nFrom the correlation plot, you should see that the single-season variables and the career variables are highly correlated with each other\nWe see very high VIF values for the career variables. I recommended removing those because they are so high and much higher than the other predictors. I encourage you not to rely strictly on the >10 threshold.\nAfter removing the career variables, we see that the standard errors for the single-season variables generally decrease. Perhaps the most notable and intuitive difference in the output is in the Years variable. We would expect that salaries generally increase as years in the league increase. In the first model, we had high collinearity between the Years variable and the career variables, and the estimate was negative. After removing the career variables with which the Years variable was highly correlated, the standard error for Years is quite a bit lower and the estimate is positive (and statistically significant)\nFor the model diagnostic plots, we see potential violation of homoscedasticity and normality. If we log-transform the outcome, the model diagnostic plots are more ‚Äúcloud-like.‚Äù Log-transformations are often necessary when outcome variables have to do with money (salary, price, income, etc.).\nWe see a few outliers and high-leverage points, though no influential points identified with Cook‚Äôs distance. If we remove Mike Schmidt, Rickey Henderson, and Terry Kennedy, the model output is slightly different but we don‚Äôt see substantial differences (i.e., conclusions drawn from p-values are not different)"
  },
  {
    "objectID": "materials/unit1/modelselection.html",
    "href": "materials/unit1/modelselection.html",
    "title": "9.14: Model selection",
    "section": "",
    "text": "understand forward and backward selection\nunderstand the argument against forward and backward selection"
  },
  {
    "objectID": "materials/unit1/modelselection.html#classwise-videos",
    "href": "materials/unit1/modelselection.html#classwise-videos",
    "title": "9.14: Model selection",
    "section": "Classwise videos",
    "text": "Classwise videos\nIf you have questions as you watch the videos, feel free to send me an email or slack message! I will address common questions at the beginning of class.\nThere are no chat sessions for this lecture.\nThe first video explains the forward and backward model selection procedures.\n\nThe reading below presents an argument against using forward and backward selection (these methods are also known as stepwise selection). Read the full introduction (pages 1-5) and the conclusion. You can skip the methods and results sections."
  },
  {
    "objectID": "materials/unit1/modelselection.html#textbook",
    "href": "materials/unit1/modelselection.html#textbook",
    "title": "9.14: Model selection",
    "section": "Textbook",
    "text": "Textbook\nISLR 6.1.2"
  },
  {
    "objectID": "materials/unit1/modelselection.html#application-exercise",
    "href": "materials/unit1/modelselection.html#application-exercise",
    "title": "9.14: Model selection",
    "section": "Application exercise",
    "text": "Application exercise\nClass exercise vote\nGroups for today‚Äôs exercise\nIn your group, discuss the following based on the video and article:\n\nSummarize the forward and backward stepwise selection procedures.\nWhy are forward and backward selection appealing?\nWhat statistical arguments does Smith make against stepwise selection?\nConsider this sentence: ‚ÄúThe standard errors of the coefficient estimates are underestimated, which makes the confidence intervals too narrow, the t statistics too high, and the p-values too low‚Ä¶‚Äù Think about the relationship between standard errors and the other quantities mentioned. Why would underestimated standard errors lead to the outcomes listed?\nExplain how big data has renewed the interest in stepwise selection and why Smith argues that big data exacerbates the problems with stepwise selection\nWhat alternative approaches to model selection does Smith recommend?\nImagine yourself working on a data science team in the future. A colleague recommends using the following two approaches. Based on the reading, which of these approaches seems reasonable? If none of them seem reasonable, how do you explain this to your colleague and how do you recommend moving forward?\n\nFit a model with pre-specified predictors and use backward selection to arrive at a ‚Äúfinal model.‚Äù Interpret the output and draw conclusions based on the final model.\nFit a model with pre-specified predictors. Remove any variables with p-values that are above 0.05. Re-fit the model and interpret the output.\nFit simple linear regression models with each predictor individually. Then, fit a multiple linear regression model with the predictors that had significant p-values in the SLR model. Interpret the MLR output."
  },
  {
    "objectID": "materials/unit1/introtomlrcode.html",
    "href": "materials/unit1/introtomlrcode.html",
    "title": "Intro to MLR",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.1 ‚îÄ‚îÄ\n\n\n‚úî ggplot2 3.4.0     ‚úî purrr   0.3.4\n‚úî tibble  3.1.8     ‚úî dplyr   1.1.0\n‚úî tidyr   1.2.0     ‚úî stringr 1.4.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2‚Ä¶\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, ‚Ä¶\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34‚Ä¶\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16‚Ä¶\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385‚Ä¶\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, ‚Ä¶\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7‚Ä¶\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, ‚Ä¶\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa‚Ä¶\n\n\n\nlibrary(tidyverse)\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2‚Ä¶\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, ‚Ä¶\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34‚Ä¶\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16‚Ä¶\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385‚Ä¶\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, ‚Ä¶\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7‚Ä¶\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, ‚Ä¶\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa‚Ä¶\n\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\")\n\n\n\n\n\n#MLR model regressing mpg on weight and origin\nmlr_mod_auto <- lm(mpg~weight+origin,\n                   data=Auto)\n\nsummary(mlr_mod_auto)\n\n\nCall:\nlm(formula = mpg ~ weight + origin, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.0698  -2.7888  -0.3122   2.4489  15.4816 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.4908175  1.3266161   32.03  < 2e-16 ***\nweight      -0.0070071  0.0003136  -22.34  < 2e-16 ***\norigin       1.1540278  0.3306915    3.49 0.000539 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.272 on 389 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.7004 \nF-statistic: 458.1 on 2 and 389 DF,  p-value: < 2.2e-16\n\n\n\n#create a factor variable\nAuto$origin_fac <- factor(Auto$origin,\n                          levels=c(1,2,3),\n                          labels=c(\"American\",\n                                   \"European\",\n                                   \"Japanese\"))\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n\n\n\n\nmlr_mod_fac <- lm(mpg~weight+origin_fac,\n                  data=Auto)\n\nsummary(mlr_mod_fac)\n\n\nCall:\nlm(formula = mpg ~ weight + origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1339  -2.7358  -0.3032   2.4307  15.4544 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        43.7322362  1.1134286  39.277  < 2e-16 ***\nweight             -0.0070271  0.0003201 -21.956  < 2e-16 ***\norigin_facEuropean  0.9709056  0.6587673   1.474 0.141340    \norigin_facJapanese  2.3271499  0.6648043   3.501 0.000518 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.277 on 388 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.6997 \nF-statistic: 304.7 on 3 and 388 DF,  p-value: < 2.2e-16\n\n\nOn average, European cars‚Äô mpg is 0.97 higher than American cars‚Äô mpg, holding all else constant. This difference is not statistically significant at the 0.05 level (p=0.14).\nOn average, per increase in weight (lb), mpg decreases by 0.007, all else constant. This is statistically significant (p<0.001), so vehicle weight is associated with mpg."
  },
  {
    "objectID": "materials/unit1/introtomlrcode.html#interaction",
    "href": "materials/unit1/introtomlrcode.html#interaction",
    "title": "Intro to MLR",
    "section": "Interaction",
    "text": "Interaction\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nmlr_mod_interact <- lm(mpg~weight*origin_fac,\n                       data=Auto)\nsummary(mlr_mod_interact)\n\n\nCall:\nlm(formula = mpg ~ weight * origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4928  -2.7715  -0.3895   2.2397  15.5163 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                4.315e+01  1.186e+00  36.378  < 2e-16 ***\nweight                    -6.854e-03  3.423e-04 -20.020  < 2e-16 ***\norigin_facEuropean         1.125e+00  2.878e+00   0.391  0.69616    \norigin_facJapanese         1.111e+01  3.574e+00   3.109  0.00202 ** \nweight:origin_facEuropean  3.575e-06  1.111e-03   0.003  0.99743    \nweight:origin_facJapanese -3.865e-03  1.541e-03  -2.508  0.01255 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.253 on 386 degrees of freedom\nMultiple R-squared:  0.7068,    Adjusted R-squared:  0.703 \nF-statistic: 186.1 on 5 and 386 DF,  p-value: < 2.2e-16\n\n\nPer lb increase in weight, mpg increases by an additional 0.0000036, on average, all else held constant, for European cars compared to American cars. This difference is not statistically significant (p>0.99).\nPer lb increase in weight, mpg decreases by 0.011, on average, for European cars. For American cars, mpg decreases by 0.007, on average, per lb increase in weight. The difference in effects, 0.004, is statistically significant at the 0.05 level (p=0.013)."
  },
  {
    "objectID": "materials/unit0/unit0b.html",
    "href": "materials/unit0/unit0b.html",
    "title": "Cleaning and exploring data in R",
    "section": "",
    "text": "A crucial first step of data analysis is exploring the dataset (and then cleaning, as needed). Today, we will practice exploring and cleaning data in R."
  },
  {
    "objectID": "materials/unit0/unit0b.html#types-of-variables",
    "href": "materials/unit0/unit0b.html#types-of-variables",
    "title": "Cleaning and exploring data in R",
    "section": "Types of variables",
    "text": "Types of variables\nNumeric variables take numerical values and it makes sense to perform calculations on the values (e.g., addition, mean)\n\nDiscrete variables can not take decimal values (e.g., Number of required statistics courses in a major)\nContinuous variables can take decimal values (e.g., height in cm)\n\nCategorical variables are variables that have categories, where each category is called a level\n\nNominal variables do not have an order (e.g., eye color)\nOrdinal variables do have an order (e.g., education categories)\n\n\nExercise\nIn your group, discuss the following:\n\nClassify each of the survey questions as discrete, continuous, nominal, or ordinal.\nWhat does it mean to explore data?\nWhat does it mean to clean data? Identify how the survey data may need to be cleaned just by looking at the questions."
  },
  {
    "objectID": "materials/unit0/unit0b.html#first-steps-in-r",
    "href": "materials/unit0/unit0b.html#first-steps-in-r",
    "title": "Cleaning and exploring data in R",
    "section": "First steps in R",
    "text": "First steps in R\nHopefully you have already installed R/RStudio on your computer. If so, you can copy and paste the code below into your own script. If you haven‚Äôt yet installed R/RStudio, you can run code directly from this page.\nLoading\n  webR...\n\n\n  \n\n\nLoading\n  webR...\n\n\n  \n\n\nLet‚Äôs remove the timestamp variable\nLoading\n  webR...\n\n\n  \n\n\nLet‚Äôs make our variable names more concise (but still descriptive!)\nLoading\n  webR..."
  },
  {
    "objectID": "materials/unit0/unit0b.html#cleaning-and-exploring-variables",
    "href": "materials/unit0/unit0b.html#cleaning-and-exploring-variables",
    "title": "Cleaning and exploring data in R",
    "section": "Cleaning and exploring variables",
    "text": "Cleaning and exploring variables\n\nSiblings\nLet‚Äôs start with the Siblings variable. What information do we need to know to clean the variable?\nLoading\n  webR...\n\n\n  \n\n\nAlways always always:\n\ncreate a new variable instead of overwriting the original\nperform a quality control check\n\nLoading\n  webR...\n\n\n  \n\n\nNow that the variable is clean, let‚Äôs explore it more:\nLoading\n  webR...\n\n\n  \n\n\nLoading\n  webR...\n\n\n  \n\n\n\n\nSushi\nNow consider the sushi variable.\nLoading\n  webR...\n\n\n  \n\n\nIt‚Äôs important to pay attention to implausible values. What would be an implausible value in this case? How should we handle it?\nLoading\n  webR...\n\n\n  \n\n\nNow let‚Äôs generate a plot to visualize the sushi variable\nLoading\n  webR...\n\n\n  \n\n\n\n\nLanguages\nLoading\n  webR...\n\n\n  \n\n\nOften, we need to combine categories if we have too few observations in multiple categories. How should we combine categories in this case?"
  },
  {
    "objectID": "materials/unit0/unit0b.html#exercises",
    "href": "materials/unit0/unit0b.html#exercises",
    "title": "Cleaning and exploring data in R",
    "section": "Exercises",
    "text": "Exercises\nIn your group, complete the following:\n\nFor the application area of interest variable, how many students responded with ‚Äúother‚Äù? What does this say about the survey design?\nExplore, clean, and visualize the remaining variables in the dataset. Note that you may have to look up some functions to help. For example, the ‚Äúsubstr‚Äù function will be useful for the course excitement variable."
  },
  {
    "objectID": "materials/unit0/unit0a.html",
    "href": "materials/unit0/unit0a.html",
    "title": "Key Principles of Statistics",
    "section": "",
    "text": "By the end of this session, students should be able to:\n\ndistinguish between a population and a sample\ndescribe sampling variability\nfit a simple linear regression model in R"
  },
  {
    "objectID": "materials/unit0/unit0a.html#load-the-data",
    "href": "materials/unit0/unit0a.html#load-the-data",
    "title": "Key Principles of Statistics",
    "section": "Load the data",
    "text": "Load the data\nToday we will use the births14 dataset in the openintro R package. You can read more about the dataset and see a data dictionary at this link.\n\n#load the packages we need\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#load the dataset from the openintro package\ndata(births14)\n\n#get an overview of the data\nglimpse(births14)"
  },
  {
    "objectID": "materials/unit0/unit0a.html#exercise",
    "href": "materials/unit0/unit0a.html#exercise",
    "title": "Key Principles of Statistics",
    "section": "Exercise",
    "text": "Exercise\nExplore the births14 data:\n\nUsing the data dictionary at the link above, classify the variables as numeric or categorical. Do the variables seem to be correctly structured in R?\nUse the summary() function to determine if there are missing values in the dataset"
  },
  {
    "objectID": "materials/unit0/unit0a.html#hypothetically",
    "href": "materials/unit0/unit0a.html#hypothetically",
    "title": "Key Principles of Statistics",
    "section": "Hypothetically‚Ä¶",
    "text": "Hypothetically‚Ä¶\nImagine that this dataset contains information about the entire population of interest (e.g., all babies born in Bull City). Then, say we have the following research question:\nWhat is the relationship between length of pregnancy in weeks and weight of the baby in pounds in Bull City?\nWe can explore this relationship graphically:\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\", y=\"baby weight (lbs)\") \n  #always use labels!"
  },
  {
    "objectID": "materials/unit0/unit0a.html#linear-regression",
    "href": "materials/unit0/unit0a.html#linear-regression",
    "title": "Key Principles of Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nTo further characterize the relationship between length of pregnancy and baby weight, we can fit a line to the plot:\n\nmod_bullcity <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births14)\n\ntidy(mod_bullcity, conf.int=TRUE)\n\n\nExercise\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\n\nLooking at the estimate column of the tidy output, how would you interpret the intercept here? how would you interpret the weeks estimate?\n\n\n\nStandard error\nTo better conceptualize the standard error, consider the premise above that these data represent the entire city. Now imagine that we could not actually obtain all of these data. Instead, we were only able to obtain a sample of 200 babies. Using only a sample of 200, if we fit a line in the same way as above, we have many different lines that we could have obtained:\n\nset.seed(823)\nbirths_sample1 <- births14 |> slice_sample(n=200)\n\nggplot(births_sample1, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\nmod_sample1 <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births_sample1)\n\ntidy(mod_sample1, conf.int=TRUE)\n\n\n\nExercise\nFill in the code below to simulate the process of taking 250 different samples and store the weeks coefficient estimate in a vector\n\nweeks.coefs <- c() #create empty vector to store coefficient estimates\n\nfor(i in 1:250){ #create loop for 250 different samples\n  print(i)\n  set.seed(823+i) #set a unique seed each iteration\n  \n  #sample data\n  births_sample <-\n  \n  #fit model\n  mod_sample <- \n    \n  #store output\n  weeks.coefs[i] <- tidy(mod_sample)$estimate[2]\n}\n\n¬†\n¬†\n¬†\nNow let‚Äôs plot the coefficient estimates we have for the 250 samples:\n\nweeks.coefs.dat <- data.frame(weeks.coefs)\n\nggplot(weeks.coefs.dat, aes(x=weeks.coefs))+\n  geom_histogram()+\n  labs(x=\"weeks coefficient estimate\")\n\nWe see that there is variability in the coefficient estimates for weeks. The standard deviation of this collection of possible estimates is the standard error of the estimate.\n\n\nConfidence interval and p-value\nWe can also use this collection of estimates to provide a plausible range for the ‚Äútrue‚Äù coefficient value:\n\nquantile(weeks.coefs, probs=c(.025,.975))\n\nOr, we can look at the collection of estimates and see that none of them are 0. So, because we collected 250 different samples and none of them had a coefficient estimate of 0, we are quite confident that the ‚Äútrue‚Äù coefficient is not zero.\n¬†\n¬†\nIn reality, we typically cannot many samples from the same population. So, we often rely on assumptions related to probability distributions to derive confidence intervals and p-values."
  },
  {
    "objectID": "materials/unit0/unit0.html",
    "href": "materials/unit0/unit0.html",
    "title": "Key Principles of Statistics",
    "section": "",
    "text": "By the end of this session, students should be able to:\n\ndistinguish between a population and a sample\ndescribe sampling variability\nfit a simple linear regression model in R"
  },
  {
    "objectID": "materials/unit0/unit0.html#load-the-data",
    "href": "materials/unit0/unit0.html#load-the-data",
    "title": "Key Principles of Statistics",
    "section": "Load the data",
    "text": "Load the data\nToday we will use the births14 dataset in the openintro R package. You can read more about the dataset and see a data dictionary at this link.\n\n#If you would like the full qmd file, you can run this in the console\ndownload.file(\"https://raw.githubusercontent.com/anlane611/datasets/main/unit0.qmd\",destfile = \"unit0.qmd\")\n\n\n#load the packages we need\nlibrary(openintro)\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n#load the dataset from the openintro package\ndata(births14)\n\n#get an overview of the data\nglimpse(births14)\n\nNote: As an alternative to using RStudio on your local machine, you can use the Duke container: https://cmgr.oit.duke.edu/containers"
  },
  {
    "objectID": "materials/unit0/unit0.html#exercise",
    "href": "materials/unit0/unit0.html#exercise",
    "title": "Key Principles of Statistics",
    "section": "Exercise",
    "text": "Exercise\nExplore the births14 data:\n\nUsing the data dictionary at the link above, classify the variables as numeric or categorical. Do the variables seem to be correctly structured in R?\nUse the summary() function to determine if there are missing values in the dataset"
  },
  {
    "objectID": "materials/unit0/unit0.html#hypothetically",
    "href": "materials/unit0/unit0.html#hypothetically",
    "title": "Key Principles of Statistics",
    "section": "Hypothetically‚Ä¶",
    "text": "Hypothetically‚Ä¶\nImagine that this dataset contains information about the entire population of interest (e.g., all babies born in Bull City). Then, say we have the following research question:\nWhat is the relationship between length of pregnancy in weeks and weight of the baby in pounds in Bull City?\nWe can explore this relationship graphically:\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\", y=\"baby weight (lbs)\") \n  #always use labels!"
  },
  {
    "objectID": "materials/unit0/unit0.html#linear-regression",
    "href": "materials/unit0/unit0.html#linear-regression",
    "title": "Key Principles of Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nTo further characterize the relationship between length of pregnancy and baby weight, we can fit a line to the plot:\n\nmod_bullcity <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births14)\n\ntidy(mod_bullcity, conf.int=TRUE)\n\n\nExercise\n\nggplot(births14, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\n\nLooking at the estimate column of the tidy output, how would you interpret the intercept here? how would you interpret the weeks estimate?\n\n\n\nStandard error\nTo better conceptualize the standard error, consider the premise above that these data represent the entire city. Now imagine that we could not actually obtain all of these data. Instead, we were only able to obtain a sample of 200 babies. Using only a sample of 200, if we fit a line in the same way as above, we have many different lines that we could have obtained:\n\nset.seed(823)\nbirths_sample1 <- births14 |> slice_sample(n=200)\n\nggplot(births_sample1, aes(x=weeks, y=weight))+\n  geom_point()+\n  labs(x=\"length of pregnancy (weeks)\",y=\"baby weight (lbs)\")+\n  geom_smooth(method=\"lm\",se=F)\n\nmod_sample1 <- linear_reg() |> \n  set_engine(\"lm\") |>\n  fit(weight ~ weeks, data=births_sample1)\n\ntidy(mod_sample1, conf.int=TRUE)\n\n\n\nExercise\nFill in the code below to simulate the process of taking 250 different samples and store the weeks coefficient estimate in a vector\n\nweeks.coefs <- c() #create empty vector to store coefficient estimates\n\nfor(i in 1:250){ #create loop for 250 different samples\n  print(i)\n  set.seed(823+i) #set a unique seed each iteration\n  \n  #sample data\n  births_sample <-\n  \n  #fit model\n  mod_sample <- \n    \n  #store output\n  weeks.coefs[i] <- tidy(mod_sample)$estimate[2]\n}\n\n¬†\n¬†\n¬†\nNow let‚Äôs plot the coefficient estimates we have for the 250 samples:\n\nweeks.coefs.dat <- data.frame(weeks.coefs)\n\nggplot(weeks.coefs.dat, aes(x=weeks.coefs))+\n  geom_histogram()+\n  labs(x=\"weeks coefficient estimate\")\n\nWe see that there is variability in the coefficient estimates for weeks. The standard deviation of this collection of possible estimates is the standard error of the estimate.\n\n\nConfidence interval and p-value\nWe can also use this collection of estimates to provide a plausible range for the ‚Äútrue‚Äù coefficient value:\n\nquantile(weeks.coefs, probs=c(.025,.975))\n\nOr, we can look at the collection of estimates and see that none of them are 0. So, because we collected 250 different samples and none of them had a coefficient estimate of 0, we are quite confident that the ‚Äútrue‚Äù coefficient is not zero.\n¬†\n¬†\nIn reality, we typically cannot many samples from the same population. So, we often rely on assumptions related to probability distributions to derive confidence intervals and p-values."
  },
  {
    "objectID": "DAA/DA1.html",
    "href": "DAA/DA1.html",
    "title": "Data analysis assignment 1",
    "section": "",
    "text": "Airbnb wants to help new hosts set prices for their Airbnb listings in Asheville, NC. They have hired your data science consulting company to build a model to generate prices based on a variety of factors.\nFor this assignment, you will write your report in two parts: 1) a report (1-2 pages) describing your model to (non-technical) Airbnb executives, and 2) a report (3-4 pages) justifying your model to your (technical) data science team"
  },
  {
    "objectID": "DAA/DA1.html#the-dataset",
    "href": "DAA/DA1.html#the-dataset",
    "title": "Data analysis assignment 1",
    "section": "The dataset",
    "text": "The dataset\nClick here to download the data\nThe data is from Inside Airbnb.\nClick here for the data dictionary"
  },
  {
    "objectID": "DAA/DA1.html#cleaning-and-model-requirements",
    "href": "DAA/DA1.html#cleaning-and-model-requirements",
    "title": "Data analysis assignment 1",
    "section": "Cleaning and model requirements",
    "text": "Cleaning and model requirements\nYou must include the following variables in your model:\n\nroom_type (you may need to combine categories)\nnumber of bedrooms\nnumber of bathrooms (note that this variable needs to be cleaned, as the bathrooms variable is empty. I recommend using the str_sub() function from the stringr package and as.numeric() to extract the number of bathrooms\ncreate a new variable that gives the distance to downtown. There may be multiple ways to do this, but you can use the code below. This uses the apply function, which is a useful function in R to perform an operation on all rows (or columns) of a matrix. Then it uses the distm() function in the geosphere package to calculate the distance in meters from a latitude and longitude in downtown Asheville. Finally, it multiplies by the appropriate constant to convert the value to miles.\n\n\nlibrary(geosphere) #you will need to install this package\nairbnb$dist_to_dt <- apply(airbnb[,c(\"longitude\",\"latitude\")],1,function(x) distm(\n  c(-82.55481168521978,35.59701329976918),\n  x,fun=distHaversine))*0.00062137\n\nNote that you will also need to clean the price variable. You can use the str_sub() function again here.\nChoose at least one other variable to include in your model. Consider what is appropriate for a new host to set a price.\n\n  Extra credit\n  \n    Earn extra points on this assignment by finding a way to incorporate amenity features in your model. For example, a host may want to change the price based on whether or not they allow pets.\n    \n  \n\nAs you fit and assess your model, consider the following elements that we have discussed in class:\n\nIs this a prediction or inference problem? Should model interpretability be prioritized in this situation?\nLook at the diagnostic plots for your model. Determine if you need to transform predictor(s) or the outcome variable to improve the model.\nEvaluate influential points and multicollinearity and make adjustments accordingly. If you remove any observations, be sure to include this information in your report.\nWhich model metric(s) are appropriate to assess the model?"
  },
  {
    "objectID": "DAA/DA1.html#deliverables",
    "href": "DAA/DA1.html#deliverables",
    "title": "Data analysis assignment 1",
    "section": "Deliverables",
    "text": "Deliverables\n\nReport for Airbnb executives (1-2 pages)\nThe report for the Airbnb executives should explain your model to a non-technical audience. No code or ‚Äúraw‚Äù R output should be in the report.\nSpecifically, your report should contain the following elements:\n\nIntroduction: Provide an overview of the dataset and the goals of the analysis. Provide basic information about the data (e.g., sample size). You may choose to include summary statistics or basic plots.\nMethods: Explain the model you used to analyze the data without getting into technical details. Why did you decide to use that model for this dataset and how does it accomplish their goal? Which variables did you include in the model and why?\nResults: Justify your model with the appropriate model metric(s). Explain them in non-technical terms. Then, provide an example of how the model can be used by giving the projected price for a particular combination of variables in your model (e.g., ‚Äúfor a listing with 2 bedrooms, 2 bathrooms, ‚Ä¶, the price would be ‚Äî‚Äù)\nConclusion: Do you feel that the model is good enough to be deployed? If not, can you think of additional data that Airbnb could collect to improve the model?\n\n\n\nReport for data science team\nThe second part of the assignment will be a 3-4 page report that is suitable for other data scientists. Here, you will present details of your model to justify the conclusions you presented to the client. This section should present technical details that someone with a data science background can understand. This report must include the following, though you may wish to provide additional details relevant to the analysis:\n\nIntroduction: Provide details about the dataset, including any data cleaning that needed to be done. Was there any missing data? Did you make any assumptions during the data cleaning process?\nMethods: Describe your model assessment and building process. Did you include any interaction terms? Why or why not? Did you transform any variables? If so, why? Provide the model diagnostic plots. Did you exclude any observations? Did you make any adjustments because of multicollinearity? How did you assess your model?\nConclusion: What do you conclude about the validity of this analysis?\n\n\n\n  Submission & Formatting Instructions/Tips\n  \n    You will submit two files to gradescope: 1) a PDF that contains the two requested reports, and 2) the qmd file you used to produce the reports \n    \n      All code must be hidden in the PDF. You can hide all code by adding the following to your YAML Header: execute: ¬† echo: false\n      Your quarto document should be rendered directly to PDF, not to HTML and then saved as a PDF\n      The PDF should be 5-6 pages: 1-2 pages for the non-technical report and 3-4 pages for the technical report. These ranges are intentional; reports that fall outside of this range will be penalized. \n      Any plots (including diagnostic plots) must be appropriately formatted (axis labels, legends where appropriate)\n      \"Raw\" R output and variable names should not be in the report. For example, in the writing, tables, plots, etc, you should say \"room type\" instead of \"room_type\"\n      The quarto website includes lots of helpful information for generating your report. I recommend that you use the visual editor  to make formatting easier. The visual editor has several features that look like a generic word processor\n      PDF Basics \n      Gallery for advanced Quarto formatting (not necessary, but could be helpful) \n    \n  \n\n\nExample of good formatting\nThis is a different assignment structure, but notice the following elements of this report:\n\ncode is hidden\ntables/plots are labeled with the variable descriptions instead of the variable names\nsections are labeled\nvariables in the text are referred to by description instead of variable name\nAll output is presented in text, table, or plot (no raw output)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "",
    "text": "Welcome to the IDS 702 course site!"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course Overview",
    "text": "Course Overview\nMeeting times: Tuesdays and Thursdays 3:05-4:20 PM, Gross Hall 107\nInstructor \nAndrea Lane, PhD \nandrea.lane@duke.edu \nGross Hall 223 \nOffice hours: Tues/Thurs 4:20-5:20 PM\n \nTeaching Assistants \nXiaoquan Liu \nx.liu@duke.edu \nOffice hours: Mon 8:15-9:15AM on Zoom (click here for Zoom link), Thurs 11:30AM-12:30PM Gross Hall 2nd floor conference room\n \nDingkun Yang \ndingkun.yang@duke.edu \nOffice hours: Tues 11:35AM-12:35PM Gross Hall 2nd floor conference room, Weds 3:15-4:15PM on Zoom (click here for Zoom link)"
  },
  {
    "objectID": "index.html#important-links",
    "href": "index.html#important-links",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Important Links",
    "text": "Important Links\nGradescope (join course with code 2PGWK8)\nSlack: join the 702-fa23 channel in the MIDS workspace\nDuke R container"
  },
  {
    "objectID": "index.html#textbook",
    "href": "index.html#textbook",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Textbook",
    "text": "Textbook\nAn Introduction to Statistical Learning with Applications in R, 2nd edition by James, G., Witten, D., Hastie, T., and Tibshirani, R.\nUse the link above to download a PDF of the book"
  },
  {
    "objectID": "index.html#important-dates",
    "href": "index.html#important-dates",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Important Dates",
    "text": "Important Dates\n\n\n  \n    \n      Tuesday, Aug. 29\n      First day of class\n    \n    \n      Tuesday, Oct. 17\n      Fall break - no class meeting\n    \n    \n      Thursday, Nov. 23 \n      Thanksgiving holiday - no class meeting \n    \n        \n      Friday, Dec 1 \n      Classes end, final reports due"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "test page",
    "section": "",
    "text": "Linear regression"
  },
  {
    "objectID": "project/proposal.html",
    "href": "project/proposal.html",
    "title": "Team Project Proposal",
    "section": "",
    "text": "The purpose of the team project is to provide an opportunity to complete a data analysis project from start to finish. This includes:\n\nSelecting data\nWriting research questions\nPerforming exploratory data analysis\nDeveloping appropriate statistical models\nCommunicating results through a written report and presentation\nWorking with a team"
  },
  {
    "objectID": "project/proposal.html#teams",
    "href": "project/proposal.html#teams",
    "title": "Team Project Proposal",
    "section": "Teams",
    "text": "Teams\nSee this sheet for your team assignment. You are responsible for dividing the work equitably among team members. Every team member is required to contribute to each portion of the project: coding, writing, and presenting. Learn from each other and, most of all, be kind. You will receive individual grades for the project that incorporate feedback from fellow team members."
  },
  {
    "objectID": "project/proposal.html#data",
    "href": "project/proposal.html#data",
    "title": "Team Project Proposal",
    "section": "Data",
    "text": "Data\nYour first step is to select the dataset that you are most interested in analyzing. Below is a list of datasets or sources that you can consider using to find a dataset. You are not require to use these.\nYour dataset must have at least 500 observations, 10 variables, and a mix of numeric and categorical variables. You may not use a dataset that we have used in class.\n\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nPew Research\n2021 CDC Behavioral Risk Factor Surveillance System Survey\nWorld Inequality Database\n\nYou are welcome to specify a subset of a particular dataset (e.g., only North Carolina in the CDC BRFSS). Be sure to look at the data to understand its scope."
  },
  {
    "objectID": "project/proposal.html#proposal",
    "href": "project/proposal.html#proposal",
    "title": "Team Project Proposal",
    "section": "Proposal",
    "text": "Proposal\nYour proposal should list the following:\n\nTeam member names\n2 or 3 datasets of interest (list in order of preference with 1 being the top choice). For each dataset, provide:\n\n\nThe source of the data, when and how it was originally collected, and a brief description of the observations. This information is likely found on the website where you found the data, so be sure to cite your source\nTWO research questions you are interested in exploring for each dataset. Explicitly state the outcome variables in the dataset that you will use to answer each question. You are required to use two different types of outcome variables for your research questions. For example, one research question may use a continuous outcome variable while the other uses an ordinal outcome variable. Variable types may include: continuous, binary, ordinal, nominal, time-to-event\na glimpse() of each dataset to show that you can access it in R\n\nConsult this helpful guide for writing a good research question\nNo data cleaning is required in the proposal. Your proposal should be generated with a Quarto document, but you will not be required to submit the code.\nSubmit one proposal per group. One person will submit and select the other group members in the Gradescope submission. After you submit, I will provide feedback to help you decide which dataset to choose for your project."
  },
  {
    "objectID": "reflections.html",
    "href": "reflections.html",
    "title": "Statistics Reflections",
    "section": "",
    "text": "In the MIDS program, we emphasize thinking critically about data analysis and upholding principles of diversity, equity, and inclusion. Quantitative fields like data science are often viewed as ‚Äúamoral,‚Äù but human judgment always plays a role in data collection and analysis. As data scientists, we must carefully consider the societal factors that play a role in our work. The materials presented with this assignment explore how statistics/data science interact with society at large.\nThis assignment connects to the third course learning objective: Make careful and critical decisions about model building and consider real-world implications."
  },
  {
    "objectID": "reflections.html#instructions",
    "href": "reflections.html#instructions",
    "title": "Statistics Reflections",
    "section": "Instructions",
    "text": "Instructions\nYou are required to complete four statistics reflections throughout the semester. You can select any four from the list of materials below.\n\nBegin your assignment with a header that includes your name and the title and source of your selected material\nReflect on the material selected. What did it make you think about? How does it affect your work as a data scientist? Note that you are required to engage with the material and provide your thoughts/reactions; you should NOT be summarizing the piece.\nWhile there is no minimum word count for the reflections, you are expected to meaningfully engage with the material (2-3 paragraphs). You can use the suggested questions to get started, but you are not required to answer them in your response.\nIn Gradescope, select the appropriate reflection assignment based on the due date. All of the assignments are already available, so you can complete them at any time!\n\nI am always available if you have any questions or comments about the content presented in these materials. Additionally, if you come across a piece that is not on this list and you would like to use it for a statistics reflection, you are welcome to send me an email. Please include a link to the piece and a brief description of how it connects data science and society."
  },
  {
    "objectID": "reflections.html#deadlines",
    "href": "reflections.html#deadlines",
    "title": "Statistics Reflections",
    "section": "Deadlines",
    "text": "Deadlines\n\nSeptember 15, 11:59 PM\nOctober 6, 11:59 PM\nOctober 27, 11:59 PM\nNovember 17, 11:59 PM\n\nSubmit your reflection to the appropriate assignment on Gradescope"
  },
  {
    "objectID": "reflections.html#materials",
    "href": "reflections.html#materials",
    "title": "Statistics Reflections",
    "section": "Materials",
    "text": "Materials\n\n  \n    \n      \n        A Primer on Non-Binary Gender and Big Data (article)\n      \n    \n    \n      \n        A Primer on Non-Binary Gender and Big Data \n        The author offers several questions you may want to consider in your response: \n        \n          What potential insights might we derive from working with non-binary gender and data?\n          What are the risks to gener minorities in relation to data?\n          What kinds of variation do we see across culture, context, and history?\n          How might non-binary gender and data deal with intersectionality (Click this link to learn more about intersectionality)\n        \n        Additionally, you may want to consider: \n        \n          Is it always useful/important to collect data on gender? In which domains might it be more important than others?\n        \n      \n    \n  \n  \n    \n      \n        How Eugenics Shaped Statistics (article - highly recommended!)\n      \n    \n    \n      \n        How eugenics shaped statistics \n        \n          Consider this quote: \"The separation was everything‚Äînot how much, what else might explain it, or why it mattered, just that it was there.\" Reflect on what this means for you as a data scientist\n          The article argues that you cannot separate the science from the scientist. Do you agree?\n          Reflect on the argument that Galton, Pearson, and Fisher's views are \"a product of their time.\"\n        \n        \n      \n    \n  \n  \n    \n      \n        Abolish Big Data (video)\n      \n    \n    \n      \n        Abolish Big Data \n        \n          What does Milner mean when she says \"abolish big data?\"\n          What role does data literacy play in the use of big data tools? What role do data scientists have in the implementation of these tools?\n        \n      \n    \n  \n    \n    \n      \n        Data sonification (videos)\n      \n    \n    \n      \n        Data sonification - from deep space research to improving lives through cancer research AND \n        Making data sing | Margaret Anne Schedel \n        \n          What are the advantages and disadvantages of data sonification?\n          How might data sonification make data more accessible to people with disabilities? Can you think of any other ways data could be made more accessible?\n        \n      \n    \n  \n    \n    \n      \n        Fairness in Machine Learning with Sherri Rose (podcast)\n      \n    \n    \n      \n        Fairness in Machine Learning with Sherri Rose  (interview starts at 8:15 and ends at 46:00)\n        \n          Reflect on Dr. Rose's recommendations for ensuring fairness in machine learning\n          Consider Dr. Rose's comments about the \"single metric leaderboard\" and what it means for you as a data scientist.\n        \n      \n    \n  \n    \n    \n      \n        Peter Donnelly: How stats fool juries (video)\n      \n    \n    \n      \n        Peter Donnelly: How stats fool juries (you can skip past the stats jokes and start at 3:30) \n        \n          This talk is from 2007. Can you think of more recent examples of misleading statistics/misuse of statistical principles?\n          How do you think situations like the trial Donnelly describes can be avoided?"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "",
    "text": "Developing an understanding of statistical modeling is a key component of becoming a data scientist. Statistical models are used to answer research questions and obtain meaningful insights from many kinds of data.\nBroadly, this course will cover the following topics:\n\nLinear Regression\nGeneralized Linear Models\nSpecial topics, including survival models and hierarchical models\n\nBut here in the MIDS program, understanding the content is only the beginning. Successful data scientists are critical thinkers, problem solvers, effective communicators, and enthusiastic collaborators. With that in mind, this course aims to meet four key learning objectives:\nBy the end of the course, students should be able to\n\nFit and interpret statistical models, including linear and generalized linear models.\nMap a research question and dataset to the appropriate statistical model\nMake careful and critical decisions about model building and consider real-world implications\nCommunicate (through written and oral communication) model results to a broad audience"
  },
  {
    "objectID": "syllabus.html#course-components",
    "href": "syllabus.html#course-components",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course Components",
    "text": "Course Components\n\nClasswise\nWe will use a platform called Classwise for lecture videos before class meetings. You will be required to engage with prep materials (mostly videos) and answer comprehension questions in Classwise before coming to class. The prep materials will primarily cover theoretical modeling concepts. Class meetings will then focus on implementation in R and application exercises. Classwise materials will be posted on the course website.\nThe Classwise course component connects to the first learning objective: Fit and interpret statistical models, including linear and generalized linear models.\n\n\nApplication exercises\nDuring class meetings, we will complete application exercises. The goal of these exercises is to practice implementing and interpreting statistical models in R. You are encouraged to work on these exercises in small groups.\nThe application exercise course component connects to the first learning objective: Fit and interpret statistical models, including linear and generalized linear models.\n\n\nData analysis assignments\nYou will have three data analysis assignments to complete during the semester. Data analysis assignments require fitting and interpreting statistical models and communicating results to a broad audience. Each assignment will have a unique structure to develop written and oral communication skills.\nYou are encouraged to talk to each other about general concepts, or to the instructor/TAs. However, the write-ups, solutions, and code MUST be entirely your own work. The assignments must be typed up using Quarto and submitted on Gradescope. Note that you will not be able to make online submissions after the due date, so be sure to submit before the Gradescope-specified deadline.\nData analysis assignments connect to all four learning objectives.\n\n\nStatistics reflections\nYou will be responsible for four statistics reflections throughout the semester. I have assigned six pieces that cover various topics related to the interaction between data science and society. You are to write a written reflection about the material that you select. Questions are provided as prompts, but you are not required to answer them in your reflection. Grades will be based on completion and thoughtful engagement. The chosen articles/videos address topics that may be sensitive and/or uncomfortable, including racism, eugenics, and gender identity. It is crucial that you engage in the reflections thoughtfully and respectfully. I seek to create a classroom environment that not only acknowledges diversity in all forms, but celebrates it. In that endeavor, I would be remiss not to acknowledge the discriminatory ways statistical science has been used both historically and currently. In having these important discussions, I want you to critically examine and appreciate the power (good and bad) of statistics as you begin your career as a data scientist. More information can be found on the statistics reflections page on the course website.\nStatistics reflections connect to the third course learning objective: Make careful and critical decisions about model building and consider real-world implications\n\n\nTeam project\nYou and your team will apply the knowledge and skills learned throughout this course to analyze a dataset that interests you. The project should be an in-depth statistical analysis of a particular research question. Your team will select the dataset. Teams will be assigned. More detailed information will be available on the course website. The project will have multiple components:\n\nProposal\nExploratory data analysis report\nStatistical analysis plan\nFinal deliverable and presentation\nTeam member evaluation\n\nThe team project connects to all four course learning objectives."
  },
  {
    "objectID": "syllabus.html#grade-calculation",
    "href": "syllabus.html#grade-calculation",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Grade Calculation",
    "text": "Grade Calculation\n\n\n\nComponent\nPercentage\n\n\n\n\nParticipation (Classwise)\n10%\n\n\nStatistics reflections\n15%\n\n\nData analysis assignments\n45%\n\n\nTeam project\n30%\n\n\n\nLetter grade scales may be adjusted at the end of the semester. Cumulative averages \\(\\geq 90\\%\\) are guaranteed at least an A-, cumulative averages \\(\\geq 80\\%\\) are guaranteed at least a B-, and cumulative averages \\(\\geq 70\\%\\) are guaranteed at least a C-\nRegrade requests can be made on Gradescope within 24 hours of the assignment‚Äôs grade release. Regrade requests for final project reports/presentations must be made within 12 hours of grade release.\nThere are no make-ups for any graded work except for cases of medical/personal/familial emergencies. Make-ups/extension requests must be made to the instructor BEFORE the assignment deadline."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Course policies",
    "text": "Course policies\n\nLate submissions\nYou (or your team when applicable) will lose 50% of the total points on each assignment if you submit within the first 24 hours after it is due. You will lose 100% of the total points if you submit later than that without explicit approval from the instructor.\n\n\nClass meeting attendance\nI expect all students to attend all class meetings. However, I know that things come up once in a while. Therefore, I expect 90% attendance each class period. If class meeting attendance begins to consistently drop below the 90% threshold, I will institute a more stringent, individual attendance policy. Note that class meetings will not be recorded.\n\n\nAcademic integrity\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course. This means that the work you submit is your own, even if you discuss assignments with your classmates. Additionally, when consulting resources (books, internet articles including stackexchange, chatgpt), you must cite them. If you have any questions about what should be cited in your work, feel free to reach out to the instructor.\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students‚Äô learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke‚Äôs commitment to diversity and inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don‚Äôt hesitate to come and talk with me. If you prefer to speak with someone outside of the course, I encourage you to speak with MIDS administrators.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know."
  },
  {
    "objectID": "syllabus.html#resources",
    "href": "syllabus.html#resources",
    "title": "IDS 702: Data Modeling and Representation",
    "section": "Resources",
    "text": "Resources\n\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS offers many services to Duke students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations. The Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nThe Academic resource center provides learning resources to help you maximize your academic capabilities."
  },
  {
    "objectID": "introtomlrcode.html",
    "href": "introtomlrcode.html",
    "title": "Intro to MLR",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.1 ‚îÄ‚îÄ\n\n\n‚úî ggplot2 3.4.0     ‚úî purrr   0.3.4\n‚úî tibble  3.1.8     ‚úî dplyr   1.1.0\n‚úî tidyr   1.2.0     ‚úî stringr 1.4.0\n‚úî readr   2.1.2     ‚úî forcats 0.5.1\n\n\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2‚Ä¶\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, ‚Ä¶\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34‚Ä¶\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16‚Ä¶\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385‚Ä¶\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, ‚Ä¶\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7‚Ä¶\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, ‚Ä¶\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa‚Ä¶\n\n\n\nlibrary(tidyverse)\nlibrary(ISLR2)\ndata(\"Auto\")\nglimpse(Auto)\n\nRows: 392\nColumns: 9\n$ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 2‚Ä¶\n$ cylinders    <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6, 6, 4, ‚Ä¶\n$ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390, 383, 34‚Ä¶\n$ horsepower   <int> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190, 170, 16‚Ä¶\n$ weight       <int> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4425, 385‚Ä¶\n$ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10.0, 8.5, ‚Ä¶\n$ year         <int> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7‚Ä¶\n$ origin       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, ‚Ä¶\n$ name         <fct> chevrolet chevelle malibu, buick skylark 320, plymouth sa‚Ä¶\n\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\")\n\n\n\n\n\n#MLR model regressing mpg on weight and origin\nmlr_mod_auto <- lm(mpg~weight+origin,\n                   data=Auto)\n\nsummary(mlr_mod_auto)\n\n\nCall:\nlm(formula = mpg ~ weight + origin, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.0698  -2.7888  -0.3122   2.4489  15.4816 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.4908175  1.3266161   32.03  < 2e-16 ***\nweight      -0.0070071  0.0003136  -22.34  < 2e-16 ***\norigin       1.1540278  0.3306915    3.49 0.000539 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.272 on 389 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.7004 \nF-statistic: 458.1 on 2 and 389 DF,  p-value: < 2.2e-16\n\n\n\n#create a factor variable\nAuto$origin_fac <- factor(Auto$origin,\n                          levels=c(1,2,3),\n                          labels=c(\"American\",\n                                   \"European\",\n                                   \"Japanese\"))\n\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n\n\n\n\nmlr_mod_fac <- lm(mpg~weight+origin_fac,\n                  data=Auto)\n\nsummary(mlr_mod_fac)\n\n\nCall:\nlm(formula = mpg ~ weight + origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.1339  -2.7358  -0.3032   2.4307  15.4544 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        43.7322362  1.1134286  39.277  < 2e-16 ***\nweight             -0.0070271  0.0003201 -21.956  < 2e-16 ***\norigin_facEuropean  0.9709056  0.6587673   1.474 0.141340    \norigin_facJapanese  2.3271499  0.6648043   3.501 0.000518 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.277 on 388 degrees of freedom\nMultiple R-squared:  0.702, Adjusted R-squared:  0.6997 \nF-statistic: 304.7 on 3 and 388 DF,  p-value: < 2.2e-16\n\n\nOn average, European cars‚Äô mpg is 0.97 higher than American cars‚Äô mpg, holding all else constant. This difference is not statistically significant at the 0.05 level (p=0.14).\nOn average, per increase in weight (lb), mpg decreases by 0.007, all else constant. This is statistically significant (p<0.001), so vehicle weight is associated with mpg."
  },
  {
    "objectID": "introtomlrcode.html#interaction",
    "href": "introtomlrcode.html#interaction",
    "title": "Intro to MLR",
    "section": "Interaction",
    "text": "Interaction\n\nggplot(Auto, aes(x=weight,y=mpg,col=origin_fac))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=F)+\n  labs(x=\"Vehicle weight (lbs)\",\n       y=\"MPG\",col=\"Origin\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nmlr_mod_interact <- lm(mpg~weight*origin_fac,\n                       data=Auto)\nsummary(mlr_mod_interact)\n\n\nCall:\nlm(formula = mpg ~ weight * origin_fac, data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4928  -2.7715  -0.3895   2.2397  15.5163 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                4.315e+01  1.186e+00  36.378  < 2e-16 ***\nweight                    -6.854e-03  3.423e-04 -20.020  < 2e-16 ***\norigin_facEuropean         1.125e+00  2.878e+00   0.391  0.69616    \norigin_facJapanese         1.111e+01  3.574e+00   3.109  0.00202 ** \nweight:origin_facEuropean  3.575e-06  1.111e-03   0.003  0.99743    \nweight:origin_facJapanese -3.865e-03  1.541e-03  -2.508  0.01255 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.253 on 386 degrees of freedom\nMultiple R-squared:  0.7068,    Adjusted R-squared:  0.703 \nF-statistic: 186.1 on 5 and 386 DF,  p-value: < 2.2e-16\n\n\nPer lb increase in weight, mpg increases by an additional 0.0000036, on average, all else held constant, for European cars compared to American cars. This difference is not statistically significant (p>0.99).\nPer lb increase in weight, mpg decreases by 0.011, on average, for European cars. For American cars, mpg decreases by 0.007, on average, per lb increase in weight. The difference in effects, 0.004, is statistically significant at the 0.05 level (p=0.013)."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Getting started with R and RStudio\nR for Data Science\nCheatsheets (RStudio, Quarto, ggplot2, dplyr)\nQuarto documentation"
  },
  {
    "objectID": "resources.html#statistics",
    "href": "resources.html#statistics",
    "title": "Resources",
    "section": "Statistics",
    "text": "Statistics\nPractical Statistics for Data Scientists (available online)\nIntroduction to Modern Statistics by Mine √áetinkaya-Rundel and Johanna Hardin\nDr.¬†Mine √áetinkaya-Rundel‚Äôs YouTube channel (includes R)"
  }
]